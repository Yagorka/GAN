{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFOGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7_PY3I7Ep44"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        " \n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        " \n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYRBzS88ubzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae2ee54-7726-49e3-e163-8ed6ff734470"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUX10eg5ujwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15782a90-85fd-4e41-e9b6-f2ff6d099226"
      },
      "source": [
        "cd /content/drive/My Drive/GAN_MNIST/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/GAN_MNIST\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD7tSGcuE14v"
      },
      "source": [
        "os.makedirs(\"images/static/\", exist_ok=True)\n",
        "#os.makedirs(\"images/varying_c1/\", exist_ok=True)\n",
        "#os.makedirs(\"images/varying_c2/\", exist_ok=True)\n",
        "\n",
        "\n",
        "n_epochs=200\n",
        "batch_size=64\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "n_cpu=8\n",
        "latent_dim=62\n",
        "code_dim=2\n",
        "n_classes=10\n",
        "img_size=32\n",
        "channels=1\n",
        "sample_interval=400\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbBSFBiCvedh"
      },
      "source": [
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def to_categorical(y, num_columns):\n",
        "    \"\"\"Returns one-hot encoded Variable\"\"\"\n",
        "    y_cat = np.zeros((y.shape[0], num_columns))\n",
        "    y_cat[range(y.shape[0]), y] = 1.0\n",
        "\n",
        "    return Variable(FloatTensor(y_cat))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L85Z2lZvjnH"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        input_dim = latent_dim +n_classes + code_dim\n",
        "\n",
        "        self.init_size = img_size // 4  # Initial size before upsampling\n",
        "        self.l1 = nn.Sequential(nn.Linear(input_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels, code):\n",
        "        gen_input = torch.cat((noise, labels, code), -1)\n",
        "        out = self.l1(gen_input)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyO45DklvuTH"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            *discriminator_block(channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = img_size // 2 ** 4\n",
        "\n",
        "        # Output layers\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1))\n",
        "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, n_classes), nn.Softmax())\n",
        "        self.latent_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, code_dim))\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.conv_blocks(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "        label = self.aux_layer(out)\n",
        "        latent_code = self.latent_layer(out)\n",
        "\n",
        "        return validity, label, latent_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C_oADjyv8Ev"
      },
      "source": [
        "# Loss functions\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "categorical_loss = torch.nn.CrossEntropyLoss()\n",
        "continuous_loss = torch.nn.MSELoss()\n",
        "\n",
        "# Loss weights\n",
        "lambda_cat = 1\n",
        "lambda_con = 0.1\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    categorical_loss.cuda()\n",
        "    continuous_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "\n",
        "# Configure data loader\n",
        "os.makedirs(\"data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXAWfPizww45"
      },
      "source": [
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_info = torch.optim.Adam(\n",
        "    itertools.chain(generator.parameters(), discriminator.parameters()), lr=lr, betas=(b1, b2)\n",
        ")\n",
        "\n",
        "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
        "\n",
        "# Static generator inputs for sampling\n",
        "static_z = Variable(FloatTensor(np.zeros((n_classes ** 2, latent_dim))))\n",
        "static_label = to_categorical(\n",
        "    np.array([num for _ in range(n_classes) for num in range(n_classes)]), num_columns=n_classes\n",
        ")\n",
        "static_code = Variable(FloatTensor(np.zeros((n_classes ** 2, code_dim))))\n",
        "\n",
        "\n",
        "def sample_image(n_row, batches_done):\n",
        "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
        "    # Static sample\n",
        "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, latent_dim))))\n",
        "    static_sample = generator(z, static_label, static_code)\n",
        "    save_image(static_sample.data, \"images/static/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "\n",
        "    # Get varied c1 and c2\n",
        "    zeros = np.zeros((n_row ** 2, 1))\n",
        "    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)\n",
        "    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))\n",
        "    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))\n",
        "    sample1 = generator(static_z, static_label, c1)\n",
        "    sample2 = generator(static_z, static_label, c2)\n",
        "    save_image(sample1.data, \"images/info/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "    save_image(sample2.data, \"images/info2/%d.png\" % batches_done, nrow=n_row, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI0mQDencoJv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddA2GTpuxEix"
      },
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (imgs, labels) in enumerate(dataloader):\n",
        "\n",
        "        batch_size = imgs.shape[0] \n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "        labels = to_categorical(labels.numpy(), num_columns=n_classes)\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise and labels as generator input\n",
        "        #Случайные параметры 62 штуки\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
        "        #Метки классов\n",
        "        label_input = to_categorical(np.random.randint(0, n_classes, batch_size), num_columns=n_classes)\n",
        "        #Структурированные скрытые переменные которые должны определять выскокоуровневые признаки  \n",
        "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, code_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z, label_input, code_input)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        validity, _, _ = discriminator(gen_imgs)\n",
        "        g_loss = adversarial_loss(validity, valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Loss for real images\n",
        "        real_pred, _, _ = discriminator(real_imgs)\n",
        "        d_real_loss = adversarial_loss(real_pred, valid)\n",
        "\n",
        "        # Loss for fake images\n",
        "        fake_pred, _, _ = discriminator(gen_imgs.detach())\n",
        "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # ------------------\n",
        "        # Information Loss\n",
        "        # ------------------\n",
        "\n",
        "        optimizer_info.zero_grad()\n",
        "\n",
        "        # Sample labels\n",
        "        sampled_labels = np.random.randint(0, n_classes, batch_size)\n",
        "\n",
        "        # Ground truth labels\n",
        "        gt_labels = Variable(LongTensor(sampled_labels), requires_grad=False)\n",
        "\n",
        "        # Sample noise, labels and code as generator input\n",
        "        # Готовим вход для генерции аналогично предыдущей\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
        "        label_input = to_categorical(sampled_labels, num_columns=n_classes)\n",
        "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, code_dim)))) # [-1;1) size (batch_size, code_dim)\n",
        "\n",
        "        gen_imgs = generator(z, label_input, code_input)\n",
        "        # Принимаем только метку класса(1,..,9) и высокоуровневые признаки\n",
        "        _, pred_label, pred_code = discriminator(gen_imgs)\n",
        "        \"\"\" Получаем ошибку пропорциональную ошибке на предсказании метки класса и ошибке на этих двух \"сверхрепрезентативных\" \n",
        "        скрытых переменных\"\"\"\n",
        "        info_loss = lambda_cat * categorical_loss(pred_label, gt_labels) + lambda_con * continuous_loss(\n",
        "            pred_code, code_input\n",
        "        )\n",
        "        # делаем шаг в сторону улучшения влияния скрытых переменных на картинку\n",
        "        info_loss.backward()\n",
        "        optimizer_info.step()\n",
        "\n",
        "        # --------------\n",
        "        # Log Progress\n",
        "        # --------------\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [info loss: %f]\"\n",
        "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item(), info_loss.item())\n",
        "        )\n",
        "        #batches_done = epoch * len(dataloader) + i\n",
        "       # if batches_done % sample_interval == 0:\n",
        "        #    sample_image(n_row=10, batches_done=batches_done)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}