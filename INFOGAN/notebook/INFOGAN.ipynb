{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFOGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7_PY3I7Ep44"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        " \n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        " \n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYRBzS88ubzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae2ee54-7726-49e3-e163-8ed6ff734470"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUX10eg5ujwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15782a90-85fd-4e41-e9b6-f2ff6d099226"
      },
      "source": [
        "cd /content/drive/My Drive/GAN_MNIST/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/GAN_MNIST\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD7tSGcuE14v"
      },
      "source": [
        "os.makedirs(\"images/static/\", exist_ok=True)\n",
        "#os.makedirs(\"images/varying_c1/\", exist_ok=True)\n",
        "#os.makedirs(\"images/varying_c2/\", exist_ok=True)\n",
        "\n",
        "\n",
        "n_epochs=200\n",
        "batch_size=64\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "n_cpu=8\n",
        "latent_dim=62\n",
        "code_dim=2\n",
        "n_classes=10\n",
        "img_size=32\n",
        "channels=1\n",
        "sample_interval=400\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbBSFBiCvedh"
      },
      "source": [
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def to_categorical(y, num_columns):\n",
        "    \"\"\"Returns one-hot encoded Variable\"\"\"\n",
        "    y_cat = np.zeros((y.shape[0], num_columns))\n",
        "    y_cat[range(y.shape[0]), y] = 1.0\n",
        "\n",
        "    return Variable(FloatTensor(y_cat))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L85Z2lZvjnH"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        input_dim = latent_dim +n_classes + code_dim\n",
        "\n",
        "        self.init_size = img_size // 4  # Initial size before upsampling\n",
        "        self.l1 = nn.Sequential(nn.Linear(input_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels, code):\n",
        "        gen_input = torch.cat((noise, labels, code), -1)\n",
        "        out = self.l1(gen_input)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyO45DklvuTH"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            *discriminator_block(channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = img_size // 2 ** 4\n",
        "\n",
        "        # Output layers\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1))\n",
        "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, n_classes), nn.Softmax())\n",
        "        self.latent_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, code_dim))\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.conv_blocks(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "        label = self.aux_layer(out)\n",
        "        latent_code = self.latent_layer(out)\n",
        "\n",
        "        return validity, label, latent_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C_oADjyv8Ev"
      },
      "source": [
        "# Loss functions\n",
        "adversarial_loss = torch.nn.MSELoss()\n",
        "categorical_loss = torch.nn.CrossEntropyLoss()\n",
        "continuous_loss = torch.nn.MSELoss()\n",
        "\n",
        "# Loss weights\n",
        "lambda_cat = 1\n",
        "lambda_con = 0.1\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    categorical_loss.cuda()\n",
        "    continuous_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "\n",
        "# Configure data loader\n",
        "os.makedirs(\"data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXAWfPizww45"
      },
      "source": [
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_info = torch.optim.Adam(\n",
        "    itertools.chain(generator.parameters(), discriminator.parameters()), lr=lr, betas=(b1, b2)\n",
        ")\n",
        "\n",
        "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
        "\n",
        "# Static generator inputs for sampling\n",
        "static_z = Variable(FloatTensor(np.zeros((n_classes ** 2, latent_dim))))\n",
        "static_label = to_categorical(\n",
        "    np.array([num for _ in range(n_classes) for num in range(n_classes)]), num_columns=n_classes\n",
        ")\n",
        "static_code = Variable(FloatTensor(np.zeros((n_classes ** 2, code_dim))))\n",
        "\n",
        "\n",
        "def sample_image(n_row, batches_done):\n",
        "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
        "    # Static sample\n",
        "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, latent_dim))))\n",
        "    static_sample = generator(z, static_label, static_code)\n",
        "    save_image(static_sample.data, \"images/static/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "\n",
        "    # Get varied c1 and c2\n",
        "    zeros = np.zeros((n_row ** 2, 1))\n",
        "    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)\n",
        "    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))\n",
        "    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))\n",
        "    sample1 = generator(static_z, static_label, c1)\n",
        "    sample2 = generator(static_z, static_label, c2)\n",
        "    save_image(sample1.data, \"images/info/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "    save_image(sample2.data, \"images/info2/%d.png\" % batches_done, nrow=n_row, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI0mQDencoJv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddA2GTpuxEix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d5eda70-2017-4e8f-ea2b-a3441c712eac"
      },
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (imgs, labels) in enumerate(dataloader):\n",
        "\n",
        "        batch_size = imgs.shape[0] \n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "        labels = to_categorical(labels.numpy(), num_columns=n_classes)\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise and labels as generator input\n",
        "        #Случайные параметры 62 штуки\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
        "        #Метки классов\n",
        "        label_input = to_categorical(np.random.randint(0, n_classes, batch_size), num_columns=n_classes)\n",
        "        #Структурированные скрытые переменные которые должны определять выскокоуровневые признаки  \n",
        "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, code_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z, label_input, code_input)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        validity, _, _ = discriminator(gen_imgs)\n",
        "        g_loss = adversarial_loss(validity, valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Loss for real images\n",
        "        real_pred, _, _ = discriminator(real_imgs)\n",
        "        d_real_loss = adversarial_loss(real_pred, valid)\n",
        "\n",
        "        # Loss for fake images\n",
        "        fake_pred, _, _ = discriminator(gen_imgs.detach())\n",
        "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # ------------------\n",
        "        # Information Loss\n",
        "        # ------------------\n",
        "\n",
        "        optimizer_info.zero_grad()\n",
        "\n",
        "        # Sample labels\n",
        "        sampled_labels = np.random.randint(0, n_classes, batch_size)\n",
        "\n",
        "        # Ground truth labels\n",
        "        gt_labels = Variable(LongTensor(sampled_labels), requires_grad=False)\n",
        "\n",
        "        # Sample noise, labels and code as generator input\n",
        "        # Готовим вход для генерции аналогично предыдущей\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
        "        label_input = to_categorical(sampled_labels, num_columns=n_classes)\n",
        "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, code_dim)))) # [-1;1) size (batch_size, code_dim)\n",
        "\n",
        "        gen_imgs = generator(z, label_input, code_input)\n",
        "        # Принимаем только метку класса(1,..,9) и высокоуровневые признаки\n",
        "        _, pred_label, pred_code = discriminator(gen_imgs)\n",
        "        \"\"\" Получаем ошибку пропорциональную ошибке на предсказании метки класса и ошибке на этих двух \"сверхрепрезентативных\" \n",
        "        скрытых переменных\"\"\"\n",
        "        info_loss = lambda_cat * categorical_loss(pred_label, gt_labels) + lambda_con * continuous_loss(\n",
        "            pred_code, code_input\n",
        "        )\n",
        "        # делаем шаг в сторону улучшения влияния скрытых переменных на картинку\n",
        "        info_loss.backward()\n",
        "        optimizer_info.step()\n",
        "\n",
        "        # --------------\n",
        "        # Log Progress\n",
        "        # --------------\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [info loss: %f]\"\n",
        "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item(), info_loss.item())\n",
        "        )\n",
        "        #batches_done = epoch * len(dataloader) + i\n",
        "       # if batches_done % sample_interval == 0:\n",
        "        #    sample_image(n_row=10, batches_done=batches_done)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "[Epoch 26/200] [Batch 863/938] [D loss: 0.182527] [G loss: 0.369521] [info loss: 1.492317]\n",
            "[Epoch 26/200] [Batch 864/938] [D loss: 0.198523] [G loss: 0.104709] [info loss: 1.475123]\n",
            "[Epoch 26/200] [Batch 865/938] [D loss: 0.381617] [G loss: 0.486339] [info loss: 1.488910]\n",
            "[Epoch 26/200] [Batch 866/938] [D loss: 0.227793] [G loss: 0.366532] [info loss: 1.478138]\n",
            "[Epoch 26/200] [Batch 867/938] [D loss: 0.252503] [G loss: 0.697170] [info loss: 1.485243]\n",
            "[Epoch 26/200] [Batch 868/938] [D loss: 0.174950] [G loss: 0.284311] [info loss: 1.488236]\n",
            "[Epoch 26/200] [Batch 869/938] [D loss: 0.134772] [G loss: 0.177469] [info loss: 1.474259]\n",
            "[Epoch 26/200] [Batch 870/938] [D loss: 0.207333] [G loss: 0.430904] [info loss: 1.478334]\n",
            "[Epoch 26/200] [Batch 871/938] [D loss: 0.234154] [G loss: 0.526021] [info loss: 1.470502]\n",
            "[Epoch 26/200] [Batch 872/938] [D loss: 0.311844] [G loss: 0.386815] [info loss: 1.470318]\n",
            "[Epoch 26/200] [Batch 873/938] [D loss: 0.192443] [G loss: 0.356758] [info loss: 1.483449]\n",
            "[Epoch 26/200] [Batch 874/938] [D loss: 0.285808] [G loss: 0.264626] [info loss: 1.509493]\n",
            "[Epoch 26/200] [Batch 875/938] [D loss: 0.209881] [G loss: 0.580481] [info loss: 1.480744]\n",
            "[Epoch 26/200] [Batch 876/938] [D loss: 0.223002] [G loss: 0.423696] [info loss: 1.494312]\n",
            "[Epoch 26/200] [Batch 877/938] [D loss: 0.204760] [G loss: 0.440700] [info loss: 1.473207]\n",
            "[Epoch 26/200] [Batch 878/938] [D loss: 0.182621] [G loss: 0.361850] [info loss: 1.470764]\n",
            "[Epoch 26/200] [Batch 879/938] [D loss: 0.189537] [G loss: 0.445463] [info loss: 1.490142]\n",
            "[Epoch 26/200] [Batch 880/938] [D loss: 0.198617] [G loss: 0.290573] [info loss: 1.470996]\n",
            "[Epoch 26/200] [Batch 881/938] [D loss: 0.167786] [G loss: 0.207599] [info loss: 1.469824]\n",
            "[Epoch 26/200] [Batch 882/938] [D loss: 0.193435] [G loss: 0.255750] [info loss: 1.469917]\n",
            "[Epoch 26/200] [Batch 883/938] [D loss: 0.154085] [G loss: 0.209417] [info loss: 1.472833]\n",
            "[Epoch 26/200] [Batch 884/938] [D loss: 0.189478] [G loss: 0.263992] [info loss: 1.473790]\n",
            "[Epoch 26/200] [Batch 885/938] [D loss: 0.273220] [G loss: 0.259384] [info loss: 1.471056]\n",
            "[Epoch 26/200] [Batch 886/938] [D loss: 0.235168] [G loss: 0.303574] [info loss: 1.470983]\n",
            "[Epoch 26/200] [Batch 887/938] [D loss: 0.254394] [G loss: 0.314615] [info loss: 1.504397]\n",
            "[Epoch 26/200] [Batch 888/938] [D loss: 0.214619] [G loss: 0.255932] [info loss: 1.475111]\n",
            "[Epoch 26/200] [Batch 889/938] [D loss: 0.220186] [G loss: 0.460641] [info loss: 1.487016]\n",
            "[Epoch 26/200] [Batch 890/938] [D loss: 0.221083] [G loss: 0.345733] [info loss: 1.474827]\n",
            "[Epoch 26/200] [Batch 891/938] [D loss: 0.148161] [G loss: 0.368313] [info loss: 1.485041]\n",
            "[Epoch 26/200] [Batch 892/938] [D loss: 0.276455] [G loss: 0.351263] [info loss: 1.488734]\n",
            "[Epoch 26/200] [Batch 893/938] [D loss: 0.218971] [G loss: 0.204926] [info loss: 1.484605]\n",
            "[Epoch 26/200] [Batch 894/938] [D loss: 0.222049] [G loss: 0.348091] [info loss: 1.477554]\n",
            "[Epoch 26/200] [Batch 895/938] [D loss: 0.263194] [G loss: 0.445942] [info loss: 1.475554]\n",
            "[Epoch 26/200] [Batch 896/938] [D loss: 0.283434] [G loss: 0.525131] [info loss: 1.469892]\n",
            "[Epoch 26/200] [Batch 897/938] [D loss: 0.309570] [G loss: 0.450463] [info loss: 1.474841]\n",
            "[Epoch 26/200] [Batch 898/938] [D loss: 0.180125] [G loss: 0.276606] [info loss: 1.477600]\n",
            "[Epoch 26/200] [Batch 899/938] [D loss: 0.314676] [G loss: 0.312304] [info loss: 1.471869]\n",
            "[Epoch 26/200] [Batch 900/938] [D loss: 0.247223] [G loss: 0.563002] [info loss: 1.476654]\n",
            "[Epoch 26/200] [Batch 901/938] [D loss: 0.169760] [G loss: 0.328604] [info loss: 1.472894]\n",
            "[Epoch 26/200] [Batch 902/938] [D loss: 0.221472] [G loss: 0.455183] [info loss: 1.488249]\n",
            "[Epoch 26/200] [Batch 903/938] [D loss: 0.164191] [G loss: 0.176361] [info loss: 1.491593]\n",
            "[Epoch 26/200] [Batch 904/938] [D loss: 0.310235] [G loss: 0.165996] [info loss: 1.481544]\n",
            "[Epoch 26/200] [Batch 905/938] [D loss: 0.183397] [G loss: 0.279940] [info loss: 1.503581]\n",
            "[Epoch 26/200] [Batch 906/938] [D loss: 0.152014] [G loss: 0.277956] [info loss: 1.478227]\n",
            "[Epoch 26/200] [Batch 907/938] [D loss: 0.252821] [G loss: 0.372978] [info loss: 1.485569]\n",
            "[Epoch 26/200] [Batch 908/938] [D loss: 0.190623] [G loss: 0.184240] [info loss: 1.470177]\n",
            "[Epoch 26/200] [Batch 909/938] [D loss: 0.241559] [G loss: 0.215776] [info loss: 1.475288]\n",
            "[Epoch 26/200] [Batch 910/938] [D loss: 0.280272] [G loss: 0.320199] [info loss: 1.483271]\n",
            "[Epoch 26/200] [Batch 911/938] [D loss: 0.283688] [G loss: 0.231028] [info loss: 1.471297]\n",
            "[Epoch 26/200] [Batch 912/938] [D loss: 0.272835] [G loss: 0.305863] [info loss: 1.500312]\n",
            "[Epoch 26/200] [Batch 913/938] [D loss: 0.258051] [G loss: 0.500440] [info loss: 1.475657]\n",
            "[Epoch 26/200] [Batch 914/938] [D loss: 0.244810] [G loss: 0.351739] [info loss: 1.481731]\n",
            "[Epoch 26/200] [Batch 915/938] [D loss: 0.273236] [G loss: 0.207816] [info loss: 1.467267]\n",
            "[Epoch 26/200] [Batch 916/938] [D loss: 0.224768] [G loss: 0.285862] [info loss: 1.488770]\n",
            "[Epoch 26/200] [Batch 917/938] [D loss: 0.197943] [G loss: 0.325881] [info loss: 1.474279]\n",
            "[Epoch 26/200] [Batch 918/938] [D loss: 0.194537] [G loss: 0.497958] [info loss: 1.512981]\n",
            "[Epoch 26/200] [Batch 919/938] [D loss: 0.263716] [G loss: 0.433021] [info loss: 1.470488]\n",
            "[Epoch 26/200] [Batch 920/938] [D loss: 0.189211] [G loss: 0.338540] [info loss: 1.471548]\n",
            "[Epoch 26/200] [Batch 921/938] [D loss: 0.170469] [G loss: 0.248404] [info loss: 1.485294]\n",
            "[Epoch 26/200] [Batch 922/938] [D loss: 0.111706] [G loss: 0.372939] [info loss: 1.492477]\n",
            "[Epoch 26/200] [Batch 923/938] [D loss: 0.125872] [G loss: 0.394025] [info loss: 1.482339]\n",
            "[Epoch 26/200] [Batch 924/938] [D loss: 0.189156] [G loss: 0.531379] [info loss: 1.484568]\n",
            "[Epoch 26/200] [Batch 925/938] [D loss: 0.301616] [G loss: 0.434004] [info loss: 1.468878]\n",
            "[Epoch 26/200] [Batch 926/938] [D loss: 0.267621] [G loss: 0.260661] [info loss: 1.470156]\n",
            "[Epoch 26/200] [Batch 927/938] [D loss: 0.205209] [G loss: 0.286707] [info loss: 1.474447]\n",
            "[Epoch 26/200] [Batch 928/938] [D loss: 0.274937] [G loss: 0.265863] [info loss: 1.488873]\n",
            "[Epoch 26/200] [Batch 929/938] [D loss: 0.216985] [G loss: 0.213962] [info loss: 1.472774]\n",
            "[Epoch 26/200] [Batch 930/938] [D loss: 0.202534] [G loss: 0.376029] [info loss: 1.488716]\n",
            "[Epoch 26/200] [Batch 931/938] [D loss: 0.249273] [G loss: 0.315724] [info loss: 1.475933]\n",
            "[Epoch 26/200] [Batch 932/938] [D loss: 0.153740] [G loss: 0.174290] [info loss: 1.471731]\n",
            "[Epoch 26/200] [Batch 933/938] [D loss: 0.145389] [G loss: 0.302265] [info loss: 1.481391]\n",
            "[Epoch 26/200] [Batch 934/938] [D loss: 0.229515] [G loss: 0.507903] [info loss: 1.495023]\n",
            "[Epoch 26/200] [Batch 935/938] [D loss: 0.289184] [G loss: 0.435267] [info loss: 1.511396]\n",
            "[Epoch 26/200] [Batch 936/938] [D loss: 0.201190] [G loss: 0.305390] [info loss: 1.491768]\n",
            "[Epoch 26/200] [Batch 937/938] [D loss: 0.124332] [G loss: 0.234267] [info loss: 1.499323]\n",
            "[Epoch 27/200] [Batch 0/938] [D loss: 0.239922] [G loss: 0.324975] [info loss: 1.473712]\n",
            "[Epoch 27/200] [Batch 1/938] [D loss: 0.257934] [G loss: 0.274060] [info loss: 1.470087]\n",
            "[Epoch 27/200] [Batch 2/938] [D loss: 0.152929] [G loss: 0.329912] [info loss: 1.471189]\n",
            "[Epoch 27/200] [Batch 3/938] [D loss: 0.167624] [G loss: 0.309936] [info loss: 1.472136]\n",
            "[Epoch 27/200] [Batch 4/938] [D loss: 0.327933] [G loss: 0.511640] [info loss: 1.472120]\n",
            "[Epoch 27/200] [Batch 5/938] [D loss: 0.344106] [G loss: 0.394874] [info loss: 1.487507]\n",
            "[Epoch 27/200] [Batch 6/938] [D loss: 0.242706] [G loss: 0.348642] [info loss: 1.477256]\n",
            "[Epoch 27/200] [Batch 7/938] [D loss: 0.170306] [G loss: 0.339956] [info loss: 1.491642]\n",
            "[Epoch 27/200] [Batch 8/938] [D loss: 0.193535] [G loss: 0.561563] [info loss: 1.492723]\n",
            "[Epoch 27/200] [Batch 9/938] [D loss: 0.188814] [G loss: 0.356039] [info loss: 1.487369]\n",
            "[Epoch 27/200] [Batch 10/938] [D loss: 0.150861] [G loss: 0.235177] [info loss: 1.477860]\n",
            "[Epoch 27/200] [Batch 11/938] [D loss: 0.165425] [G loss: 0.379430] [info loss: 1.480016]\n",
            "[Epoch 27/200] [Batch 12/938] [D loss: 0.185661] [G loss: 0.294687] [info loss: 1.481347]\n",
            "[Epoch 27/200] [Batch 13/938] [D loss: 0.246948] [G loss: 0.595066] [info loss: 1.490250]\n",
            "[Epoch 27/200] [Batch 14/938] [D loss: 0.193711] [G loss: 0.274645] [info loss: 1.495477]\n",
            "[Epoch 27/200] [Batch 15/938] [D loss: 0.150622] [G loss: 0.278907] [info loss: 1.485404]\n",
            "[Epoch 27/200] [Batch 16/938] [D loss: 0.191478] [G loss: 0.198781] [info loss: 1.485670]\n",
            "[Epoch 27/200] [Batch 17/938] [D loss: 0.306376] [G loss: 0.166659] [info loss: 1.470121]\n",
            "[Epoch 27/200] [Batch 18/938] [D loss: 0.268245] [G loss: 0.098888] [info loss: 1.470046]\n",
            "[Epoch 27/200] [Batch 19/938] [D loss: 0.267422] [G loss: 0.329356] [info loss: 1.471768]\n",
            "[Epoch 27/200] [Batch 20/938] [D loss: 0.206866] [G loss: 0.280257] [info loss: 1.472111]\n",
            "[Epoch 27/200] [Batch 21/938] [D loss: 0.213998] [G loss: 0.408660] [info loss: 1.471561]\n",
            "[Epoch 27/200] [Batch 22/938] [D loss: 0.274822] [G loss: 0.478573] [info loss: 1.479692]\n",
            "[Epoch 27/200] [Batch 23/938] [D loss: 0.165990] [G loss: 0.330929] [info loss: 1.484342]\n",
            "[Epoch 27/200] [Batch 24/938] [D loss: 0.114292] [G loss: 0.266986] [info loss: 1.482914]\n",
            "[Epoch 27/200] [Batch 25/938] [D loss: 0.193480] [G loss: 0.275414] [info loss: 1.477286]\n",
            "[Epoch 27/200] [Batch 26/938] [D loss: 0.177474] [G loss: 0.281243] [info loss: 1.501447]\n",
            "[Epoch 27/200] [Batch 27/938] [D loss: 0.172856] [G loss: 0.367593] [info loss: 1.473335]\n",
            "[Epoch 27/200] [Batch 28/938] [D loss: 0.310751] [G loss: 0.409916] [info loss: 1.474417]\n",
            "[Epoch 27/200] [Batch 29/938] [D loss: 0.201131] [G loss: 0.279530] [info loss: 1.471324]\n",
            "[Epoch 27/200] [Batch 30/938] [D loss: 0.188193] [G loss: 0.276029] [info loss: 1.471570]\n",
            "[Epoch 27/200] [Batch 31/938] [D loss: 0.158879] [G loss: 0.249090] [info loss: 1.472051]\n",
            "[Epoch 27/200] [Batch 32/938] [D loss: 0.258380] [G loss: 0.502684] [info loss: 1.502435]\n",
            "[Epoch 27/200] [Batch 33/938] [D loss: 0.224621] [G loss: 0.268942] [info loss: 1.473680]\n",
            "[Epoch 27/200] [Batch 34/938] [D loss: 0.201874] [G loss: 0.233902] [info loss: 1.474350]\n",
            "[Epoch 27/200] [Batch 35/938] [D loss: 0.277977] [G loss: 0.241410] [info loss: 1.480934]\n",
            "[Epoch 27/200] [Batch 36/938] [D loss: 0.265290] [G loss: 0.358568] [info loss: 1.499565]\n",
            "[Epoch 27/200] [Batch 37/938] [D loss: 0.270002] [G loss: 0.550750] [info loss: 1.479306]\n",
            "[Epoch 27/200] [Batch 38/938] [D loss: 0.182613] [G loss: 0.542982] [info loss: 1.479776]\n",
            "[Epoch 27/200] [Batch 39/938] [D loss: 0.112960] [G loss: 0.369989] [info loss: 1.483781]\n",
            "[Epoch 27/200] [Batch 40/938] [D loss: 0.203569] [G loss: 0.275434] [info loss: 1.471344]\n",
            "[Epoch 27/200] [Batch 41/938] [D loss: 0.203178] [G loss: 0.298035] [info loss: 1.475800]\n",
            "[Epoch 27/200] [Batch 42/938] [D loss: 0.171655] [G loss: 0.511217] [info loss: 1.485248]\n",
            "[Epoch 27/200] [Batch 43/938] [D loss: 0.210677] [G loss: 0.353654] [info loss: 1.505902]\n",
            "[Epoch 27/200] [Batch 44/938] [D loss: 0.106560] [G loss: 0.525962] [info loss: 1.491113]\n",
            "[Epoch 27/200] [Batch 45/938] [D loss: 0.205964] [G loss: 0.312617] [info loss: 1.483837]\n",
            "[Epoch 27/200] [Batch 46/938] [D loss: 0.227258] [G loss: 0.319263] [info loss: 1.513979]\n",
            "[Epoch 27/200] [Batch 47/938] [D loss: 0.203201] [G loss: 0.146670] [info loss: 1.470085]\n",
            "[Epoch 27/200] [Batch 48/938] [D loss: 0.368791] [G loss: 0.197743] [info loss: 1.488998]\n",
            "[Epoch 27/200] [Batch 49/938] [D loss: 0.279587] [G loss: 0.437886] [info loss: 1.473909]\n",
            "[Epoch 27/200] [Batch 50/938] [D loss: 0.178874] [G loss: 0.479611] [info loss: 1.491228]\n",
            "[Epoch 27/200] [Batch 51/938] [D loss: 0.237750] [G loss: 0.799850] [info loss: 1.486401]\n",
            "[Epoch 27/200] [Batch 52/938] [D loss: 0.276107] [G loss: 0.526642] [info loss: 1.470650]\n",
            "[Epoch 27/200] [Batch 53/938] [D loss: 0.139048] [G loss: 0.173211] [info loss: 1.487723]\n",
            "[Epoch 27/200] [Batch 54/938] [D loss: 0.180091] [G loss: 0.300057] [info loss: 1.475972]\n",
            "[Epoch 27/200] [Batch 55/938] [D loss: 0.165216] [G loss: 0.239478] [info loss: 1.488459]\n",
            "[Epoch 27/200] [Batch 56/938] [D loss: 0.246859] [G loss: 0.429066] [info loss: 1.476835]\n",
            "[Epoch 27/200] [Batch 57/938] [D loss: 0.192017] [G loss: 0.323752] [info loss: 1.469964]\n",
            "[Epoch 27/200] [Batch 58/938] [D loss: 0.246936] [G loss: 0.273704] [info loss: 1.487065]\n",
            "[Epoch 27/200] [Batch 59/938] [D loss: 0.285143] [G loss: 0.321205] [info loss: 1.485548]\n",
            "[Epoch 27/200] [Batch 60/938] [D loss: 0.129141] [G loss: 0.461368] [info loss: 1.475650]\n",
            "[Epoch 27/200] [Batch 61/938] [D loss: 0.297644] [G loss: 0.577538] [info loss: 1.472139]\n",
            "[Epoch 27/200] [Batch 62/938] [D loss: 0.238122] [G loss: 0.263471] [info loss: 1.474579]\n",
            "[Epoch 27/200] [Batch 63/938] [D loss: 0.234885] [G loss: 0.423389] [info loss: 1.486053]\n",
            "[Epoch 27/200] [Batch 64/938] [D loss: 0.204950] [G loss: 0.455637] [info loss: 1.472976]\n",
            "[Epoch 27/200] [Batch 65/938] [D loss: 0.155320] [G loss: 0.236948] [info loss: 1.474330]\n",
            "[Epoch 27/200] [Batch 66/938] [D loss: 0.274924] [G loss: 0.217356] [info loss: 1.473746]\n",
            "[Epoch 27/200] [Batch 67/938] [D loss: 0.281208] [G loss: 0.110968] [info loss: 1.476559]\n",
            "[Epoch 27/200] [Batch 68/938] [D loss: 0.112800] [G loss: 0.343046] [info loss: 1.470669]\n",
            "[Epoch 27/200] [Batch 69/938] [D loss: 0.210601] [G loss: 0.407616] [info loss: 1.471713]\n",
            "[Epoch 27/200] [Batch 70/938] [D loss: 0.348867] [G loss: 0.393146] [info loss: 1.471076]\n",
            "[Epoch 27/200] [Batch 71/938] [D loss: 0.120646] [G loss: 0.509347] [info loss: 1.473091]\n",
            "[Epoch 27/200] [Batch 72/938] [D loss: 0.096920] [G loss: 0.325188] [info loss: 1.472608]\n",
            "[Epoch 27/200] [Batch 73/938] [D loss: 0.183740] [G loss: 0.327910] [info loss: 1.478668]\n",
            "[Epoch 27/200] [Batch 74/938] [D loss: 0.147803] [G loss: 0.170876] [info loss: 1.487597]\n",
            "[Epoch 27/200] [Batch 75/938] [D loss: 0.177281] [G loss: 0.607682] [info loss: 1.473114]\n",
            "[Epoch 27/200] [Batch 76/938] [D loss: 0.255715] [G loss: 0.531141] [info loss: 1.471383]\n",
            "[Epoch 27/200] [Batch 77/938] [D loss: 0.321909] [G loss: 0.424651] [info loss: 1.487787]\n",
            "[Epoch 27/200] [Batch 78/938] [D loss: 0.229355] [G loss: 0.257756] [info loss: 1.491284]\n",
            "[Epoch 27/200] [Batch 79/938] [D loss: 0.157754] [G loss: 0.112425] [info loss: 1.472768]\n",
            "[Epoch 27/200] [Batch 80/938] [D loss: 0.415296] [G loss: 0.358204] [info loss: 1.477889]\n",
            "[Epoch 27/200] [Batch 81/938] [D loss: 0.234450] [G loss: 0.315541] [info loss: 1.493502]\n",
            "[Epoch 27/200] [Batch 82/938] [D loss: 0.239995] [G loss: 0.153683] [info loss: 1.476439]\n",
            "[Epoch 27/200] [Batch 83/938] [D loss: 0.247586] [G loss: 0.176638] [info loss: 1.488029]\n",
            "[Epoch 27/200] [Batch 84/938] [D loss: 0.264568] [G loss: 0.158302] [info loss: 1.474101]\n",
            "[Epoch 27/200] [Batch 85/938] [D loss: 0.179968] [G loss: 0.313520] [info loss: 1.477451]\n",
            "[Epoch 27/200] [Batch 86/938] [D loss: 0.191356] [G loss: 0.458597] [info loss: 1.485642]\n",
            "[Epoch 27/200] [Batch 87/938] [D loss: 0.291621] [G loss: 0.722854] [info loss: 1.487354]\n",
            "[Epoch 27/200] [Batch 88/938] [D loss: 0.179792] [G loss: 0.482742] [info loss: 1.474820]\n",
            "[Epoch 27/200] [Batch 89/938] [D loss: 0.192447] [G loss: 0.552470] [info loss: 1.479261]\n",
            "[Epoch 27/200] [Batch 90/938] [D loss: 0.203770] [G loss: 0.282449] [info loss: 1.469563]\n",
            "[Epoch 27/200] [Batch 91/938] [D loss: 0.262124] [G loss: 0.249913] [info loss: 1.475256]\n",
            "[Epoch 27/200] [Batch 92/938] [D loss: 0.280119] [G loss: 0.146347] [info loss: 1.471330]\n",
            "[Epoch 27/200] [Batch 93/938] [D loss: 0.142052] [G loss: 0.254534] [info loss: 1.471523]\n",
            "[Epoch 27/200] [Batch 94/938] [D loss: 0.150512] [G loss: 0.466849] [info loss: 1.473491]\n",
            "[Epoch 27/200] [Batch 95/938] [D loss: 0.160333] [G loss: 0.431931] [info loss: 1.472722]\n",
            "[Epoch 27/200] [Batch 96/938] [D loss: 0.115627] [G loss: 0.583321] [info loss: 1.476125]\n",
            "[Epoch 27/200] [Batch 97/938] [D loss: 0.219893] [G loss: 0.304027] [info loss: 1.483322]\n",
            "[Epoch 27/200] [Batch 98/938] [D loss: 0.153171] [G loss: 0.302076] [info loss: 1.472659]\n",
            "[Epoch 27/200] [Batch 99/938] [D loss: 0.147743] [G loss: 0.167897] [info loss: 1.471674]\n",
            "[Epoch 27/200] [Batch 100/938] [D loss: 0.246533] [G loss: 0.134466] [info loss: 1.471992]\n",
            "[Epoch 27/200] [Batch 101/938] [D loss: 0.213667] [G loss: 0.399182] [info loss: 1.474599]\n",
            "[Epoch 27/200] [Batch 102/938] [D loss: 0.210324] [G loss: 0.503935] [info loss: 1.472916]\n",
            "[Epoch 27/200] [Batch 103/938] [D loss: 0.187884] [G loss: 0.174308] [info loss: 1.476099]\n",
            "[Epoch 27/200] [Batch 104/938] [D loss: 0.259935] [G loss: 0.467456] [info loss: 1.486005]\n",
            "[Epoch 27/200] [Batch 105/938] [D loss: 0.219234] [G loss: 0.395365] [info loss: 1.480831]\n",
            "[Epoch 27/200] [Batch 106/938] [D loss: 0.168183] [G loss: 0.610568] [info loss: 1.491715]\n",
            "[Epoch 27/200] [Batch 107/938] [D loss: 0.254890] [G loss: 0.317666] [info loss: 1.493707]\n",
            "[Epoch 27/200] [Batch 108/938] [D loss: 0.315655] [G loss: 0.192389] [info loss: 1.469089]\n",
            "[Epoch 27/200] [Batch 109/938] [D loss: 0.186087] [G loss: 0.238673] [info loss: 1.473356]\n",
            "[Epoch 27/200] [Batch 110/938] [D loss: 0.245975] [G loss: 0.348770] [info loss: 1.517969]\n",
            "[Epoch 27/200] [Batch 111/938] [D loss: 0.279914] [G loss: 0.295907] [info loss: 1.470445]\n",
            "[Epoch 27/200] [Batch 112/938] [D loss: 0.297106] [G loss: 0.417501] [info loss: 1.480445]\n",
            "[Epoch 27/200] [Batch 113/938] [D loss: 0.210439] [G loss: 0.263873] [info loss: 1.486072]\n",
            "[Epoch 27/200] [Batch 114/938] [D loss: 0.149499] [G loss: 0.326439] [info loss: 1.492680]\n",
            "[Epoch 27/200] [Batch 115/938] [D loss: 0.198628] [G loss: 0.263042] [info loss: 1.484683]\n",
            "[Epoch 27/200] [Batch 116/938] [D loss: 0.214725] [G loss: 0.166961] [info loss: 1.470858]\n",
            "[Epoch 27/200] [Batch 117/938] [D loss: 0.264700] [G loss: 0.163021] [info loss: 1.473127]\n",
            "[Epoch 27/200] [Batch 118/938] [D loss: 0.149500] [G loss: 0.299550] [info loss: 1.471631]\n",
            "[Epoch 27/200] [Batch 119/938] [D loss: 0.253806] [G loss: 0.187959] [info loss: 1.495162]\n",
            "[Epoch 27/200] [Batch 120/938] [D loss: 0.167105] [G loss: 0.341714] [info loss: 1.470189]\n",
            "[Epoch 27/200] [Batch 121/938] [D loss: 0.186929] [G loss: 0.225581] [info loss: 1.469416]\n",
            "[Epoch 27/200] [Batch 122/938] [D loss: 0.244404] [G loss: 0.329842] [info loss: 1.469510]\n",
            "[Epoch 27/200] [Batch 123/938] [D loss: 0.197286] [G loss: 0.333560] [info loss: 1.487105]\n",
            "[Epoch 27/200] [Batch 124/938] [D loss: 0.202951] [G loss: 0.300299] [info loss: 1.472836]\n",
            "[Epoch 27/200] [Batch 125/938] [D loss: 0.107423] [G loss: 0.308790] [info loss: 1.492725]\n",
            "[Epoch 27/200] [Batch 126/938] [D loss: 0.222718] [G loss: 0.214564] [info loss: 1.475820]\n",
            "[Epoch 27/200] [Batch 127/938] [D loss: 0.223026] [G loss: 0.247502] [info loss: 1.501563]\n",
            "[Epoch 27/200] [Batch 128/938] [D loss: 0.349906] [G loss: 0.212709] [info loss: 1.476742]\n",
            "[Epoch 27/200] [Batch 129/938] [D loss: 0.224857] [G loss: 0.240460] [info loss: 1.471573]\n",
            "[Epoch 27/200] [Batch 130/938] [D loss: 0.204359] [G loss: 0.368650] [info loss: 1.473421]\n",
            "[Epoch 27/200] [Batch 131/938] [D loss: 0.250395] [G loss: 0.337698] [info loss: 1.475823]\n",
            "[Epoch 27/200] [Batch 132/938] [D loss: 0.253249] [G loss: 0.348355] [info loss: 1.487356]\n",
            "[Epoch 27/200] [Batch 133/938] [D loss: 0.186686] [G loss: 0.257572] [info loss: 1.476159]\n",
            "[Epoch 27/200] [Batch 134/938] [D loss: 0.184504] [G loss: 0.238205] [info loss: 1.479715]\n",
            "[Epoch 27/200] [Batch 135/938] [D loss: 0.152540] [G loss: 0.396696] [info loss: 1.521456]\n",
            "[Epoch 27/200] [Batch 136/938] [D loss: 0.202766] [G loss: 0.455265] [info loss: 1.494141]\n",
            "[Epoch 27/200] [Batch 137/938] [D loss: 0.130616] [G loss: 0.504108] [info loss: 1.471852]\n",
            "[Epoch 27/200] [Batch 138/938] [D loss: 0.199179] [G loss: 0.270979] [info loss: 1.500648]\n",
            "[Epoch 27/200] [Batch 139/938] [D loss: 0.185114] [G loss: 0.139497] [info loss: 1.486136]\n",
            "[Epoch 27/200] [Batch 140/938] [D loss: 0.168403] [G loss: 0.097407] [info loss: 1.486354]\n",
            "[Epoch 27/200] [Batch 141/938] [D loss: 0.176425] [G loss: 0.205037] [info loss: 1.500083]\n",
            "[Epoch 27/200] [Batch 142/938] [D loss: 0.154973] [G loss: 0.224269] [info loss: 1.470486]\n",
            "[Epoch 27/200] [Batch 143/938] [D loss: 0.207714] [G loss: 0.442571] [info loss: 1.473774]\n",
            "[Epoch 27/200] [Batch 144/938] [D loss: 0.126740] [G loss: 0.437084] [info loss: 1.490141]\n",
            "[Epoch 27/200] [Batch 145/938] [D loss: 0.229186] [G loss: 0.398567] [info loss: 1.484522]\n",
            "[Epoch 27/200] [Batch 146/938] [D loss: 0.243943] [G loss: 0.461257] [info loss: 1.469343]\n",
            "[Epoch 27/200] [Batch 147/938] [D loss: 0.245442] [G loss: 0.256319] [info loss: 1.500067]\n",
            "[Epoch 27/200] [Batch 148/938] [D loss: 0.241102] [G loss: 0.297363] [info loss: 1.487539]\n",
            "[Epoch 27/200] [Batch 149/938] [D loss: 0.253808] [G loss: 0.299314] [info loss: 1.491607]\n",
            "[Epoch 27/200] [Batch 150/938] [D loss: 0.248874] [G loss: 0.334801] [info loss: 1.473912]\n",
            "[Epoch 27/200] [Batch 151/938] [D loss: 0.299661] [G loss: 0.461171] [info loss: 1.470052]\n",
            "[Epoch 27/200] [Batch 152/938] [D loss: 0.245954] [G loss: 0.337502] [info loss: 1.493134]\n",
            "[Epoch 27/200] [Batch 153/938] [D loss: 0.345509] [G loss: 0.286654] [info loss: 1.473026]\n",
            "[Epoch 27/200] [Batch 154/938] [D loss: 0.259055] [G loss: 0.269331] [info loss: 1.471594]\n",
            "[Epoch 27/200] [Batch 155/938] [D loss: 0.276255] [G loss: 0.350254] [info loss: 1.483528]\n",
            "[Epoch 27/200] [Batch 156/938] [D loss: 0.312621] [G loss: 0.346928] [info loss: 1.518836]\n",
            "[Epoch 27/200] [Batch 157/938] [D loss: 0.167949] [G loss: 0.211855] [info loss: 1.486875]\n",
            "[Epoch 27/200] [Batch 158/938] [D loss: 0.194669] [G loss: 0.244485] [info loss: 1.471905]\n",
            "[Epoch 27/200] [Batch 159/938] [D loss: 0.223509] [G loss: 0.238258] [info loss: 1.472011]\n",
            "[Epoch 27/200] [Batch 160/938] [D loss: 0.211233] [G loss: 0.452024] [info loss: 1.471851]\n",
            "[Epoch 27/200] [Batch 161/938] [D loss: 0.199581] [G loss: 0.762216] [info loss: 1.474217]\n",
            "[Epoch 27/200] [Batch 162/938] [D loss: 0.306755] [G loss: 0.148767] [info loss: 1.472899]\n",
            "[Epoch 27/200] [Batch 163/938] [D loss: 0.146519] [G loss: 0.248684] [info loss: 1.490271]\n",
            "[Epoch 27/200] [Batch 164/938] [D loss: 0.171906] [G loss: 0.420590] [info loss: 1.474362]\n",
            "[Epoch 27/200] [Batch 165/938] [D loss: 0.250918] [G loss: 0.384022] [info loss: 1.518258]\n",
            "[Epoch 27/200] [Batch 166/938] [D loss: 0.124792] [G loss: 0.152071] [info loss: 1.479533]\n",
            "[Epoch 27/200] [Batch 167/938] [D loss: 0.182788] [G loss: 0.222578] [info loss: 1.477865]\n",
            "[Epoch 27/200] [Batch 168/938] [D loss: 0.220467] [G loss: 0.183846] [info loss: 1.469321]\n",
            "[Epoch 27/200] [Batch 169/938] [D loss: 0.107179] [G loss: 0.325527] [info loss: 1.474240]\n",
            "[Epoch 27/200] [Batch 170/938] [D loss: 0.292025] [G loss: 0.290975] [info loss: 1.469404]\n",
            "[Epoch 27/200] [Batch 171/938] [D loss: 0.329191] [G loss: 0.195961] [info loss: 1.472011]\n",
            "[Epoch 27/200] [Batch 172/938] [D loss: 0.299275] [G loss: 0.360117] [info loss: 1.482633]\n",
            "[Epoch 27/200] [Batch 173/938] [D loss: 0.161008] [G loss: 0.174793] [info loss: 1.484537]\n",
            "[Epoch 27/200] [Batch 174/938] [D loss: 0.218917] [G loss: 0.145803] [info loss: 1.469080]\n",
            "[Epoch 27/200] [Batch 175/938] [D loss: 0.270093] [G loss: 0.470356] [info loss: 1.472746]\n",
            "[Epoch 27/200] [Batch 176/938] [D loss: 0.258747] [G loss: 0.615040] [info loss: 1.470858]\n",
            "[Epoch 27/200] [Batch 177/938] [D loss: 0.189192] [G loss: 0.392417] [info loss: 1.470334]\n",
            "[Epoch 27/200] [Batch 178/938] [D loss: 0.317967] [G loss: 0.241100] [info loss: 1.471725]\n",
            "[Epoch 27/200] [Batch 179/938] [D loss: 0.291114] [G loss: 0.370695] [info loss: 1.486431]\n",
            "[Epoch 27/200] [Batch 180/938] [D loss: 0.167057] [G loss: 0.469647] [info loss: 1.473197]\n",
            "[Epoch 27/200] [Batch 181/938] [D loss: 0.215805] [G loss: 0.613554] [info loss: 1.485302]\n",
            "[Epoch 27/200] [Batch 182/938] [D loss: 0.185074] [G loss: 0.234669] [info loss: 1.471314]\n",
            "[Epoch 27/200] [Batch 183/938] [D loss: 0.249812] [G loss: 0.455328] [info loss: 1.489456]\n",
            "[Epoch 27/200] [Batch 184/938] [D loss: 0.128724] [G loss: 0.247689] [info loss: 1.472756]\n",
            "[Epoch 27/200] [Batch 185/938] [D loss: 0.289265] [G loss: 0.099490] [info loss: 1.471870]\n",
            "[Epoch 27/200] [Batch 186/938] [D loss: 0.226567] [G loss: 0.160490] [info loss: 1.480105]\n",
            "[Epoch 27/200] [Batch 187/938] [D loss: 0.262979] [G loss: 0.381319] [info loss: 1.471258]\n",
            "[Epoch 27/200] [Batch 188/938] [D loss: 0.248229] [G loss: 0.416213] [info loss: 1.472065]\n",
            "[Epoch 27/200] [Batch 189/938] [D loss: 0.135534] [G loss: 0.399937] [info loss: 1.492109]\n",
            "[Epoch 27/200] [Batch 190/938] [D loss: 0.239302] [G loss: 0.206620] [info loss: 1.474169]\n",
            "[Epoch 27/200] [Batch 191/938] [D loss: 0.144017] [G loss: 0.308244] [info loss: 1.477998]\n",
            "[Epoch 27/200] [Batch 192/938] [D loss: 0.122125] [G loss: 0.294370] [info loss: 1.501794]\n",
            "[Epoch 27/200] [Batch 193/938] [D loss: 0.164806] [G loss: 0.256654] [info loss: 1.490009]\n",
            "[Epoch 27/200] [Batch 194/938] [D loss: 0.317362] [G loss: 0.292007] [info loss: 1.487969]\n",
            "[Epoch 27/200] [Batch 195/938] [D loss: 0.287338] [G loss: 0.228760] [info loss: 1.487627]\n",
            "[Epoch 27/200] [Batch 196/938] [D loss: 0.142128] [G loss: 0.398541] [info loss: 1.488298]\n",
            "[Epoch 27/200] [Batch 197/938] [D loss: 0.157917] [G loss: 0.329585] [info loss: 1.470978]\n",
            "[Epoch 27/200] [Batch 198/938] [D loss: 0.185292] [G loss: 0.152518] [info loss: 1.477526]\n",
            "[Epoch 27/200] [Batch 199/938] [D loss: 0.317451] [G loss: 0.462804] [info loss: 1.471606]\n",
            "[Epoch 27/200] [Batch 200/938] [D loss: 0.200390] [G loss: 0.357033] [info loss: 1.488405]\n",
            "[Epoch 27/200] [Batch 201/938] [D loss: 0.165042] [G loss: 0.407373] [info loss: 1.494733]\n",
            "[Epoch 27/200] [Batch 202/938] [D loss: 0.294776] [G loss: 0.369043] [info loss: 1.470330]\n",
            "[Epoch 27/200] [Batch 203/938] [D loss: 0.149198] [G loss: 0.322375] [info loss: 1.476771]\n",
            "[Epoch 27/200] [Batch 204/938] [D loss: 0.314606] [G loss: 0.272794] [info loss: 1.483364]\n",
            "[Epoch 27/200] [Batch 205/938] [D loss: 0.230523] [G loss: 0.335047] [info loss: 1.486417]\n",
            "[Epoch 27/200] [Batch 206/938] [D loss: 0.245540] [G loss: 0.463475] [info loss: 1.473767]\n",
            "[Epoch 27/200] [Batch 207/938] [D loss: 0.134644] [G loss: 0.365232] [info loss: 1.471519]\n",
            "[Epoch 27/200] [Batch 208/938] [D loss: 0.307188] [G loss: 0.289537] [info loss: 1.470947]\n",
            "[Epoch 27/200] [Batch 209/938] [D loss: 0.344578] [G loss: 0.261333] [info loss: 1.476439]\n",
            "[Epoch 27/200] [Batch 210/938] [D loss: 0.278522] [G loss: 0.394685] [info loss: 1.472328]\n",
            "[Epoch 27/200] [Batch 211/938] [D loss: 0.238068] [G loss: 0.559571] [info loss: 1.500956]\n",
            "[Epoch 27/200] [Batch 212/938] [D loss: 0.226599] [G loss: 0.347097] [info loss: 1.474236]\n",
            "[Epoch 27/200] [Batch 213/938] [D loss: 0.280308] [G loss: 0.326936] [info loss: 1.471555]\n",
            "[Epoch 27/200] [Batch 214/938] [D loss: 0.164681] [G loss: 0.215824] [info loss: 1.471202]\n",
            "[Epoch 27/200] [Batch 215/938] [D loss: 0.310593] [G loss: 0.358650] [info loss: 1.487448]\n",
            "[Epoch 27/200] [Batch 216/938] [D loss: 0.281463] [G loss: 0.121914] [info loss: 1.489417]\n",
            "[Epoch 27/200] [Batch 217/938] [D loss: 0.385188] [G loss: 0.249484] [info loss: 1.496880]\n",
            "[Epoch 27/200] [Batch 218/938] [D loss: 0.250819] [G loss: 0.083700] [info loss: 1.469446]\n",
            "[Epoch 27/200] [Batch 219/938] [D loss: 0.298267] [G loss: 0.337136] [info loss: 1.495502]\n",
            "[Epoch 27/200] [Batch 220/938] [D loss: 0.331840] [G loss: 0.319498] [info loss: 1.472657]\n",
            "[Epoch 27/200] [Batch 221/938] [D loss: 0.233817] [G loss: 0.295225] [info loss: 1.474173]\n",
            "[Epoch 27/200] [Batch 222/938] [D loss: 0.114315] [G loss: 0.486493] [info loss: 1.503289]\n",
            "[Epoch 27/200] [Batch 223/938] [D loss: 0.155203] [G loss: 0.285391] [info loss: 1.472165]\n",
            "[Epoch 27/200] [Batch 224/938] [D loss: 0.153090] [G loss: 0.492902] [info loss: 1.487267]\n",
            "[Epoch 27/200] [Batch 225/938] [D loss: 0.264912] [G loss: 0.452618] [info loss: 1.477451]\n",
            "[Epoch 27/200] [Batch 226/938] [D loss: 0.223545] [G loss: 0.473277] [info loss: 1.479010]\n",
            "[Epoch 27/200] [Batch 227/938] [D loss: 0.189788] [G loss: 0.147373] [info loss: 1.471798]\n",
            "[Epoch 27/200] [Batch 228/938] [D loss: 0.308074] [G loss: 0.302769] [info loss: 1.474416]\n",
            "[Epoch 27/200] [Batch 229/938] [D loss: 0.266284] [G loss: 0.315738] [info loss: 1.471845]\n",
            "[Epoch 27/200] [Batch 230/938] [D loss: 0.169441] [G loss: 0.210115] [info loss: 1.474177]\n",
            "[Epoch 27/200] [Batch 231/938] [D loss: 0.254323] [G loss: 0.324518] [info loss: 1.468803]\n",
            "[Epoch 27/200] [Batch 232/938] [D loss: 0.161628] [G loss: 0.244211] [info loss: 1.488045]\n",
            "[Epoch 27/200] [Batch 233/938] [D loss: 0.293786] [G loss: 0.360840] [info loss: 1.470897]\n",
            "[Epoch 27/200] [Batch 234/938] [D loss: 0.165769] [G loss: 0.345439] [info loss: 1.519133]\n",
            "[Epoch 27/200] [Batch 235/938] [D loss: 0.150725] [G loss: 0.278715] [info loss: 1.487004]\n",
            "[Epoch 27/200] [Batch 236/938] [D loss: 0.207917] [G loss: 0.316974] [info loss: 1.470396]\n",
            "[Epoch 27/200] [Batch 237/938] [D loss: 0.192388] [G loss: 0.288821] [info loss: 1.477099]\n",
            "[Epoch 27/200] [Batch 238/938] [D loss: 0.269616] [G loss: 0.357234] [info loss: 1.503018]\n",
            "[Epoch 27/200] [Batch 239/938] [D loss: 0.155138] [G loss: 0.303955] [info loss: 1.491783]\n",
            "[Epoch 27/200] [Batch 240/938] [D loss: 0.173164] [G loss: 0.182517] [info loss: 1.487341]\n",
            "[Epoch 27/200] [Batch 241/938] [D loss: 0.386206] [G loss: 0.216332] [info loss: 1.473897]\n",
            "[Epoch 27/200] [Batch 242/938] [D loss: 0.290236] [G loss: 0.224121] [info loss: 1.485615]\n",
            "[Epoch 27/200] [Batch 243/938] [D loss: 0.144788] [G loss: 0.283463] [info loss: 1.469345]\n",
            "[Epoch 27/200] [Batch 244/938] [D loss: 0.166847] [G loss: 0.360008] [info loss: 1.473510]\n",
            "[Epoch 27/200] [Batch 245/938] [D loss: 0.294782] [G loss: 0.565332] [info loss: 1.484130]\n",
            "[Epoch 27/200] [Batch 246/938] [D loss: 0.320383] [G loss: 0.203421] [info loss: 1.475681]\n",
            "[Epoch 27/200] [Batch 247/938] [D loss: 0.174733] [G loss: 0.295483] [info loss: 1.471266]\n",
            "[Epoch 27/200] [Batch 248/938] [D loss: 0.249877] [G loss: 0.138832] [info loss: 1.477283]\n",
            "[Epoch 27/200] [Batch 249/938] [D loss: 0.194080] [G loss: 0.347818] [info loss: 1.481742]\n",
            "[Epoch 27/200] [Batch 250/938] [D loss: 0.269770] [G loss: 0.469564] [info loss: 1.481400]\n",
            "[Epoch 27/200] [Batch 251/938] [D loss: 0.202810] [G loss: 0.430986] [info loss: 1.485545]\n",
            "[Epoch 27/200] [Batch 252/938] [D loss: 0.255108] [G loss: 0.188855] [info loss: 1.485326]\n",
            "[Epoch 27/200] [Batch 253/938] [D loss: 0.240782] [G loss: 0.274294] [info loss: 1.472470]\n",
            "[Epoch 27/200] [Batch 254/938] [D loss: 0.252124] [G loss: 0.225092] [info loss: 1.483858]\n",
            "[Epoch 27/200] [Batch 255/938] [D loss: 0.240729] [G loss: 0.188003] [info loss: 1.496158]\n",
            "[Epoch 27/200] [Batch 256/938] [D loss: 0.146533] [G loss: 0.332315] [info loss: 1.482938]\n",
            "[Epoch 27/200] [Batch 257/938] [D loss: 0.252238] [G loss: 0.248257] [info loss: 1.468010]\n",
            "[Epoch 27/200] [Batch 258/938] [D loss: 0.186295] [G loss: 0.595239] [info loss: 1.475708]\n",
            "[Epoch 27/200] [Batch 259/938] [D loss: 0.238497] [G loss: 0.279228] [info loss: 1.516873]\n",
            "[Epoch 27/200] [Batch 260/938] [D loss: 0.153940] [G loss: 0.406342] [info loss: 1.470384]\n",
            "[Epoch 27/200] [Batch 261/938] [D loss: 0.199811] [G loss: 0.425572] [info loss: 1.499281]\n",
            "[Epoch 27/200] [Batch 262/938] [D loss: 0.140244] [G loss: 0.368420] [info loss: 1.487520]\n",
            "[Epoch 27/200] [Batch 263/938] [D loss: 0.266967] [G loss: 0.219417] [info loss: 1.471235]\n",
            "[Epoch 27/200] [Batch 264/938] [D loss: 0.182550] [G loss: 0.243390] [info loss: 1.505462]\n",
            "[Epoch 27/200] [Batch 265/938] [D loss: 0.337027] [G loss: 0.204595] [info loss: 1.470616]\n",
            "[Epoch 27/200] [Batch 266/938] [D loss: 0.176986] [G loss: 0.410781] [info loss: 1.472715]\n",
            "[Epoch 27/200] [Batch 267/938] [D loss: 0.192345] [G loss: 0.457831] [info loss: 1.483782]\n",
            "[Epoch 27/200] [Batch 268/938] [D loss: 0.241426] [G loss: 0.748496] [info loss: 1.474408]\n",
            "[Epoch 27/200] [Batch 269/938] [D loss: 0.198054] [G loss: 0.295276] [info loss: 1.470584]\n",
            "[Epoch 27/200] [Batch 270/938] [D loss: 0.212504] [G loss: 0.328980] [info loss: 1.469735]\n",
            "[Epoch 27/200] [Batch 271/938] [D loss: 0.214206] [G loss: 0.292757] [info loss: 1.488215]\n",
            "[Epoch 27/200] [Batch 272/938] [D loss: 0.275108] [G loss: 0.299379] [info loss: 1.469175]\n",
            "[Epoch 27/200] [Batch 273/938] [D loss: 0.164944] [G loss: 0.189066] [info loss: 1.474439]\n",
            "[Epoch 27/200] [Batch 274/938] [D loss: 0.260769] [G loss: 0.287781] [info loss: 1.490077]\n",
            "[Epoch 27/200] [Batch 275/938] [D loss: 0.248155] [G loss: 0.243229] [info loss: 1.473467]\n",
            "[Epoch 27/200] [Batch 276/938] [D loss: 0.245315] [G loss: 0.201807] [info loss: 1.473991]\n",
            "[Epoch 27/200] [Batch 277/938] [D loss: 0.306816] [G loss: 0.406907] [info loss: 1.490687]\n",
            "[Epoch 27/200] [Batch 278/938] [D loss: 0.195340] [G loss: 0.590780] [info loss: 1.483790]\n",
            "[Epoch 27/200] [Batch 279/938] [D loss: 0.228733] [G loss: 0.384641] [info loss: 1.471024]\n",
            "[Epoch 27/200] [Batch 280/938] [D loss: 0.275428] [G loss: 0.194673] [info loss: 1.485581]\n",
            "[Epoch 27/200] [Batch 281/938] [D loss: 0.161413] [G loss: 0.198300] [info loss: 1.471831]\n",
            "[Epoch 27/200] [Batch 282/938] [D loss: 0.209636] [G loss: 0.265344] [info loss: 1.486909]\n",
            "[Epoch 27/200] [Batch 283/938] [D loss: 0.278905] [G loss: 0.319479] [info loss: 1.470726]\n",
            "[Epoch 27/200] [Batch 284/938] [D loss: 0.163167] [G loss: 0.323542] [info loss: 1.487229]\n",
            "[Epoch 27/200] [Batch 285/938] [D loss: 0.199048] [G loss: 0.253964] [info loss: 1.472960]\n",
            "[Epoch 27/200] [Batch 286/938] [D loss: 0.171121] [G loss: 0.224814] [info loss: 1.488272]\n",
            "[Epoch 27/200] [Batch 287/938] [D loss: 0.229060] [G loss: 0.315523] [info loss: 1.470097]\n",
            "[Epoch 27/200] [Batch 288/938] [D loss: 0.198302] [G loss: 0.340345] [info loss: 1.501634]\n",
            "[Epoch 27/200] [Batch 289/938] [D loss: 0.310593] [G loss: 0.412493] [info loss: 1.468411]\n",
            "[Epoch 27/200] [Batch 290/938] [D loss: 0.175885] [G loss: 0.390386] [info loss: 1.472823]\n",
            "[Epoch 27/200] [Batch 291/938] [D loss: 0.293489] [G loss: 0.240376] [info loss: 1.485379]\n",
            "[Epoch 27/200] [Batch 292/938] [D loss: 0.209020] [G loss: 0.237907] [info loss: 1.470685]\n",
            "[Epoch 27/200] [Batch 293/938] [D loss: 0.342613] [G loss: 0.236838] [info loss: 1.481812]\n",
            "[Epoch 27/200] [Batch 294/938] [D loss: 0.176441] [G loss: 0.203893] [info loss: 1.485223]\n",
            "[Epoch 27/200] [Batch 295/938] [D loss: 0.183805] [G loss: 0.623138] [info loss: 1.473586]\n",
            "[Epoch 27/200] [Batch 296/938] [D loss: 0.214991] [G loss: 0.763332] [info loss: 1.479961]\n",
            "[Epoch 27/200] [Batch 297/938] [D loss: 0.248617] [G loss: 0.618008] [info loss: 1.484151]\n",
            "[Epoch 27/200] [Batch 298/938] [D loss: 0.226646] [G loss: 0.359572] [info loss: 1.470917]\n",
            "[Epoch 27/200] [Batch 299/938] [D loss: 0.158565] [G loss: 0.304352] [info loss: 1.486794]\n",
            "[Epoch 27/200] [Batch 300/938] [D loss: 0.187714] [G loss: 0.146220] [info loss: 1.490349]\n",
            "[Epoch 27/200] [Batch 301/938] [D loss: 0.229788] [G loss: 0.163581] [info loss: 1.471225]\n",
            "[Epoch 27/200] [Batch 302/938] [D loss: 0.232119] [G loss: 0.449118] [info loss: 1.471468]\n",
            "[Epoch 27/200] [Batch 303/938] [D loss: 0.258300] [G loss: 0.425762] [info loss: 1.472657]\n",
            "[Epoch 27/200] [Batch 304/938] [D loss: 0.281034] [G loss: 0.455030] [info loss: 1.473480]\n",
            "[Epoch 27/200] [Batch 305/938] [D loss: 0.178997] [G loss: 0.202385] [info loss: 1.484130]\n",
            "[Epoch 27/200] [Batch 306/938] [D loss: 0.228387] [G loss: 0.122806] [info loss: 1.486326]\n",
            "[Epoch 27/200] [Batch 307/938] [D loss: 0.160043] [G loss: 0.370403] [info loss: 1.469559]\n",
            "[Epoch 27/200] [Batch 308/938] [D loss: 0.196782] [G loss: 0.243968] [info loss: 1.471372]\n",
            "[Epoch 27/200] [Batch 309/938] [D loss: 0.172290] [G loss: 0.237741] [info loss: 1.486124]\n",
            "[Epoch 27/200] [Batch 310/938] [D loss: 0.188916] [G loss: 0.251747] [info loss: 1.470542]\n",
            "[Epoch 27/200] [Batch 311/938] [D loss: 0.186269] [G loss: 0.273374] [info loss: 1.483069]\n",
            "[Epoch 27/200] [Batch 312/938] [D loss: 0.193568] [G loss: 0.261187] [info loss: 1.486177]\n",
            "[Epoch 27/200] [Batch 313/938] [D loss: 0.186784] [G loss: 0.438595] [info loss: 1.469131]\n",
            "[Epoch 27/200] [Batch 314/938] [D loss: 0.248982] [G loss: 0.266293] [info loss: 1.471268]\n",
            "[Epoch 27/200] [Batch 315/938] [D loss: 0.167343] [G loss: 0.393603] [info loss: 1.474548]\n",
            "[Epoch 27/200] [Batch 316/938] [D loss: 0.281590] [G loss: 0.491895] [info loss: 1.493970]\n",
            "[Epoch 27/200] [Batch 317/938] [D loss: 0.172095] [G loss: 0.571436] [info loss: 1.473071]\n",
            "[Epoch 27/200] [Batch 318/938] [D loss: 0.253260] [G loss: 0.275891] [info loss: 1.475403]\n",
            "[Epoch 27/200] [Batch 319/938] [D loss: 0.280865] [G loss: 0.079288] [info loss: 1.484155]\n",
            "[Epoch 27/200] [Batch 320/938] [D loss: 0.133714] [G loss: 0.452160] [info loss: 1.500356]\n",
            "[Epoch 27/200] [Batch 321/938] [D loss: 0.216309] [G loss: 0.456973] [info loss: 1.483624]\n",
            "[Epoch 27/200] [Batch 322/938] [D loss: 0.156818] [G loss: 0.309686] [info loss: 1.468947]\n",
            "[Epoch 27/200] [Batch 323/938] [D loss: 0.213547] [G loss: 0.209735] [info loss: 1.484741]\n",
            "[Epoch 27/200] [Batch 324/938] [D loss: 0.220035] [G loss: 0.253490] [info loss: 1.472206]\n",
            "[Epoch 27/200] [Batch 325/938] [D loss: 0.173806] [G loss: 0.205035] [info loss: 1.491202]\n",
            "[Epoch 27/200] [Batch 326/938] [D loss: 0.152704] [G loss: 0.573669] [info loss: 1.491876]\n",
            "[Epoch 27/200] [Batch 327/938] [D loss: 0.196703] [G loss: 0.414072] [info loss: 1.470452]\n",
            "[Epoch 27/200] [Batch 328/938] [D loss: 0.187580] [G loss: 0.377465] [info loss: 1.498733]\n",
            "[Epoch 27/200] [Batch 329/938] [D loss: 0.193658] [G loss: 0.409584] [info loss: 1.483882]\n",
            "[Epoch 27/200] [Batch 330/938] [D loss: 0.295953] [G loss: 0.411628] [info loss: 1.473684]\n",
            "[Epoch 27/200] [Batch 331/938] [D loss: 0.211784] [G loss: 0.363697] [info loss: 1.470589]\n",
            "[Epoch 27/200] [Batch 332/938] [D loss: 0.303889] [G loss: 0.387618] [info loss: 1.478263]\n",
            "[Epoch 27/200] [Batch 333/938] [D loss: 0.095631] [G loss: 0.334883] [info loss: 1.488145]\n",
            "[Epoch 27/200] [Batch 334/938] [D loss: 0.250344] [G loss: 0.480393] [info loss: 1.474427]\n",
            "[Epoch 27/200] [Batch 335/938] [D loss: 0.160766] [G loss: 0.395757] [info loss: 1.483103]\n",
            "[Epoch 27/200] [Batch 336/938] [D loss: 0.299120] [G loss: 0.473724] [info loss: 1.489094]\n",
            "[Epoch 27/200] [Batch 337/938] [D loss: 0.184067] [G loss: 0.473299] [info loss: 1.471780]\n",
            "[Epoch 27/200] [Batch 338/938] [D loss: 0.178670] [G loss: 0.370599] [info loss: 1.481980]\n",
            "[Epoch 27/200] [Batch 339/938] [D loss: 0.176381] [G loss: 0.375539] [info loss: 1.470742]\n",
            "[Epoch 27/200] [Batch 340/938] [D loss: 0.222918] [G loss: 0.270449] [info loss: 1.472175]\n",
            "[Epoch 27/200] [Batch 341/938] [D loss: 0.182440] [G loss: 0.329694] [info loss: 1.470621]\n",
            "[Epoch 27/200] [Batch 342/938] [D loss: 0.166061] [G loss: 0.360973] [info loss: 1.470397]\n",
            "[Epoch 27/200] [Batch 343/938] [D loss: 0.251299] [G loss: 0.445554] [info loss: 1.492912]\n",
            "[Epoch 27/200] [Batch 344/938] [D loss: 0.268917] [G loss: 0.198546] [info loss: 1.481719]\n",
            "[Epoch 27/200] [Batch 345/938] [D loss: 0.185089] [G loss: 0.218982] [info loss: 1.473407]\n",
            "[Epoch 27/200] [Batch 346/938] [D loss: 0.348894] [G loss: 0.351796] [info loss: 1.473059]\n",
            "[Epoch 27/200] [Batch 347/938] [D loss: 0.200850] [G loss: 0.188329] [info loss: 1.473193]\n",
            "[Epoch 27/200] [Batch 348/938] [D loss: 0.178186] [G loss: 0.180614] [info loss: 1.470950]\n",
            "[Epoch 27/200] [Batch 349/938] [D loss: 0.192195] [G loss: 0.239996] [info loss: 1.497302]\n",
            "[Epoch 27/200] [Batch 350/938] [D loss: 0.234853] [G loss: 0.285635] [info loss: 1.470061]\n",
            "[Epoch 27/200] [Batch 351/938] [D loss: 0.142198] [G loss: 0.300395] [info loss: 1.494226]\n",
            "[Epoch 27/200] [Batch 352/938] [D loss: 0.280581] [G loss: 0.405944] [info loss: 1.489152]\n",
            "[Epoch 27/200] [Batch 353/938] [D loss: 0.262906] [G loss: 0.272766] [info loss: 1.472123]\n",
            "[Epoch 27/200] [Batch 354/938] [D loss: 0.207327] [G loss: 0.485037] [info loss: 1.479630]\n",
            "[Epoch 27/200] [Batch 355/938] [D loss: 0.273583] [G loss: 0.254283] [info loss: 1.469731]\n",
            "[Epoch 27/200] [Batch 356/938] [D loss: 0.226464] [G loss: 0.210010] [info loss: 1.488232]\n",
            "[Epoch 27/200] [Batch 357/938] [D loss: 0.146280] [G loss: 0.415796] [info loss: 1.470101]\n",
            "[Epoch 27/200] [Batch 358/938] [D loss: 0.246627] [G loss: 0.293747] [info loss: 1.470061]\n",
            "[Epoch 27/200] [Batch 359/938] [D loss: 0.226349] [G loss: 0.535134] [info loss: 1.485799]\n",
            "[Epoch 27/200] [Batch 360/938] [D loss: 0.204206] [G loss: 0.272657] [info loss: 1.475277]\n",
            "[Epoch 27/200] [Batch 361/938] [D loss: 0.149128] [G loss: 0.355450] [info loss: 1.498022]\n",
            "[Epoch 27/200] [Batch 362/938] [D loss: 0.131388] [G loss: 0.301485] [info loss: 1.484180]\n",
            "[Epoch 27/200] [Batch 363/938] [D loss: 0.223731] [G loss: 0.330406] [info loss: 1.470835]\n",
            "[Epoch 27/200] [Batch 364/938] [D loss: 0.184028] [G loss: 0.423132] [info loss: 1.486782]\n",
            "[Epoch 27/200] [Batch 365/938] [D loss: 0.361382] [G loss: 0.346309] [info loss: 1.473469]\n",
            "[Epoch 27/200] [Batch 366/938] [D loss: 0.215527] [G loss: 0.364099] [info loss: 1.473739]\n",
            "[Epoch 27/200] [Batch 367/938] [D loss: 0.111913] [G loss: 0.373948] [info loss: 1.480405]\n",
            "[Epoch 27/200] [Batch 368/938] [D loss: 0.206268] [G loss: 0.361699] [info loss: 1.480844]\n",
            "[Epoch 27/200] [Batch 369/938] [D loss: 0.375062] [G loss: 0.347343] [info loss: 1.484431]\n",
            "[Epoch 27/200] [Batch 370/938] [D loss: 0.215382] [G loss: 0.178486] [info loss: 1.514802]\n",
            "[Epoch 27/200] [Batch 371/938] [D loss: 0.141957] [G loss: 0.228165] [info loss: 1.482553]\n",
            "[Epoch 27/200] [Batch 372/938] [D loss: 0.148064] [G loss: 0.333107] [info loss: 1.483971]\n",
            "[Epoch 27/200] [Batch 373/938] [D loss: 0.178878] [G loss: 0.197417] [info loss: 1.487513]\n",
            "[Epoch 27/200] [Batch 374/938] [D loss: 0.169415] [G loss: 0.405385] [info loss: 1.484618]\n",
            "[Epoch 27/200] [Batch 375/938] [D loss: 0.278134] [G loss: 0.307251] [info loss: 1.469237]\n",
            "[Epoch 27/200] [Batch 376/938] [D loss: 0.198844] [G loss: 0.200872] [info loss: 1.471137]\n",
            "[Epoch 27/200] [Batch 377/938] [D loss: 0.234086] [G loss: 0.273238] [info loss: 1.479016]\n",
            "[Epoch 27/200] [Batch 378/938] [D loss: 0.168334] [G loss: 0.680894] [info loss: 1.482767]\n",
            "[Epoch 27/200] [Batch 379/938] [D loss: 0.197030] [G loss: 0.337473] [info loss: 1.471475]\n",
            "[Epoch 27/200] [Batch 380/938] [D loss: 0.153848] [G loss: 0.400110] [info loss: 1.470650]\n",
            "[Epoch 27/200] [Batch 381/938] [D loss: 0.341934] [G loss: 0.314338] [info loss: 1.488833]\n",
            "[Epoch 27/200] [Batch 382/938] [D loss: 0.355685] [G loss: 0.543166] [info loss: 1.472362]\n",
            "[Epoch 27/200] [Batch 383/938] [D loss: 0.083182] [G loss: 0.402364] [info loss: 1.473508]\n",
            "[Epoch 27/200] [Batch 384/938] [D loss: 0.225530] [G loss: 0.244200] [info loss: 1.488779]\n",
            "[Epoch 27/200] [Batch 385/938] [D loss: 0.244908] [G loss: 0.223398] [info loss: 1.468559]\n",
            "[Epoch 27/200] [Batch 386/938] [D loss: 0.235843] [G loss: 0.278193] [info loss: 1.495298]\n",
            "[Epoch 27/200] [Batch 387/938] [D loss: 0.196296] [G loss: 0.395890] [info loss: 1.489839]\n",
            "[Epoch 27/200] [Batch 388/938] [D loss: 0.303210] [G loss: 0.439231] [info loss: 1.477761]\n",
            "[Epoch 27/200] [Batch 389/938] [D loss: 0.205734] [G loss: 0.261665] [info loss: 1.487591]\n",
            "[Epoch 27/200] [Batch 390/938] [D loss: 0.084060] [G loss: 0.381135] [info loss: 1.471712]\n",
            "[Epoch 27/200] [Batch 391/938] [D loss: 0.321157] [G loss: 0.390230] [info loss: 1.498061]\n",
            "[Epoch 27/200] [Batch 392/938] [D loss: 0.206855] [G loss: 0.276960] [info loss: 1.474227]\n",
            "[Epoch 27/200] [Batch 393/938] [D loss: 0.189967] [G loss: 0.380098] [info loss: 1.485285]\n",
            "[Epoch 27/200] [Batch 394/938] [D loss: 0.100870] [G loss: 0.309984] [info loss: 1.470141]\n",
            "[Epoch 27/200] [Batch 395/938] [D loss: 0.221228] [G loss: 0.269609] [info loss: 1.471572]\n",
            "[Epoch 27/200] [Batch 396/938] [D loss: 0.309042] [G loss: 0.136604] [info loss: 1.473711]\n",
            "[Epoch 27/200] [Batch 397/938] [D loss: 0.275470] [G loss: 0.358204] [info loss: 1.476196]\n",
            "[Epoch 27/200] [Batch 398/938] [D loss: 0.162716] [G loss: 0.323503] [info loss: 1.483517]\n",
            "[Epoch 27/200] [Batch 399/938] [D loss: 0.242718] [G loss: 0.336083] [info loss: 1.468635]\n",
            "[Epoch 27/200] [Batch 400/938] [D loss: 0.109594] [G loss: 0.408514] [info loss: 1.470947]\n",
            "[Epoch 27/200] [Batch 401/938] [D loss: 0.153391] [G loss: 0.262945] [info loss: 1.471002]\n",
            "[Epoch 27/200] [Batch 402/938] [D loss: 0.124952] [G loss: 0.371632] [info loss: 1.470958]\n",
            "[Epoch 27/200] [Batch 403/938] [D loss: 0.203742] [G loss: 0.404177] [info loss: 1.487341]\n",
            "[Epoch 27/200] [Batch 404/938] [D loss: 0.188370] [G loss: 0.295252] [info loss: 1.474900]\n",
            "[Epoch 27/200] [Batch 405/938] [D loss: 0.143324] [G loss: 0.309528] [info loss: 1.472445]\n",
            "[Epoch 27/200] [Batch 406/938] [D loss: 0.225124] [G loss: 0.371549] [info loss: 1.473205]\n",
            "[Epoch 27/200] [Batch 407/938] [D loss: 0.241855] [G loss: 0.361738] [info loss: 1.493783]\n",
            "[Epoch 27/200] [Batch 408/938] [D loss: 0.183679] [G loss: 0.293036] [info loss: 1.471291]\n",
            "[Epoch 27/200] [Batch 409/938] [D loss: 0.195431] [G loss: 0.462920] [info loss: 1.486516]\n",
            "[Epoch 27/200] [Batch 410/938] [D loss: 0.218692] [G loss: 0.199313] [info loss: 1.472030]\n",
            "[Epoch 27/200] [Batch 411/938] [D loss: 0.196213] [G loss: 0.377839] [info loss: 1.489195]\n",
            "[Epoch 27/200] [Batch 412/938] [D loss: 0.230405] [G loss: 0.356295] [info loss: 1.473362]\n",
            "[Epoch 27/200] [Batch 413/938] [D loss: 0.196005] [G loss: 0.507895] [info loss: 1.495908]\n",
            "[Epoch 27/200] [Batch 414/938] [D loss: 0.238411] [G loss: 0.385910] [info loss: 1.495603]\n",
            "[Epoch 27/200] [Batch 415/938] [D loss: 0.278718] [G loss: 0.559072] [info loss: 1.470517]\n",
            "[Epoch 27/200] [Batch 416/938] [D loss: 0.264931] [G loss: 0.743504] [info loss: 1.471663]\n",
            "[Epoch 27/200] [Batch 417/938] [D loss: 0.277676] [G loss: 0.411111] [info loss: 1.482704]\n",
            "[Epoch 27/200] [Batch 418/938] [D loss: 0.244166] [G loss: 0.298926] [info loss: 1.474500]\n",
            "[Epoch 27/200] [Batch 419/938] [D loss: 0.160886] [G loss: 0.471093] [info loss: 1.472188]\n",
            "[Epoch 27/200] [Batch 420/938] [D loss: 0.259584] [G loss: 0.550767] [info loss: 1.485681]\n",
            "[Epoch 27/200] [Batch 421/938] [D loss: 0.296785] [G loss: 0.418210] [info loss: 1.472282]\n",
            "[Epoch 27/200] [Batch 422/938] [D loss: 0.092436] [G loss: 0.261128] [info loss: 1.469830]\n",
            "[Epoch 27/200] [Batch 423/938] [D loss: 0.233350] [G loss: 0.190450] [info loss: 1.470763]\n",
            "[Epoch 27/200] [Batch 424/938] [D loss: 0.221435] [G loss: 0.175633] [info loss: 1.474813]\n",
            "[Epoch 27/200] [Batch 425/938] [D loss: 0.243424] [G loss: 0.372274] [info loss: 1.486373]\n",
            "[Epoch 27/200] [Batch 426/938] [D loss: 0.129133] [G loss: 0.496679] [info loss: 1.470098]\n",
            "[Epoch 27/200] [Batch 427/938] [D loss: 0.162667] [G loss: 0.564349] [info loss: 1.500724]\n",
            "[Epoch 27/200] [Batch 428/938] [D loss: 0.188976] [G loss: 0.337449] [info loss: 1.484642]\n",
            "[Epoch 27/200] [Batch 429/938] [D loss: 0.155216] [G loss: 0.276274] [info loss: 1.486547]\n",
            "[Epoch 27/200] [Batch 430/938] [D loss: 0.302127] [G loss: 0.261758] [info loss: 1.469904]\n",
            "[Epoch 27/200] [Batch 431/938] [D loss: 0.200155] [G loss: 0.535867] [info loss: 1.479595]\n",
            "[Epoch 27/200] [Batch 432/938] [D loss: 0.212275] [G loss: 0.377993] [info loss: 1.486412]\n",
            "[Epoch 27/200] [Batch 433/938] [D loss: 0.231026] [G loss: 0.543367] [info loss: 1.482214]\n",
            "[Epoch 27/200] [Batch 434/938] [D loss: 0.210499] [G loss: 0.190332] [info loss: 1.484711]\n",
            "[Epoch 27/200] [Batch 435/938] [D loss: 0.191925] [G loss: 0.235810] [info loss: 1.474264]\n",
            "[Epoch 27/200] [Batch 436/938] [D loss: 0.190500] [G loss: 0.343621] [info loss: 1.490690]\n",
            "[Epoch 27/200] [Batch 437/938] [D loss: 0.294769] [G loss: 0.283290] [info loss: 1.517604]\n",
            "[Epoch 27/200] [Batch 438/938] [D loss: 0.281585] [G loss: 0.326798] [info loss: 1.487197]\n",
            "[Epoch 27/200] [Batch 439/938] [D loss: 0.263327] [G loss: 0.124777] [info loss: 1.471722]\n",
            "[Epoch 27/200] [Batch 440/938] [D loss: 0.235107] [G loss: 0.386626] [info loss: 1.472116]\n",
            "[Epoch 27/200] [Batch 441/938] [D loss: 0.252841] [G loss: 0.404751] [info loss: 1.469827]\n",
            "[Epoch 27/200] [Batch 442/938] [D loss: 0.285236] [G loss: 0.260943] [info loss: 1.492817]\n",
            "[Epoch 27/200] [Batch 443/938] [D loss: 0.261042] [G loss: 0.429531] [info loss: 1.484383]\n",
            "[Epoch 27/200] [Batch 444/938] [D loss: 0.126253] [G loss: 0.433358] [info loss: 1.478784]\n",
            "[Epoch 27/200] [Batch 445/938] [D loss: 0.194265] [G loss: 0.374580] [info loss: 1.483811]\n",
            "[Epoch 27/200] [Batch 446/938] [D loss: 0.266184] [G loss: 0.376439] [info loss: 1.482704]\n",
            "[Epoch 27/200] [Batch 447/938] [D loss: 0.250244] [G loss: 0.132556] [info loss: 1.488337]\n",
            "[Epoch 27/200] [Batch 448/938] [D loss: 0.264581] [G loss: 0.333671] [info loss: 1.480855]\n",
            "[Epoch 27/200] [Batch 449/938] [D loss: 0.279133] [G loss: 0.362221] [info loss: 1.497195]\n",
            "[Epoch 27/200] [Batch 450/938] [D loss: 0.220138] [G loss: 0.152206] [info loss: 1.482506]\n",
            "[Epoch 27/200] [Batch 451/938] [D loss: 0.190931] [G loss: 0.217782] [info loss: 1.469366]\n",
            "[Epoch 27/200] [Batch 452/938] [D loss: 0.157659] [G loss: 0.230062] [info loss: 1.472964]\n",
            "[Epoch 27/200] [Batch 453/938] [D loss: 0.184120] [G loss: 0.356756] [info loss: 1.468454]\n",
            "[Epoch 27/200] [Batch 454/938] [D loss: 0.231389] [G loss: 0.300961] [info loss: 1.482193]\n",
            "[Epoch 27/200] [Batch 455/938] [D loss: 0.179636] [G loss: 0.268757] [info loss: 1.479688]\n",
            "[Epoch 27/200] [Batch 456/938] [D loss: 0.287939] [G loss: 0.332705] [info loss: 1.491984]\n",
            "[Epoch 27/200] [Batch 457/938] [D loss: 0.203138] [G loss: 0.289980] [info loss: 1.474370]\n",
            "[Epoch 27/200] [Batch 458/938] [D loss: 0.240093] [G loss: 0.354986] [info loss: 1.472698]\n",
            "[Epoch 27/200] [Batch 459/938] [D loss: 0.304572] [G loss: 0.269360] [info loss: 1.470645]\n",
            "[Epoch 27/200] [Batch 460/938] [D loss: 0.227537] [G loss: 0.360915] [info loss: 1.505146]\n",
            "[Epoch 27/200] [Batch 461/938] [D loss: 0.282663] [G loss: 0.318074] [info loss: 1.484496]\n",
            "[Epoch 27/200] [Batch 462/938] [D loss: 0.213200] [G loss: 0.261986] [info loss: 1.486664]\n",
            "[Epoch 27/200] [Batch 463/938] [D loss: 0.240401] [G loss: 0.206621] [info loss: 1.470996]\n",
            "[Epoch 27/200] [Batch 464/938] [D loss: 0.213291] [G loss: 0.244494] [info loss: 1.487888]\n",
            "[Epoch 27/200] [Batch 465/938] [D loss: 0.190197] [G loss: 0.312568] [info loss: 1.486893]\n",
            "[Epoch 27/200] [Batch 466/938] [D loss: 0.198126] [G loss: 0.315732] [info loss: 1.484869]\n",
            "[Epoch 27/200] [Batch 467/938] [D loss: 0.131275] [G loss: 0.521372] [info loss: 1.471389]\n",
            "[Epoch 27/200] [Batch 468/938] [D loss: 0.220912] [G loss: 0.371946] [info loss: 1.474814]\n",
            "[Epoch 27/200] [Batch 469/938] [D loss: 0.179715] [G loss: 0.284576] [info loss: 1.489657]\n",
            "[Epoch 27/200] [Batch 470/938] [D loss: 0.240668] [G loss: 0.309616] [info loss: 1.486053]\n",
            "[Epoch 27/200] [Batch 471/938] [D loss: 0.197837] [G loss: 0.211965] [info loss: 1.470304]\n",
            "[Epoch 27/200] [Batch 472/938] [D loss: 0.177453] [G loss: 0.372454] [info loss: 1.474635]\n",
            "[Epoch 27/200] [Batch 473/938] [D loss: 0.242347] [G loss: 0.284084] [info loss: 1.468780]\n",
            "[Epoch 27/200] [Batch 474/938] [D loss: 0.236650] [G loss: 0.404245] [info loss: 1.487951]\n",
            "[Epoch 27/200] [Batch 475/938] [D loss: 0.257065] [G loss: 0.421885] [info loss: 1.485187]\n",
            "[Epoch 27/200] [Batch 476/938] [D loss: 0.182337] [G loss: 0.267466] [info loss: 1.506971]\n",
            "[Epoch 27/200] [Batch 477/938] [D loss: 0.262292] [G loss: 0.210995] [info loss: 1.469798]\n",
            "[Epoch 27/200] [Batch 478/938] [D loss: 0.140713] [G loss: 0.193315] [info loss: 1.474790]\n",
            "[Epoch 27/200] [Batch 479/938] [D loss: 0.200900] [G loss: 0.235007] [info loss: 1.471807]\n",
            "[Epoch 27/200] [Batch 480/938] [D loss: 0.227169] [G loss: 0.106757] [info loss: 1.473484]\n",
            "[Epoch 27/200] [Batch 481/938] [D loss: 0.211240] [G loss: 0.158960] [info loss: 1.472764]\n",
            "[Epoch 27/200] [Batch 482/938] [D loss: 0.323947] [G loss: 0.270991] [info loss: 1.486390]\n",
            "[Epoch 27/200] [Batch 483/938] [D loss: 0.132094] [G loss: 0.568882] [info loss: 1.502620]\n",
            "[Epoch 27/200] [Batch 484/938] [D loss: 0.359960] [G loss: 0.522937] [info loss: 1.476447]\n",
            "[Epoch 27/200] [Batch 485/938] [D loss: 0.314306] [G loss: 0.252688] [info loss: 1.485750]\n",
            "[Epoch 27/200] [Batch 486/938] [D loss: 0.210022] [G loss: 0.151543] [info loss: 1.483350]\n",
            "[Epoch 27/200] [Batch 487/938] [D loss: 0.168475] [G loss: 0.168114] [info loss: 1.470716]\n",
            "[Epoch 27/200] [Batch 488/938] [D loss: 0.257717] [G loss: 0.283602] [info loss: 1.485018]\n",
            "[Epoch 27/200] [Batch 489/938] [D loss: 0.353515] [G loss: 0.239305] [info loss: 1.487108]\n",
            "[Epoch 27/200] [Batch 490/938] [D loss: 0.271341] [G loss: 0.370665] [info loss: 1.487852]\n",
            "[Epoch 27/200] [Batch 491/938] [D loss: 0.163115] [G loss: 0.565047] [info loss: 1.472661]\n",
            "[Epoch 27/200] [Batch 492/938] [D loss: 0.205678] [G loss: 0.218935] [info loss: 1.492899]\n",
            "[Epoch 27/200] [Batch 493/938] [D loss: 0.297255] [G loss: 0.202362] [info loss: 1.481681]\n",
            "[Epoch 27/200] [Batch 494/938] [D loss: 0.203225] [G loss: 0.203322] [info loss: 1.473193]\n",
            "[Epoch 27/200] [Batch 495/938] [D loss: 0.229321] [G loss: 0.291399] [info loss: 1.473796]\n",
            "[Epoch 27/200] [Batch 496/938] [D loss: 0.265833] [G loss: 0.489993] [info loss: 1.501929]\n",
            "[Epoch 27/200] [Batch 497/938] [D loss: 0.204495] [G loss: 0.544929] [info loss: 1.488983]\n",
            "[Epoch 27/200] [Batch 498/938] [D loss: 0.194006] [G loss: 0.246856] [info loss: 1.487923]\n",
            "[Epoch 27/200] [Batch 499/938] [D loss: 0.181540] [G loss: 0.258308] [info loss: 1.481696]\n",
            "[Epoch 27/200] [Batch 500/938] [D loss: 0.138217] [G loss: 0.479818] [info loss: 1.472686]\n",
            "[Epoch 27/200] [Batch 501/938] [D loss: 0.165983] [G loss: 0.397925] [info loss: 1.484220]\n",
            "[Epoch 27/200] [Batch 502/938] [D loss: 0.292832] [G loss: 0.164612] [info loss: 1.471999]\n",
            "[Epoch 27/200] [Batch 503/938] [D loss: 0.227703] [G loss: 0.185582] [info loss: 1.469276]\n",
            "[Epoch 27/200] [Batch 504/938] [D loss: 0.354655] [G loss: 0.089593] [info loss: 1.484370]\n",
            "[Epoch 27/200] [Batch 505/938] [D loss: 0.283269] [G loss: 0.274512] [info loss: 1.481692]\n",
            "[Epoch 27/200] [Batch 506/938] [D loss: 0.323669] [G loss: 0.176959] [info loss: 1.474137]\n",
            "[Epoch 27/200] [Batch 507/938] [D loss: 0.237574] [G loss: 0.118890] [info loss: 1.503939]\n",
            "[Epoch 27/200] [Batch 508/938] [D loss: 0.230714] [G loss: 0.349885] [info loss: 1.469999]\n",
            "[Epoch 27/200] [Batch 509/938] [D loss: 0.263087] [G loss: 0.300145] [info loss: 1.506047]\n",
            "[Epoch 27/200] [Batch 510/938] [D loss: 0.240838] [G loss: 0.216140] [info loss: 1.471139]\n",
            "[Epoch 27/200] [Batch 511/938] [D loss: 0.203320] [G loss: 0.664672] [info loss: 1.474088]\n",
            "[Epoch 27/200] [Batch 512/938] [D loss: 0.204160] [G loss: 0.626416] [info loss: 1.470084]\n",
            "[Epoch 27/200] [Batch 513/938] [D loss: 0.211901] [G loss: 0.357900] [info loss: 1.483598]\n",
            "[Epoch 27/200] [Batch 514/938] [D loss: 0.125612] [G loss: 0.224728] [info loss: 1.487072]\n",
            "[Epoch 27/200] [Batch 515/938] [D loss: 0.208126] [G loss: 0.170314] [info loss: 1.484669]\n",
            "[Epoch 27/200] [Batch 516/938] [D loss: 0.186228] [G loss: 0.146809] [info loss: 1.490229]\n",
            "[Epoch 27/200] [Batch 517/938] [D loss: 0.210048] [G loss: 0.180612] [info loss: 1.491320]\n",
            "[Epoch 27/200] [Batch 518/938] [D loss: 0.248255] [G loss: 0.544834] [info loss: 1.472559]\n",
            "[Epoch 27/200] [Batch 519/938] [D loss: 0.240416] [G loss: 0.237562] [info loss: 1.469938]\n",
            "[Epoch 27/200] [Batch 520/938] [D loss: 0.179630] [G loss: 0.246563] [info loss: 1.482043]\n",
            "[Epoch 27/200] [Batch 521/938] [D loss: 0.186470] [G loss: 0.424714] [info loss: 1.471215]\n",
            "[Epoch 27/200] [Batch 522/938] [D loss: 0.277738] [G loss: 0.250266] [info loss: 1.484434]\n",
            "[Epoch 27/200] [Batch 523/938] [D loss: 0.269996] [G loss: 0.254554] [info loss: 1.472435]\n",
            "[Epoch 27/200] [Batch 524/938] [D loss: 0.181300] [G loss: 0.210109] [info loss: 1.482779]\n",
            "[Epoch 27/200] [Batch 525/938] [D loss: 0.245681] [G loss: 0.378959] [info loss: 1.471177]\n",
            "[Epoch 27/200] [Batch 526/938] [D loss: 0.257648] [G loss: 0.439421] [info loss: 1.498685]\n",
            "[Epoch 27/200] [Batch 527/938] [D loss: 0.151569] [G loss: 0.352302] [info loss: 1.486241]\n",
            "[Epoch 27/200] [Batch 528/938] [D loss: 0.214955] [G loss: 0.324324] [info loss: 1.480147]\n",
            "[Epoch 27/200] [Batch 529/938] [D loss: 0.174674] [G loss: 0.379304] [info loss: 1.470588]\n",
            "[Epoch 27/200] [Batch 530/938] [D loss: 0.363530] [G loss: 0.438499] [info loss: 1.469574]\n",
            "[Epoch 27/200] [Batch 531/938] [D loss: 0.186526] [G loss: 0.280546] [info loss: 1.471942]\n",
            "[Epoch 27/200] [Batch 532/938] [D loss: 0.223942] [G loss: 0.258473] [info loss: 1.478881]\n",
            "[Epoch 27/200] [Batch 533/938] [D loss: 0.179028] [G loss: 0.373745] [info loss: 1.472431]\n",
            "[Epoch 27/200] [Batch 534/938] [D loss: 0.229572] [G loss: 0.276103] [info loss: 1.482067]\n",
            "[Epoch 27/200] [Batch 535/938] [D loss: 0.294198] [G loss: 0.451228] [info loss: 1.507456]\n",
            "[Epoch 27/200] [Batch 536/938] [D loss: 0.164676] [G loss: 0.326147] [info loss: 1.488451]\n",
            "[Epoch 27/200] [Batch 537/938] [D loss: 0.165899] [G loss: 0.266532] [info loss: 1.476578]\n",
            "[Epoch 27/200] [Batch 538/938] [D loss: 0.272994] [G loss: 0.459822] [info loss: 1.471207]\n",
            "[Epoch 27/200] [Batch 539/938] [D loss: 0.298335] [G loss: 0.594013] [info loss: 1.476755]\n",
            "[Epoch 27/200] [Batch 540/938] [D loss: 0.116672] [G loss: 0.420519] [info loss: 1.471192]\n",
            "[Epoch 27/200] [Batch 541/938] [D loss: 0.240103] [G loss: 0.367378] [info loss: 1.474996]\n",
            "[Epoch 27/200] [Batch 542/938] [D loss: 0.300827] [G loss: 0.281036] [info loss: 1.504018]\n",
            "[Epoch 27/200] [Batch 543/938] [D loss: 0.259385] [G loss: 0.286786] [info loss: 1.475946]\n",
            "[Epoch 27/200] [Batch 544/938] [D loss: 0.217344] [G loss: 0.451180] [info loss: 1.500925]\n",
            "[Epoch 27/200] [Batch 545/938] [D loss: 0.221863] [G loss: 0.174708] [info loss: 1.480276]\n",
            "[Epoch 27/200] [Batch 546/938] [D loss: 0.294079] [G loss: 0.323119] [info loss: 1.470715]\n",
            "[Epoch 27/200] [Batch 547/938] [D loss: 0.216030] [G loss: 0.298120] [info loss: 1.471635]\n",
            "[Epoch 27/200] [Batch 548/938] [D loss: 0.206547] [G loss: 0.431632] [info loss: 1.473306]\n",
            "[Epoch 27/200] [Batch 549/938] [D loss: 0.262021] [G loss: 0.307171] [info loss: 1.483527]\n",
            "[Epoch 27/200] [Batch 550/938] [D loss: 0.180242] [G loss: 0.206051] [info loss: 1.473679]\n",
            "[Epoch 27/200] [Batch 551/938] [D loss: 0.195639] [G loss: 0.492607] [info loss: 1.472931]\n",
            "[Epoch 27/200] [Batch 552/938] [D loss: 0.198097] [G loss: 0.346819] [info loss: 1.485735]\n",
            "[Epoch 27/200] [Batch 553/938] [D loss: 0.271910] [G loss: 0.526547] [info loss: 1.471997]\n",
            "[Epoch 27/200] [Batch 554/938] [D loss: 0.212221] [G loss: 0.365108] [info loss: 1.474842]\n",
            "[Epoch 27/200] [Batch 555/938] [D loss: 0.228673] [G loss: 0.176045] [info loss: 1.479725]\n",
            "[Epoch 27/200] [Batch 556/938] [D loss: 0.311705] [G loss: 0.203004] [info loss: 1.476290]\n",
            "[Epoch 27/200] [Batch 557/938] [D loss: 0.388904] [G loss: 0.263992] [info loss: 1.474213]\n",
            "[Epoch 27/200] [Batch 558/938] [D loss: 0.279750] [G loss: 0.378350] [info loss: 1.478467]\n",
            "[Epoch 27/200] [Batch 559/938] [D loss: 0.216205] [G loss: 0.446916] [info loss: 1.476275]\n",
            "[Epoch 27/200] [Batch 560/938] [D loss: 0.103346] [G loss: 0.504953] [info loss: 1.483435]\n",
            "[Epoch 27/200] [Batch 561/938] [D loss: 0.184218] [G loss: 0.540911] [info loss: 1.472804]\n",
            "[Epoch 27/200] [Batch 562/938] [D loss: 0.294493] [G loss: 0.328225] [info loss: 1.472269]\n",
            "[Epoch 27/200] [Batch 563/938] [D loss: 0.222195] [G loss: 0.354148] [info loss: 1.471562]\n",
            "[Epoch 27/200] [Batch 564/938] [D loss: 0.204649] [G loss: 0.396334] [info loss: 1.514549]\n",
            "[Epoch 27/200] [Batch 565/938] [D loss: 0.221329] [G loss: 0.606527] [info loss: 1.470935]\n",
            "[Epoch 27/200] [Batch 566/938] [D loss: 0.150831] [G loss: 0.590864] [info loss: 1.473999]\n",
            "[Epoch 27/200] [Batch 567/938] [D loss: 0.224479] [G loss: 0.483642] [info loss: 1.501221]\n",
            "[Epoch 27/200] [Batch 568/938] [D loss: 0.208564] [G loss: 0.236267] [info loss: 1.500540]\n",
            "[Epoch 27/200] [Batch 569/938] [D loss: 0.159885] [G loss: 0.399792] [info loss: 1.475843]\n",
            "[Epoch 27/200] [Batch 570/938] [D loss: 0.341062] [G loss: 0.307348] [info loss: 1.472317]\n",
            "[Epoch 27/200] [Batch 571/938] [D loss: 0.104430] [G loss: 0.159061] [info loss: 1.475356]\n",
            "[Epoch 27/200] [Batch 572/938] [D loss: 0.134984] [G loss: 0.269832] [info loss: 1.470325]\n",
            "[Epoch 27/200] [Batch 573/938] [D loss: 0.214151] [G loss: 0.326698] [info loss: 1.488029]\n",
            "[Epoch 27/200] [Batch 574/938] [D loss: 0.241180] [G loss: 0.318699] [info loss: 1.488484]\n",
            "[Epoch 27/200] [Batch 575/938] [D loss: 0.281853] [G loss: 0.361921] [info loss: 1.483964]\n",
            "[Epoch 27/200] [Batch 576/938] [D loss: 0.243017] [G loss: 0.469117] [info loss: 1.471332]\n",
            "[Epoch 27/200] [Batch 577/938] [D loss: 0.211513] [G loss: 0.211082] [info loss: 1.483233]\n",
            "[Epoch 27/200] [Batch 578/938] [D loss: 0.332263] [G loss: 0.199119] [info loss: 1.475703]\n",
            "[Epoch 27/200] [Batch 579/938] [D loss: 0.225365] [G loss: 0.119032] [info loss: 1.475501]\n",
            "[Epoch 27/200] [Batch 580/938] [D loss: 0.187672] [G loss: 0.303094] [info loss: 1.472251]\n",
            "[Epoch 27/200] [Batch 581/938] [D loss: 0.219452] [G loss: 0.185116] [info loss: 1.472313]\n",
            "[Epoch 27/200] [Batch 582/938] [D loss: 0.233680] [G loss: 0.280333] [info loss: 1.504270]\n",
            "[Epoch 27/200] [Batch 583/938] [D loss: 0.148301] [G loss: 0.249775] [info loss: 1.487317]\n",
            "[Epoch 27/200] [Batch 584/938] [D loss: 0.183380] [G loss: 0.292418] [info loss: 1.482867]\n",
            "[Epoch 27/200] [Batch 585/938] [D loss: 0.125223] [G loss: 0.433836] [info loss: 1.477647]\n",
            "[Epoch 27/200] [Batch 586/938] [D loss: 0.133060] [G loss: 0.268841] [info loss: 1.474068]\n",
            "[Epoch 27/200] [Batch 587/938] [D loss: 0.292384] [G loss: 0.348542] [info loss: 1.471266]\n",
            "[Epoch 27/200] [Batch 588/938] [D loss: 0.388005] [G loss: 0.259952] [info loss: 1.468908]\n",
            "[Epoch 27/200] [Batch 589/938] [D loss: 0.234279] [G loss: 0.154780] [info loss: 1.481110]\n",
            "[Epoch 27/200] [Batch 590/938] [D loss: 0.227061] [G loss: 0.259215] [info loss: 1.469470]\n",
            "[Epoch 27/200] [Batch 591/938] [D loss: 0.194295] [G loss: 0.524874] [info loss: 1.500829]\n",
            "[Epoch 27/200] [Batch 592/938] [D loss: 0.152652] [G loss: 0.353230] [info loss: 1.485794]\n",
            "[Epoch 27/200] [Batch 593/938] [D loss: 0.296256] [G loss: 0.392220] [info loss: 1.495827]\n",
            "[Epoch 27/200] [Batch 594/938] [D loss: 0.227805] [G loss: 0.409704] [info loss: 1.472734]\n",
            "[Epoch 27/200] [Batch 595/938] [D loss: 0.174907] [G loss: 0.349140] [info loss: 1.487179]\n",
            "[Epoch 27/200] [Batch 596/938] [D loss: 0.166014] [G loss: 0.570385] [info loss: 1.472835]\n",
            "[Epoch 27/200] [Batch 597/938] [D loss: 0.197479] [G loss: 0.376483] [info loss: 1.470359]\n",
            "[Epoch 27/200] [Batch 598/938] [D loss: 0.296886] [G loss: 0.247012] [info loss: 1.471165]\n",
            "[Epoch 27/200] [Batch 599/938] [D loss: 0.204045] [G loss: 0.296062] [info loss: 1.473591]\n",
            "[Epoch 27/200] [Batch 600/938] [D loss: 0.278247] [G loss: 0.355233] [info loss: 1.499213]\n",
            "[Epoch 27/200] [Batch 601/938] [D loss: 0.209684] [G loss: 0.218610] [info loss: 1.474445]\n",
            "[Epoch 27/200] [Batch 602/938] [D loss: 0.298725] [G loss: 0.267705] [info loss: 1.482740]\n",
            "[Epoch 27/200] [Batch 603/938] [D loss: 0.186090] [G loss: 0.378503] [info loss: 1.470683]\n",
            "[Epoch 27/200] [Batch 604/938] [D loss: 0.348317] [G loss: 0.418431] [info loss: 1.482648]\n",
            "[Epoch 27/200] [Batch 605/938] [D loss: 0.094384] [G loss: 0.361330] [info loss: 1.471402]\n",
            "[Epoch 27/200] [Batch 606/938] [D loss: 0.154220] [G loss: 0.377362] [info loss: 1.469806]\n",
            "[Epoch 27/200] [Batch 607/938] [D loss: 0.185200] [G loss: 0.414768] [info loss: 1.471505]\n",
            "[Epoch 27/200] [Batch 608/938] [D loss: 0.282228] [G loss: 0.444710] [info loss: 1.470517]\n",
            "[Epoch 27/200] [Batch 609/938] [D loss: 0.186620] [G loss: 0.531655] [info loss: 1.473124]\n",
            "[Epoch 27/200] [Batch 610/938] [D loss: 0.186584] [G loss: 0.496236] [info loss: 1.476637]\n",
            "[Epoch 27/200] [Batch 611/938] [D loss: 0.201863] [G loss: 0.398944] [info loss: 1.475797]\n",
            "[Epoch 27/200] [Batch 612/938] [D loss: 0.229379] [G loss: 0.273482] [info loss: 1.484838]\n",
            "[Epoch 27/200] [Batch 613/938] [D loss: 0.144167] [G loss: 0.316419] [info loss: 1.474280]\n",
            "[Epoch 27/200] [Batch 614/938] [D loss: 0.185554] [G loss: 0.291200] [info loss: 1.468505]\n",
            "[Epoch 27/200] [Batch 615/938] [D loss: 0.167343] [G loss: 0.409214] [info loss: 1.477871]\n",
            "[Epoch 27/200] [Batch 616/938] [D loss: 0.186805] [G loss: 0.393543] [info loss: 1.475421]\n",
            "[Epoch 27/200] [Batch 617/938] [D loss: 0.189877] [G loss: 0.351665] [info loss: 1.469870]\n",
            "[Epoch 27/200] [Batch 618/938] [D loss: 0.199912] [G loss: 0.252701] [info loss: 1.481965]\n",
            "[Epoch 27/200] [Batch 619/938] [D loss: 0.262064] [G loss: 0.194572] [info loss: 1.476197]\n",
            "[Epoch 27/200] [Batch 620/938] [D loss: 0.215958] [G loss: 0.163595] [info loss: 1.473777]\n",
            "[Epoch 27/200] [Batch 621/938] [D loss: 0.244878] [G loss: 0.274442] [info loss: 1.518201]\n",
            "[Epoch 27/200] [Batch 622/938] [D loss: 0.248868] [G loss: 0.516352] [info loss: 1.474409]\n",
            "[Epoch 27/200] [Batch 623/938] [D loss: 0.166984] [G loss: 0.317056] [info loss: 1.477217]\n",
            "[Epoch 27/200] [Batch 624/938] [D loss: 0.219352] [G loss: 0.330389] [info loss: 1.472020]\n",
            "[Epoch 27/200] [Batch 625/938] [D loss: 0.240744] [G loss: 0.397162] [info loss: 1.468456]\n",
            "[Epoch 27/200] [Batch 626/938] [D loss: 0.197333] [G loss: 0.403664] [info loss: 1.501666]\n",
            "[Epoch 27/200] [Batch 627/938] [D loss: 0.219883] [G loss: 0.242484] [info loss: 1.488999]\n",
            "[Epoch 27/200] [Batch 628/938] [D loss: 0.159906] [G loss: 0.367589] [info loss: 1.488767]\n",
            "[Epoch 27/200] [Batch 629/938] [D loss: 0.237709] [G loss: 0.173241] [info loss: 1.471799]\n",
            "[Epoch 27/200] [Batch 630/938] [D loss: 0.178301] [G loss: 0.255359] [info loss: 1.469214]\n",
            "[Epoch 27/200] [Batch 631/938] [D loss: 0.270465] [G loss: 0.280264] [info loss: 1.472042]\n",
            "[Epoch 27/200] [Batch 632/938] [D loss: 0.260632] [G loss: 0.428545] [info loss: 1.480703]\n",
            "[Epoch 27/200] [Batch 633/938] [D loss: 0.167026] [G loss: 0.240214] [info loss: 1.480070]\n",
            "[Epoch 27/200] [Batch 634/938] [D loss: 0.302804] [G loss: 0.203626] [info loss: 1.473809]\n",
            "[Epoch 27/200] [Batch 635/938] [D loss: 0.196286] [G loss: 0.437580] [info loss: 1.472679]\n",
            "[Epoch 27/200] [Batch 636/938] [D loss: 0.372342] [G loss: 0.391114] [info loss: 1.478410]\n",
            "[Epoch 27/200] [Batch 637/938] [D loss: 0.182842] [G loss: 0.314892] [info loss: 1.490576]\n",
            "[Epoch 27/200] [Batch 638/938] [D loss: 0.339842] [G loss: 0.332567] [info loss: 1.469185]\n",
            "[Epoch 27/200] [Batch 639/938] [D loss: 0.252523] [G loss: 0.440696] [info loss: 1.506172]\n",
            "[Epoch 27/200] [Batch 640/938] [D loss: 0.267809] [G loss: 0.388492] [info loss: 1.470872]\n",
            "[Epoch 27/200] [Batch 641/938] [D loss: 0.223139] [G loss: 0.532098] [info loss: 1.486903]\n",
            "[Epoch 27/200] [Batch 642/938] [D loss: 0.226315] [G loss: 0.374114] [info loss: 1.474917]\n",
            "[Epoch 27/200] [Batch 643/938] [D loss: 0.180579] [G loss: 0.320099] [info loss: 1.471166]\n",
            "[Epoch 27/200] [Batch 644/938] [D loss: 0.179152] [G loss: 0.408680] [info loss: 1.497436]\n",
            "[Epoch 27/200] [Batch 645/938] [D loss: 0.285908] [G loss: 0.134832] [info loss: 1.476366]\n",
            "[Epoch 27/200] [Batch 646/938] [D loss: 0.216044] [G loss: 0.276714] [info loss: 1.468178]\n",
            "[Epoch 27/200] [Batch 647/938] [D loss: 0.247864] [G loss: 0.467589] [info loss: 1.476128]\n",
            "[Epoch 27/200] [Batch 648/938] [D loss: 0.120271] [G loss: 0.374689] [info loss: 1.478626]\n",
            "[Epoch 27/200] [Batch 649/938] [D loss: 0.254538] [G loss: 0.392910] [info loss: 1.479181]\n",
            "[Epoch 27/200] [Batch 650/938] [D loss: 0.180951] [G loss: 0.402536] [info loss: 1.467739]\n",
            "[Epoch 27/200] [Batch 651/938] [D loss: 0.206702] [G loss: 0.427008] [info loss: 1.489938]\n",
            "[Epoch 27/200] [Batch 652/938] [D loss: 0.186489] [G loss: 0.371215] [info loss: 1.481900]\n",
            "[Epoch 27/200] [Batch 653/938] [D loss: 0.146526] [G loss: 0.187280] [info loss: 1.481454]\n",
            "[Epoch 27/200] [Batch 654/938] [D loss: 0.232233] [G loss: 0.350008] [info loss: 1.492383]\n",
            "[Epoch 27/200] [Batch 655/938] [D loss: 0.351013] [G loss: 0.281163] [info loss: 1.472045]\n",
            "[Epoch 27/200] [Batch 656/938] [D loss: 0.198936] [G loss: 0.239902] [info loss: 1.473541]\n",
            "[Epoch 27/200] [Batch 657/938] [D loss: 0.220623] [G loss: 0.152425] [info loss: 1.473472]\n",
            "[Epoch 27/200] [Batch 658/938] [D loss: 0.189869] [G loss: 0.269501] [info loss: 1.484519]\n",
            "[Epoch 27/200] [Batch 659/938] [D loss: 0.159299] [G loss: 0.358524] [info loss: 1.477556]\n",
            "[Epoch 27/200] [Batch 660/938] [D loss: 0.265735] [G loss: 0.201714] [info loss: 1.480749]\n",
            "[Epoch 27/200] [Batch 661/938] [D loss: 0.261734] [G loss: 0.278326] [info loss: 1.490455]\n",
            "[Epoch 27/200] [Batch 662/938] [D loss: 0.113735] [G loss: 0.388376] [info loss: 1.485845]\n",
            "[Epoch 27/200] [Batch 663/938] [D loss: 0.192341] [G loss: 0.539053] [info loss: 1.474445]\n",
            "[Epoch 27/200] [Batch 664/938] [D loss: 0.216567] [G loss: 0.362151] [info loss: 1.470803]\n",
            "[Epoch 27/200] [Batch 665/938] [D loss: 0.277581] [G loss: 0.349712] [info loss: 1.493227]\n",
            "[Epoch 27/200] [Batch 666/938] [D loss: 0.207339] [G loss: 0.580522] [info loss: 1.482333]\n",
            "[Epoch 27/200] [Batch 667/938] [D loss: 0.231948] [G loss: 0.273040] [info loss: 1.470762]\n",
            "[Epoch 27/200] [Batch 668/938] [D loss: 0.137840] [G loss: 0.309464] [info loss: 1.472142]\n",
            "[Epoch 27/200] [Batch 669/938] [D loss: 0.324314] [G loss: 0.150873] [info loss: 1.484390]\n",
            "[Epoch 27/200] [Batch 670/938] [D loss: 0.308206] [G loss: 0.462600] [info loss: 1.483067]\n",
            "[Epoch 27/200] [Batch 671/938] [D loss: 0.229031] [G loss: 0.322222] [info loss: 1.489342]\n",
            "[Epoch 27/200] [Batch 672/938] [D loss: 0.182570] [G loss: 0.373327] [info loss: 1.479711]\n",
            "[Epoch 27/200] [Batch 673/938] [D loss: 0.262122] [G loss: 0.112115] [info loss: 1.483414]\n",
            "[Epoch 27/200] [Batch 674/938] [D loss: 0.183895] [G loss: 0.354925] [info loss: 1.488740]\n",
            "[Epoch 27/200] [Batch 675/938] [D loss: 0.256194] [G loss: 0.267102] [info loss: 1.471914]\n",
            "[Epoch 27/200] [Batch 676/938] [D loss: 0.214398] [G loss: 0.398013] [info loss: 1.481019]\n",
            "[Epoch 27/200] [Batch 677/938] [D loss: 0.278084] [G loss: 0.247516] [info loss: 1.478533]\n",
            "[Epoch 27/200] [Batch 678/938] [D loss: 0.258323] [G loss: 0.295316] [info loss: 1.473110]\n",
            "[Epoch 27/200] [Batch 679/938] [D loss: 0.164876] [G loss: 0.176908] [info loss: 1.470124]\n",
            "[Epoch 27/200] [Batch 680/938] [D loss: 0.235605] [G loss: 0.328808] [info loss: 1.472293]\n",
            "[Epoch 27/200] [Batch 681/938] [D loss: 0.269913] [G loss: 0.430696] [info loss: 1.478425]\n",
            "[Epoch 27/200] [Batch 682/938] [D loss: 0.215711] [G loss: 0.457946] [info loss: 1.487786]\n",
            "[Epoch 27/200] [Batch 683/938] [D loss: 0.180473] [G loss: 0.274195] [info loss: 1.477838]\n",
            "[Epoch 27/200] [Batch 684/938] [D loss: 0.245178] [G loss: 0.248651] [info loss: 1.487037]\n",
            "[Epoch 27/200] [Batch 685/938] [D loss: 0.194640] [G loss: 0.129769] [info loss: 1.471326]\n",
            "[Epoch 27/200] [Batch 686/938] [D loss: 0.266265] [G loss: 0.131493] [info loss: 1.493602]\n",
            "[Epoch 27/200] [Batch 687/938] [D loss: 0.184785] [G loss: 0.234679] [info loss: 1.487185]\n",
            "[Epoch 27/200] [Batch 688/938] [D loss: 0.177801] [G loss: 0.327318] [info loss: 1.472580]\n",
            "[Epoch 27/200] [Batch 689/938] [D loss: 0.297182] [G loss: 0.334293] [info loss: 1.468653]\n",
            "[Epoch 27/200] [Batch 690/938] [D loss: 0.136375] [G loss: 0.327918] [info loss: 1.472540]\n",
            "[Epoch 27/200] [Batch 691/938] [D loss: 0.203386] [G loss: 0.417865] [info loss: 1.490921]\n",
            "[Epoch 27/200] [Batch 692/938] [D loss: 0.264697] [G loss: 0.245153] [info loss: 1.474718]\n",
            "[Epoch 27/200] [Batch 693/938] [D loss: 0.223478] [G loss: 0.371336] [info loss: 1.475389]\n",
            "[Epoch 27/200] [Batch 694/938] [D loss: 0.228738] [G loss: 0.424986] [info loss: 1.472966]\n",
            "[Epoch 27/200] [Batch 695/938] [D loss: 0.227915] [G loss: 0.414981] [info loss: 1.471236]\n",
            "[Epoch 27/200] [Batch 696/938] [D loss: 0.252211] [G loss: 0.231644] [info loss: 1.494309]\n",
            "[Epoch 27/200] [Batch 697/938] [D loss: 0.194733] [G loss: 0.258096] [info loss: 1.506157]\n",
            "[Epoch 27/200] [Batch 698/938] [D loss: 0.196575] [G loss: 0.259053] [info loss: 1.487600]\n",
            "[Epoch 27/200] [Batch 699/938] [D loss: 0.253864] [G loss: 0.247569] [info loss: 1.469620]\n",
            "[Epoch 27/200] [Batch 700/938] [D loss: 0.173698] [G loss: 0.325791] [info loss: 1.482670]\n",
            "[Epoch 27/200] [Batch 701/938] [D loss: 0.170457] [G loss: 0.367840] [info loss: 1.483168]\n",
            "[Epoch 27/200] [Batch 702/938] [D loss: 0.205649] [G loss: 0.461673] [info loss: 1.479368]\n",
            "[Epoch 27/200] [Batch 703/938] [D loss: 0.242061] [G loss: 0.657278] [info loss: 1.501664]\n",
            "[Epoch 27/200] [Batch 704/938] [D loss: 0.253637] [G loss: 0.507333] [info loss: 1.487705]\n",
            "[Epoch 27/200] [Batch 705/938] [D loss: 0.255415] [G loss: 0.445894] [info loss: 1.487382]\n",
            "[Epoch 27/200] [Batch 706/938] [D loss: 0.137466] [G loss: 0.685982] [info loss: 1.493010]\n",
            "[Epoch 27/200] [Batch 707/938] [D loss: 0.213042] [G loss: 0.422044] [info loss: 1.476894]\n",
            "[Epoch 27/200] [Batch 708/938] [D loss: 0.155387] [G loss: 0.178036] [info loss: 1.472816]\n",
            "[Epoch 27/200] [Batch 709/938] [D loss: 0.296613] [G loss: 0.190112] [info loss: 1.479780]\n",
            "[Epoch 27/200] [Batch 710/938] [D loss: 0.251013] [G loss: 0.258097] [info loss: 1.485807]\n",
            "[Epoch 27/200] [Batch 711/938] [D loss: 0.191666] [G loss: 0.405158] [info loss: 1.490152]\n",
            "[Epoch 27/200] [Batch 712/938] [D loss: 0.219339] [G loss: 0.437837] [info loss: 1.484732]\n",
            "[Epoch 27/200] [Batch 713/938] [D loss: 0.217658] [G loss: 0.301457] [info loss: 1.485795]\n",
            "[Epoch 27/200] [Batch 714/938] [D loss: 0.205824] [G loss: 0.316387] [info loss: 1.478562]\n",
            "[Epoch 27/200] [Batch 715/938] [D loss: 0.383543] [G loss: 0.141438] [info loss: 1.470733]\n",
            "[Epoch 27/200] [Batch 716/938] [D loss: 0.264958] [G loss: 0.254413] [info loss: 1.498623]\n",
            "[Epoch 27/200] [Batch 717/938] [D loss: 0.319051] [G loss: 0.136234] [info loss: 1.481823]\n",
            "[Epoch 27/200] [Batch 718/938] [D loss: 0.144355] [G loss: 0.348728] [info loss: 1.487369]\n",
            "[Epoch 27/200] [Batch 719/938] [D loss: 0.167074] [G loss: 0.254857] [info loss: 1.470821]\n",
            "[Epoch 27/200] [Batch 720/938] [D loss: 0.214878] [G loss: 0.622880] [info loss: 1.475820]\n",
            "[Epoch 27/200] [Batch 721/938] [D loss: 0.204152] [G loss: 0.559536] [info loss: 1.476926]\n",
            "[Epoch 27/200] [Batch 722/938] [D loss: 0.148305] [G loss: 0.414965] [info loss: 1.501792]\n",
            "[Epoch 27/200] [Batch 723/938] [D loss: 0.229900] [G loss: 0.487236] [info loss: 1.489869]\n",
            "[Epoch 27/200] [Batch 724/938] [D loss: 0.261394] [G loss: 0.331017] [info loss: 1.475756]\n",
            "[Epoch 27/200] [Batch 725/938] [D loss: 0.198813] [G loss: 0.353657] [info loss: 1.487124]\n",
            "[Epoch 27/200] [Batch 726/938] [D loss: 0.280923] [G loss: 0.450091] [info loss: 1.479228]\n",
            "[Epoch 27/200] [Batch 727/938] [D loss: 0.236912] [G loss: 0.304919] [info loss: 1.505893]\n",
            "[Epoch 27/200] [Batch 728/938] [D loss: 0.227316] [G loss: 0.397774] [info loss: 1.484881]\n",
            "[Epoch 27/200] [Batch 729/938] [D loss: 0.313224] [G loss: 0.430506] [info loss: 1.477349]\n",
            "[Epoch 27/200] [Batch 730/938] [D loss: 0.332997] [G loss: 0.493580] [info loss: 1.474564]\n",
            "[Epoch 27/200] [Batch 731/938] [D loss: 0.223147] [G loss: 0.356972] [info loss: 1.487449]\n",
            "[Epoch 27/200] [Batch 732/938] [D loss: 0.163385] [G loss: 0.301333] [info loss: 1.485464]\n",
            "[Epoch 27/200] [Batch 733/938] [D loss: 0.317849] [G loss: 0.306216] [info loss: 1.469942]\n",
            "[Epoch 27/200] [Batch 734/938] [D loss: 0.175372] [G loss: 0.213566] [info loss: 1.479959]\n",
            "[Epoch 27/200] [Batch 735/938] [D loss: 0.108225] [G loss: 0.414016] [info loss: 1.471715]\n",
            "[Epoch 27/200] [Batch 736/938] [D loss: 0.183303] [G loss: 0.387997] [info loss: 1.480609]\n",
            "[Epoch 27/200] [Batch 737/938] [D loss: 0.325233] [G loss: 0.298460] [info loss: 1.468577]\n",
            "[Epoch 27/200] [Batch 738/938] [D loss: 0.198087] [G loss: 0.381900] [info loss: 1.473034]\n",
            "[Epoch 27/200] [Batch 739/938] [D loss: 0.243555] [G loss: 0.534446] [info loss: 1.495637]\n",
            "[Epoch 27/200] [Batch 740/938] [D loss: 0.299478] [G loss: 0.297192] [info loss: 1.471796]\n",
            "[Epoch 27/200] [Batch 741/938] [D loss: 0.290430] [G loss: 0.300502] [info loss: 1.490085]\n",
            "[Epoch 27/200] [Batch 742/938] [D loss: 0.184457] [G loss: 0.337180] [info loss: 1.487490]\n",
            "[Epoch 27/200] [Batch 743/938] [D loss: 0.132750] [G loss: 0.361411] [info loss: 1.484859]\n",
            "[Epoch 27/200] [Batch 744/938] [D loss: 0.200330] [G loss: 0.530897] [info loss: 1.478228]\n",
            "[Epoch 27/200] [Batch 745/938] [D loss: 0.212934] [G loss: 0.460949] [info loss: 1.482201]\n",
            "[Epoch 27/200] [Batch 746/938] [D loss: 0.278865] [G loss: 0.348039] [info loss: 1.484519]\n",
            "[Epoch 27/200] [Batch 747/938] [D loss: 0.156302] [G loss: 0.263978] [info loss: 1.474046]\n",
            "[Epoch 27/200] [Batch 748/938] [D loss: 0.341736] [G loss: 0.441037] [info loss: 1.484604]\n",
            "[Epoch 27/200] [Batch 749/938] [D loss: 0.225066] [G loss: 0.280510] [info loss: 1.497202]\n",
            "[Epoch 27/200] [Batch 750/938] [D loss: 0.107139] [G loss: 0.418746] [info loss: 1.495481]\n",
            "[Epoch 27/200] [Batch 751/938] [D loss: 0.262420] [G loss: 0.275430] [info loss: 1.470191]\n",
            "[Epoch 27/200] [Batch 752/938] [D loss: 0.176466] [G loss: 0.284267] [info loss: 1.488335]\n",
            "[Epoch 27/200] [Batch 753/938] [D loss: 0.220046] [G loss: 0.214992] [info loss: 1.494485]\n",
            "[Epoch 27/200] [Batch 754/938] [D loss: 0.308813] [G loss: 0.226566] [info loss: 1.492217]\n",
            "[Epoch 27/200] [Batch 755/938] [D loss: 0.189594] [G loss: 0.330833] [info loss: 1.486090]\n",
            "[Epoch 27/200] [Batch 756/938] [D loss: 0.274855] [G loss: 0.277988] [info loss: 1.483285]\n",
            "[Epoch 27/200] [Batch 757/938] [D loss: 0.218569] [G loss: 0.427599] [info loss: 1.482511]\n",
            "[Epoch 27/200] [Batch 758/938] [D loss: 0.330950] [G loss: 0.294361] [info loss: 1.471767]\n",
            "[Epoch 27/200] [Batch 759/938] [D loss: 0.139600] [G loss: 0.265119] [info loss: 1.487112]\n",
            "[Epoch 27/200] [Batch 760/938] [D loss: 0.217702] [G loss: 0.210213] [info loss: 1.471046]\n",
            "[Epoch 27/200] [Batch 761/938] [D loss: 0.217157] [G loss: 0.311439] [info loss: 1.470686]\n",
            "[Epoch 27/200] [Batch 762/938] [D loss: 0.166730] [G loss: 0.189061] [info loss: 1.484792]\n",
            "[Epoch 27/200] [Batch 763/938] [D loss: 0.296505] [G loss: 0.295530] [info loss: 1.471342]\n",
            "[Epoch 27/200] [Batch 764/938] [D loss: 0.176187] [G loss: 0.202783] [info loss: 1.469209]\n",
            "[Epoch 27/200] [Batch 765/938] [D loss: 0.261492] [G loss: 0.276295] [info loss: 1.470915]\n",
            "[Epoch 27/200] [Batch 766/938] [D loss: 0.339116] [G loss: 0.295580] [info loss: 1.478636]\n",
            "[Epoch 27/200] [Batch 767/938] [D loss: 0.194346] [G loss: 0.282944] [info loss: 1.481609]\n",
            "[Epoch 27/200] [Batch 768/938] [D loss: 0.298657] [G loss: 0.188996] [info loss: 1.472115]\n",
            "[Epoch 27/200] [Batch 769/938] [D loss: 0.231573] [G loss: 0.152515] [info loss: 1.473699]\n",
            "[Epoch 27/200] [Batch 770/938] [D loss: 0.177785] [G loss: 0.455604] [info loss: 1.468231]\n",
            "[Epoch 27/200] [Batch 771/938] [D loss: 0.126988] [G loss: 0.533105] [info loss: 1.470323]\n",
            "[Epoch 27/200] [Batch 772/938] [D loss: 0.209987] [G loss: 0.540769] [info loss: 1.468947]\n",
            "[Epoch 27/200] [Batch 773/938] [D loss: 0.319414] [G loss: 0.297852] [info loss: 1.481882]\n",
            "[Epoch 27/200] [Batch 774/938] [D loss: 0.251000] [G loss: 0.259270] [info loss: 1.471162]\n",
            "[Epoch 27/200] [Batch 775/938] [D loss: 0.160937] [G loss: 0.233076] [info loss: 1.488916]\n",
            "[Epoch 27/200] [Batch 776/938] [D loss: 0.164657] [G loss: 0.305748] [info loss: 1.485086]\n",
            "[Epoch 27/200] [Batch 777/938] [D loss: 0.220340] [G loss: 0.208350] [info loss: 1.472135]\n",
            "[Epoch 27/200] [Batch 778/938] [D loss: 0.259910] [G loss: 0.333214] [info loss: 1.484888]\n",
            "[Epoch 27/200] [Batch 779/938] [D loss: 0.272007] [G loss: 0.598419] [info loss: 1.483703]\n",
            "[Epoch 27/200] [Batch 780/938] [D loss: 0.332046] [G loss: 0.185961] [info loss: 1.470577]\n",
            "[Epoch 27/200] [Batch 781/938] [D loss: 0.162085] [G loss: 0.251686] [info loss: 1.468604]\n",
            "[Epoch 27/200] [Batch 782/938] [D loss: 0.234076] [G loss: 0.375517] [info loss: 1.488100]\n",
            "[Epoch 27/200] [Batch 783/938] [D loss: 0.316325] [G loss: 0.579845] [info loss: 1.515491]\n",
            "[Epoch 27/200] [Batch 784/938] [D loss: 0.119994] [G loss: 0.687117] [info loss: 1.479545]\n",
            "[Epoch 27/200] [Batch 785/938] [D loss: 0.192054] [G loss: 0.208811] [info loss: 1.470464]\n",
            "[Epoch 27/200] [Batch 786/938] [D loss: 0.115907] [G loss: 0.356227] [info loss: 1.472371]\n",
            "[Epoch 27/200] [Batch 787/938] [D loss: 0.210914] [G loss: 0.247299] [info loss: 1.477345]\n",
            "[Epoch 27/200] [Batch 788/938] [D loss: 0.227136] [G loss: 0.397014] [info loss: 1.484617]\n",
            "[Epoch 27/200] [Batch 789/938] [D loss: 0.193744] [G loss: 0.516173] [info loss: 1.480177]\n",
            "[Epoch 27/200] [Batch 790/938] [D loss: 0.178911] [G loss: 0.604828] [info loss: 1.482887]\n",
            "[Epoch 27/200] [Batch 791/938] [D loss: 0.246937] [G loss: 0.372797] [info loss: 1.485708]\n",
            "[Epoch 27/200] [Batch 792/938] [D loss: 0.214999] [G loss: 0.281376] [info loss: 1.470793]\n",
            "[Epoch 27/200] [Batch 793/938] [D loss: 0.213531] [G loss: 0.263895] [info loss: 1.485911]\n",
            "[Epoch 27/200] [Batch 794/938] [D loss: 0.185733] [G loss: 0.380632] [info loss: 1.478314]\n",
            "[Epoch 27/200] [Batch 795/938] [D loss: 0.208328] [G loss: 0.294543] [info loss: 1.488183]\n",
            "[Epoch 27/200] [Batch 796/938] [D loss: 0.248175] [G loss: 0.348287] [info loss: 1.501391]\n",
            "[Epoch 27/200] [Batch 797/938] [D loss: 0.168301] [G loss: 0.477807] [info loss: 1.488712]\n",
            "[Epoch 27/200] [Batch 798/938] [D loss: 0.342717] [G loss: 0.409255] [info loss: 1.469467]\n",
            "[Epoch 27/200] [Batch 799/938] [D loss: 0.171439] [G loss: 0.390332] [info loss: 1.473670]\n",
            "[Epoch 27/200] [Batch 800/938] [D loss: 0.181188] [G loss: 0.380351] [info loss: 1.475593]\n",
            "[Epoch 27/200] [Batch 801/938] [D loss: 0.246662] [G loss: 0.171894] [info loss: 1.473945]\n",
            "[Epoch 27/200] [Batch 802/938] [D loss: 0.310494] [G loss: 0.144758] [info loss: 1.487169]\n",
            "[Epoch 27/200] [Batch 803/938] [D loss: 0.263889] [G loss: 0.272734] [info loss: 1.484766]\n",
            "[Epoch 27/200] [Batch 804/938] [D loss: 0.286503] [G loss: 0.377958] [info loss: 1.501299]\n",
            "[Epoch 27/200] [Batch 805/938] [D loss: 0.264767] [G loss: 0.517924] [info loss: 1.471674]\n",
            "[Epoch 27/200] [Batch 806/938] [D loss: 0.325777] [G loss: 0.272344] [info loss: 1.469837]\n",
            "[Epoch 27/200] [Batch 807/938] [D loss: 0.219142] [G loss: 0.503147] [info loss: 1.495478]\n",
            "[Epoch 27/200] [Batch 808/938] [D loss: 0.184991] [G loss: 0.500860] [info loss: 1.472592]\n",
            "[Epoch 27/200] [Batch 809/938] [D loss: 0.175956] [G loss: 0.352825] [info loss: 1.469947]\n",
            "[Epoch 27/200] [Batch 810/938] [D loss: 0.203068] [G loss: 0.290780] [info loss: 1.469977]\n",
            "[Epoch 27/200] [Batch 811/938] [D loss: 0.254233] [G loss: 0.322438] [info loss: 1.487593]\n",
            "[Epoch 27/200] [Batch 812/938] [D loss: 0.252625] [G loss: 0.130914] [info loss: 1.469285]\n",
            "[Epoch 27/200] [Batch 813/938] [D loss: 0.209120] [G loss: 0.142616] [info loss: 1.470666]\n",
            "[Epoch 27/200] [Batch 814/938] [D loss: 0.226676] [G loss: 0.209537] [info loss: 1.506552]\n",
            "[Epoch 27/200] [Batch 815/938] [D loss: 0.227466] [G loss: 0.179180] [info loss: 1.470548]\n",
            "[Epoch 27/200] [Batch 816/938] [D loss: 0.124947] [G loss: 0.353241] [info loss: 1.472904]\n",
            "[Epoch 27/200] [Batch 817/938] [D loss: 0.234549] [G loss: 0.564655] [info loss: 1.471486]\n",
            "[Epoch 27/200] [Batch 818/938] [D loss: 0.166401] [G loss: 0.336063] [info loss: 1.469868]\n",
            "[Epoch 27/200] [Batch 819/938] [D loss: 0.204837] [G loss: 0.163802] [info loss: 1.488735]\n",
            "[Epoch 27/200] [Batch 820/938] [D loss: 0.185852] [G loss: 0.450619] [info loss: 1.467544]\n",
            "[Epoch 27/200] [Batch 821/938] [D loss: 0.389145] [G loss: 0.377109] [info loss: 1.471530]\n",
            "[Epoch 27/200] [Batch 822/938] [D loss: 0.294737] [G loss: 0.562600] [info loss: 1.468312]\n",
            "[Epoch 27/200] [Batch 823/938] [D loss: 0.244708] [G loss: 0.354067] [info loss: 1.470304]\n",
            "[Epoch 27/200] [Batch 824/938] [D loss: 0.268152] [G loss: 0.247473] [info loss: 1.471064]\n",
            "[Epoch 27/200] [Batch 825/938] [D loss: 0.199830] [G loss: 0.427577] [info loss: 1.469362]\n",
            "[Epoch 27/200] [Batch 826/938] [D loss: 0.201883] [G loss: 0.359548] [info loss: 1.485685]\n",
            "[Epoch 27/200] [Batch 827/938] [D loss: 0.228881] [G loss: 0.111809] [info loss: 1.469245]\n",
            "[Epoch 27/200] [Batch 828/938] [D loss: 0.270541] [G loss: 0.180311] [info loss: 1.483561]\n",
            "[Epoch 27/200] [Batch 829/938] [D loss: 0.228973] [G loss: 0.225125] [info loss: 1.470187]\n",
            "[Epoch 27/200] [Batch 830/938] [D loss: 0.189226] [G loss: 0.225304] [info loss: 1.480011]\n",
            "[Epoch 27/200] [Batch 831/938] [D loss: 0.391914] [G loss: 0.473481] [info loss: 1.481596]\n",
            "[Epoch 27/200] [Batch 832/938] [D loss: 0.203635] [G loss: 0.428118] [info loss: 1.512055]\n",
            "[Epoch 27/200] [Batch 833/938] [D loss: 0.200503] [G loss: 0.358411] [info loss: 1.474633]\n",
            "[Epoch 27/200] [Batch 834/938] [D loss: 0.255150] [G loss: 0.449694] [info loss: 1.477474]\n",
            "[Epoch 27/200] [Batch 835/938] [D loss: 0.254558] [G loss: 0.339347] [info loss: 1.470303]\n",
            "[Epoch 27/200] [Batch 836/938] [D loss: 0.218176] [G loss: 0.296942] [info loss: 1.491949]\n",
            "[Epoch 27/200] [Batch 837/938] [D loss: 0.174016] [G loss: 0.597811] [info loss: 1.473976]\n",
            "[Epoch 27/200] [Batch 838/938] [D loss: 0.147173] [G loss: 0.305306] [info loss: 1.480008]\n",
            "[Epoch 27/200] [Batch 839/938] [D loss: 0.238896] [G loss: 0.276725] [info loss: 1.474586]\n",
            "[Epoch 27/200] [Batch 840/938] [D loss: 0.229922] [G loss: 0.432777] [info loss: 1.486534]\n",
            "[Epoch 27/200] [Batch 841/938] [D loss: 0.120422] [G loss: 0.546614] [info loss: 1.471189]\n",
            "[Epoch 27/200] [Batch 842/938] [D loss: 0.192283] [G loss: 0.377778] [info loss: 1.476598]\n",
            "[Epoch 27/200] [Batch 843/938] [D loss: 0.217935] [G loss: 0.330771] [info loss: 1.472737]\n",
            "[Epoch 27/200] [Batch 844/938] [D loss: 0.293200] [G loss: 0.324483] [info loss: 1.470392]\n",
            "[Epoch 27/200] [Batch 845/938] [D loss: 0.260335] [G loss: 0.278376] [info loss: 1.493806]\n",
            "[Epoch 27/200] [Batch 846/938] [D loss: 0.205092] [G loss: 0.224694] [info loss: 1.477750]\n",
            "[Epoch 27/200] [Batch 847/938] [D loss: 0.180770] [G loss: 0.462448] [info loss: 1.470981]\n",
            "[Epoch 27/200] [Batch 848/938] [D loss: 0.237820] [G loss: 0.812168] [info loss: 1.486605]\n",
            "[Epoch 27/200] [Batch 849/938] [D loss: 0.295035] [G loss: 0.349585] [info loss: 1.471435]\n",
            "[Epoch 27/200] [Batch 850/938] [D loss: 0.163837] [G loss: 0.258195] [info loss: 1.471589]\n",
            "[Epoch 27/200] [Batch 851/938] [D loss: 0.276663] [G loss: 0.197877] [info loss: 1.476208]\n",
            "[Epoch 27/200] [Batch 852/938] [D loss: 0.205779] [G loss: 0.521357] [info loss: 1.471336]\n",
            "[Epoch 27/200] [Batch 853/938] [D loss: 0.212456] [G loss: 0.438359] [info loss: 1.484443]\n",
            "[Epoch 27/200] [Batch 854/938] [D loss: 0.218669] [G loss: 0.389808] [info loss: 1.471460]\n",
            "[Epoch 27/200] [Batch 855/938] [D loss: 0.211790] [G loss: 0.165162] [info loss: 1.482366]\n",
            "[Epoch 27/200] [Batch 856/938] [D loss: 0.166035] [G loss: 0.441038] [info loss: 1.476517]\n",
            "[Epoch 27/200] [Batch 857/938] [D loss: 0.157572] [G loss: 0.425297] [info loss: 1.473790]\n",
            "[Epoch 27/200] [Batch 858/938] [D loss: 0.209805] [G loss: 0.529522] [info loss: 1.488294]\n",
            "[Epoch 27/200] [Batch 859/938] [D loss: 0.223057] [G loss: 0.194995] [info loss: 1.475930]\n",
            "[Epoch 27/200] [Batch 860/938] [D loss: 0.242252] [G loss: 0.302376] [info loss: 1.489507]\n",
            "[Epoch 27/200] [Batch 861/938] [D loss: 0.417605] [G loss: 0.387980] [info loss: 1.478381]\n",
            "[Epoch 27/200] [Batch 862/938] [D loss: 0.283669] [G loss: 0.295624] [info loss: 1.474569]\n",
            "[Epoch 27/200] [Batch 863/938] [D loss: 0.203502] [G loss: 0.219961] [info loss: 1.483906]\n",
            "[Epoch 27/200] [Batch 864/938] [D loss: 0.208805] [G loss: 0.301869] [info loss: 1.471963]\n",
            "[Epoch 27/200] [Batch 865/938] [D loss: 0.248376] [G loss: 0.407590] [info loss: 1.473374]\n",
            "[Epoch 27/200] [Batch 866/938] [D loss: 0.153392] [G loss: 0.263453] [info loss: 1.468464]\n",
            "[Epoch 27/200] [Batch 867/938] [D loss: 0.282998] [G loss: 0.380066] [info loss: 1.476544]\n",
            "[Epoch 27/200] [Batch 868/938] [D loss: 0.185119] [G loss: 0.221573] [info loss: 1.471924]\n",
            "[Epoch 27/200] [Batch 869/938] [D loss: 0.150695] [G loss: 0.509961] [info loss: 1.469796]\n",
            "[Epoch 27/200] [Batch 870/938] [D loss: 0.241465] [G loss: 0.474665] [info loss: 1.476726]\n",
            "[Epoch 27/200] [Batch 871/938] [D loss: 0.200392] [G loss: 0.452880] [info loss: 1.471017]\n",
            "[Epoch 27/200] [Batch 872/938] [D loss: 0.151444] [G loss: 0.356258] [info loss: 1.484601]\n",
            "[Epoch 27/200] [Batch 873/938] [D loss: 0.232897] [G loss: 0.388574] [info loss: 1.490419]\n",
            "[Epoch 27/200] [Batch 874/938] [D loss: 0.297992] [G loss: 0.335430] [info loss: 1.474238]\n",
            "[Epoch 27/200] [Batch 875/938] [D loss: 0.202605] [G loss: 0.215962] [info loss: 1.474089]\n",
            "[Epoch 27/200] [Batch 876/938] [D loss: 0.243600] [G loss: 0.275090] [info loss: 1.473632]\n",
            "[Epoch 27/200] [Batch 877/938] [D loss: 0.275238] [G loss: 0.261200] [info loss: 1.469858]\n",
            "[Epoch 27/200] [Batch 878/938] [D loss: 0.195471] [G loss: 0.404454] [info loss: 1.485625]\n",
            "[Epoch 27/200] [Batch 879/938] [D loss: 0.183626] [G loss: 0.427589] [info loss: 1.514767]\n",
            "[Epoch 27/200] [Batch 880/938] [D loss: 0.193722] [G loss: 0.355044] [info loss: 1.468762]\n",
            "[Epoch 27/200] [Batch 881/938] [D loss: 0.218537] [G loss: 0.323706] [info loss: 1.470029]\n",
            "[Epoch 27/200] [Batch 882/938] [D loss: 0.243006] [G loss: 0.314631] [info loss: 1.470955]\n",
            "[Epoch 27/200] [Batch 883/938] [D loss: 0.270467] [G loss: 0.234160] [info loss: 1.479805]\n",
            "[Epoch 27/200] [Batch 884/938] [D loss: 0.298869] [G loss: 0.365941] [info loss: 1.470745]\n",
            "[Epoch 27/200] [Batch 885/938] [D loss: 0.292163] [G loss: 0.350102] [info loss: 1.486976]\n",
            "[Epoch 27/200] [Batch 886/938] [D loss: 0.284557] [G loss: 0.492235] [info loss: 1.468714]\n",
            "[Epoch 27/200] [Batch 887/938] [D loss: 0.270816] [G loss: 0.351137] [info loss: 1.474077]\n",
            "[Epoch 27/200] [Batch 888/938] [D loss: 0.150349] [G loss: 0.265911] [info loss: 1.482932]\n",
            "[Epoch 27/200] [Batch 889/938] [D loss: 0.131123] [G loss: 0.272305] [info loss: 1.471683]\n",
            "[Epoch 27/200] [Batch 890/938] [D loss: 0.185775] [G loss: 0.508636] [info loss: 1.471389]\n",
            "[Epoch 27/200] [Batch 891/938] [D loss: 0.106127] [G loss: 0.397849] [info loss: 1.482916]\n",
            "[Epoch 27/200] [Batch 892/938] [D loss: 0.277238] [G loss: 0.405350] [info loss: 1.475548]\n",
            "[Epoch 27/200] [Batch 893/938] [D loss: 0.224541] [G loss: 0.159676] [info loss: 1.503014]\n",
            "[Epoch 27/200] [Batch 894/938] [D loss: 0.185650] [G loss: 0.295347] [info loss: 1.515902]\n",
            "[Epoch 27/200] [Batch 895/938] [D loss: 0.152427] [G loss: 0.363723] [info loss: 1.470954]\n",
            "[Epoch 27/200] [Batch 896/938] [D loss: 0.158647] [G loss: 0.197650] [info loss: 1.480713]\n",
            "[Epoch 27/200] [Batch 897/938] [D loss: 0.137498] [G loss: 0.209643] [info loss: 1.476829]\n",
            "[Epoch 27/200] [Batch 898/938] [D loss: 0.224253] [G loss: 0.594356] [info loss: 1.474488]\n",
            "[Epoch 27/200] [Batch 899/938] [D loss: 0.181576] [G loss: 0.294043] [info loss: 1.473468]\n",
            "[Epoch 27/200] [Batch 900/938] [D loss: 0.238434] [G loss: 0.226582] [info loss: 1.478182]\n",
            "[Epoch 27/200] [Batch 901/938] [D loss: 0.219868] [G loss: 0.299457] [info loss: 1.484698]\n",
            "[Epoch 27/200] [Batch 902/938] [D loss: 0.131273] [G loss: 0.458931] [info loss: 1.494366]\n",
            "[Epoch 27/200] [Batch 903/938] [D loss: 0.203719] [G loss: 0.425828] [info loss: 1.473182]\n",
            "[Epoch 27/200] [Batch 904/938] [D loss: 0.171880] [G loss: 0.183538] [info loss: 1.472267]\n",
            "[Epoch 27/200] [Batch 905/938] [D loss: 0.343859] [G loss: 0.218377] [info loss: 1.478767]\n",
            "[Epoch 27/200] [Batch 906/938] [D loss: 0.297442] [G loss: 0.291490] [info loss: 1.469667]\n",
            "[Epoch 27/200] [Batch 907/938] [D loss: 0.192410] [G loss: 0.408068] [info loss: 1.495874]\n",
            "[Epoch 27/200] [Batch 908/938] [D loss: 0.193446] [G loss: 0.373777] [info loss: 1.470956]\n",
            "[Epoch 27/200] [Batch 909/938] [D loss: 0.272973] [G loss: 0.231637] [info loss: 1.493222]\n",
            "[Epoch 27/200] [Batch 910/938] [D loss: 0.162716] [G loss: 0.176353] [info loss: 1.485645]\n",
            "[Epoch 27/200] [Batch 911/938] [D loss: 0.221567] [G loss: 0.354235] [info loss: 1.502148]\n",
            "[Epoch 27/200] [Batch 912/938] [D loss: 0.176222] [G loss: 0.398832] [info loss: 1.486522]\n",
            "[Epoch 27/200] [Batch 913/938] [D loss: 0.175717] [G loss: 0.351150] [info loss: 1.484560]\n",
            "[Epoch 27/200] [Batch 914/938] [D loss: 0.162176] [G loss: 0.471855] [info loss: 1.470607]\n",
            "[Epoch 27/200] [Batch 915/938] [D loss: 0.202775] [G loss: 0.445166] [info loss: 1.470195]\n",
            "[Epoch 27/200] [Batch 916/938] [D loss: 0.202595] [G loss: 0.653595] [info loss: 1.483987]\n",
            "[Epoch 27/200] [Batch 917/938] [D loss: 0.250397] [G loss: 0.355298] [info loss: 1.483359]\n",
            "[Epoch 27/200] [Batch 918/938] [D loss: 0.143781] [G loss: 0.526306] [info loss: 1.473353]\n",
            "[Epoch 27/200] [Batch 919/938] [D loss: 0.189644] [G loss: 0.270179] [info loss: 1.494254]\n",
            "[Epoch 27/200] [Batch 920/938] [D loss: 0.190676] [G loss: 0.273952] [info loss: 1.475822]\n",
            "[Epoch 27/200] [Batch 921/938] [D loss: 0.243024] [G loss: 0.421023] [info loss: 1.487220]\n",
            "[Epoch 27/200] [Batch 922/938] [D loss: 0.278024] [G loss: 0.270267] [info loss: 1.470524]\n",
            "[Epoch 27/200] [Batch 923/938] [D loss: 0.099861] [G loss: 0.585663] [info loss: 1.469730]\n",
            "[Epoch 27/200] [Batch 924/938] [D loss: 0.329719] [G loss: 0.429423] [info loss: 1.486395]\n",
            "[Epoch 27/200] [Batch 925/938] [D loss: 0.265049] [G loss: 0.349505] [info loss: 1.481492]\n",
            "[Epoch 27/200] [Batch 926/938] [D loss: 0.251965] [G loss: 0.394487] [info loss: 1.496623]\n",
            "[Epoch 27/200] [Batch 927/938] [D loss: 0.201960] [G loss: 0.458138] [info loss: 1.503886]\n",
            "[Epoch 27/200] [Batch 928/938] [D loss: 0.298865] [G loss: 0.480705] [info loss: 1.474975]\n",
            "[Epoch 27/200] [Batch 929/938] [D loss: 0.230006] [G loss: 0.481618] [info loss: 1.483734]\n",
            "[Epoch 27/200] [Batch 930/938] [D loss: 0.165513] [G loss: 0.339799] [info loss: 1.472493]\n",
            "[Epoch 27/200] [Batch 931/938] [D loss: 0.155268] [G loss: 0.400908] [info loss: 1.472867]\n",
            "[Epoch 27/200] [Batch 932/938] [D loss: 0.195456] [G loss: 0.394806] [info loss: 1.487808]\n",
            "[Epoch 27/200] [Batch 933/938] [D loss: 0.244852] [G loss: 0.424819] [info loss: 1.498584]\n",
            "[Epoch 27/200] [Batch 934/938] [D loss: 0.196164] [G loss: 0.543133] [info loss: 1.470841]\n",
            "[Epoch 27/200] [Batch 935/938] [D loss: 0.225968] [G loss: 0.292285] [info loss: 1.482653]\n",
            "[Epoch 27/200] [Batch 936/938] [D loss: 0.229699] [G loss: 0.387885] [info loss: 1.472453]\n",
            "[Epoch 27/200] [Batch 937/938] [D loss: 0.278512] [G loss: 0.430703] [info loss: 1.470584]\n",
            "[Epoch 28/200] [Batch 0/938] [D loss: 0.185533] [G loss: 0.234482] [info loss: 1.487640]\n",
            "[Epoch 28/200] [Batch 1/938] [D loss: 0.233562] [G loss: 0.303804] [info loss: 1.471859]\n",
            "[Epoch 28/200] [Batch 2/938] [D loss: 0.325265] [G loss: 0.359749] [info loss: 1.471996]\n",
            "[Epoch 28/200] [Batch 3/938] [D loss: 0.315664] [G loss: 0.440821] [info loss: 1.489785]\n",
            "[Epoch 28/200] [Batch 4/938] [D loss: 0.228734] [G loss: 0.334210] [info loss: 1.488165]\n",
            "[Epoch 28/200] [Batch 5/938] [D loss: 0.209259] [G loss: 0.517176] [info loss: 1.470664]\n",
            "[Epoch 28/200] [Batch 6/938] [D loss: 0.183717] [G loss: 0.227614] [info loss: 1.471593]\n",
            "[Epoch 28/200] [Batch 7/938] [D loss: 0.159825] [G loss: 0.251197] [info loss: 1.490580]\n",
            "[Epoch 28/200] [Batch 8/938] [D loss: 0.252021] [G loss: 0.371929] [info loss: 1.477779]\n",
            "[Epoch 28/200] [Batch 9/938] [D loss: 0.189950] [G loss: 0.609091] [info loss: 1.500567]\n",
            "[Epoch 28/200] [Batch 10/938] [D loss: 0.186498] [G loss: 0.323287] [info loss: 1.483006]\n",
            "[Epoch 28/200] [Batch 11/938] [D loss: 0.220874] [G loss: 0.312975] [info loss: 1.472808]\n",
            "[Epoch 28/200] [Batch 12/938] [D loss: 0.166618] [G loss: 0.538907] [info loss: 1.491904]\n",
            "[Epoch 28/200] [Batch 13/938] [D loss: 0.195982] [G loss: 0.363377] [info loss: 1.476630]\n",
            "[Epoch 28/200] [Batch 14/938] [D loss: 0.303947] [G loss: 0.299168] [info loss: 1.471184]\n",
            "[Epoch 28/200] [Batch 15/938] [D loss: 0.197666] [G loss: 0.379659] [info loss: 1.469767]\n",
            "[Epoch 28/200] [Batch 16/938] [D loss: 0.251888] [G loss: 0.322503] [info loss: 1.474656]\n",
            "[Epoch 28/200] [Batch 17/938] [D loss: 0.192294] [G loss: 0.474637] [info loss: 1.484295]\n",
            "[Epoch 28/200] [Batch 18/938] [D loss: 0.267729] [G loss: 0.423976] [info loss: 1.492136]\n",
            "[Epoch 28/200] [Batch 19/938] [D loss: 0.268859] [G loss: 0.230859] [info loss: 1.479640]\n",
            "[Epoch 28/200] [Batch 20/938] [D loss: 0.213931] [G loss: 0.187713] [info loss: 1.472867]\n",
            "[Epoch 28/200] [Batch 21/938] [D loss: 0.170192] [G loss: 0.334831] [info loss: 1.471945]\n",
            "[Epoch 28/200] [Batch 22/938] [D loss: 0.238885] [G loss: 0.338852] [info loss: 1.506889]\n",
            "[Epoch 28/200] [Batch 23/938] [D loss: 0.130688] [G loss: 0.333854] [info loss: 1.470461]\n",
            "[Epoch 28/200] [Batch 24/938] [D loss: 0.238376] [G loss: 0.313393] [info loss: 1.486698]\n",
            "[Epoch 28/200] [Batch 25/938] [D loss: 0.182184] [G loss: 0.235101] [info loss: 1.477990]\n",
            "[Epoch 28/200] [Batch 26/938] [D loss: 0.183592] [G loss: 0.396220] [info loss: 1.493013]\n",
            "[Epoch 28/200] [Batch 27/938] [D loss: 0.305310] [G loss: 0.273295] [info loss: 1.482550]\n",
            "[Epoch 28/200] [Batch 28/938] [D loss: 0.336951] [G loss: 0.306994] [info loss: 1.472124]\n",
            "[Epoch 28/200] [Batch 29/938] [D loss: 0.169783] [G loss: 0.362164] [info loss: 1.473646]\n",
            "[Epoch 28/200] [Batch 30/938] [D loss: 0.208394] [G loss: 0.383926] [info loss: 1.484690]\n",
            "[Epoch 28/200] [Batch 31/938] [D loss: 0.260074] [G loss: 0.368910] [info loss: 1.470034]\n",
            "[Epoch 28/200] [Batch 32/938] [D loss: 0.192084] [G loss: 0.220186] [info loss: 1.501647]\n",
            "[Epoch 28/200] [Batch 33/938] [D loss: 0.182730] [G loss: 0.149681] [info loss: 1.472833]\n",
            "[Epoch 28/200] [Batch 34/938] [D loss: 0.275867] [G loss: 0.238733] [info loss: 1.523897]\n",
            "[Epoch 28/200] [Batch 35/938] [D loss: 0.207493] [G loss: 0.166126] [info loss: 1.488990]\n",
            "[Epoch 28/200] [Batch 36/938] [D loss: 0.211713] [G loss: 0.346581] [info loss: 1.503198]\n",
            "[Epoch 28/200] [Batch 37/938] [D loss: 0.278165] [G loss: 0.237954] [info loss: 1.485630]\n",
            "[Epoch 28/200] [Batch 38/938] [D loss: 0.257033] [G loss: 0.315696] [info loss: 1.487743]\n",
            "[Epoch 28/200] [Batch 39/938] [D loss: 0.213791] [G loss: 0.323539] [info loss: 1.490894]\n",
            "[Epoch 28/200] [Batch 40/938] [D loss: 0.202803] [G loss: 0.270983] [info loss: 1.469861]\n",
            "[Epoch 28/200] [Batch 41/938] [D loss: 0.259579] [G loss: 0.686714] [info loss: 1.472170]\n",
            "[Epoch 28/200] [Batch 42/938] [D loss: 0.373228] [G loss: 0.355380] [info loss: 1.490120]\n",
            "[Epoch 28/200] [Batch 43/938] [D loss: 0.114631] [G loss: 0.269894] [info loss: 1.468622]\n",
            "[Epoch 28/200] [Batch 44/938] [D loss: 0.090191] [G loss: 0.307181] [info loss: 1.479216]\n",
            "[Epoch 28/200] [Batch 45/938] [D loss: 0.347648] [G loss: 0.410499] [info loss: 1.471966]\n",
            "[Epoch 28/200] [Batch 46/938] [D loss: 0.155766] [G loss: 0.363868] [info loss: 1.476957]\n",
            "[Epoch 28/200] [Batch 47/938] [D loss: 0.250236] [G loss: 0.297992] [info loss: 1.501753]\n",
            "[Epoch 28/200] [Batch 48/938] [D loss: 0.161038] [G loss: 0.269928] [info loss: 1.485959]\n",
            "[Epoch 28/200] [Batch 49/938] [D loss: 0.174087] [G loss: 0.211106] [info loss: 1.474526]\n",
            "[Epoch 28/200] [Batch 50/938] [D loss: 0.135629] [G loss: 0.129926] [info loss: 1.482545]\n",
            "[Epoch 28/200] [Batch 51/938] [D loss: 0.187238] [G loss: 0.297411] [info loss: 1.486360]\n",
            "[Epoch 28/200] [Batch 52/938] [D loss: 0.220601] [G loss: 0.259257] [info loss: 1.477604]\n",
            "[Epoch 28/200] [Batch 53/938] [D loss: 0.176665] [G loss: 0.309912] [info loss: 1.472408]\n",
            "[Epoch 28/200] [Batch 54/938] [D loss: 0.222224] [G loss: 0.281791] [info loss: 1.491737]\n",
            "[Epoch 28/200] [Batch 55/938] [D loss: 0.313472] [G loss: 0.250436] [info loss: 1.502560]\n",
            "[Epoch 28/200] [Batch 56/938] [D loss: 0.269714] [G loss: 0.217381] [info loss: 1.502533]\n",
            "[Epoch 28/200] [Batch 57/938] [D loss: 0.186799] [G loss: 0.488385] [info loss: 1.471294]\n",
            "[Epoch 28/200] [Batch 58/938] [D loss: 0.211383] [G loss: 0.663446] [info loss: 1.486288]\n",
            "[Epoch 28/200] [Batch 59/938] [D loss: 0.220890] [G loss: 0.140489] [info loss: 1.470081]\n",
            "[Epoch 28/200] [Batch 60/938] [D loss: 0.186857] [G loss: 0.254953] [info loss: 1.478627]\n",
            "[Epoch 28/200] [Batch 61/938] [D loss: 0.237382] [G loss: 0.273953] [info loss: 1.475583]\n",
            "[Epoch 28/200] [Batch 62/938] [D loss: 0.203439] [G loss: 0.561343] [info loss: 1.469412]\n",
            "[Epoch 28/200] [Batch 63/938] [D loss: 0.361460] [G loss: 0.329913] [info loss: 1.470094]\n",
            "[Epoch 28/200] [Batch 64/938] [D loss: 0.252172] [G loss: 0.422913] [info loss: 1.470000]\n",
            "[Epoch 28/200] [Batch 65/938] [D loss: 0.234395] [G loss: 0.467896] [info loss: 1.475932]\n",
            "[Epoch 28/200] [Batch 66/938] [D loss: 0.196648] [G loss: 0.303430] [info loss: 1.485902]\n",
            "[Epoch 28/200] [Batch 67/938] [D loss: 0.204945] [G loss: 0.342063] [info loss: 1.491169]\n",
            "[Epoch 28/200] [Batch 68/938] [D loss: 0.286020] [G loss: 0.409772] [info loss: 1.494065]\n",
            "[Epoch 28/200] [Batch 69/938] [D loss: 0.265237] [G loss: 0.216375] [info loss: 1.480413]\n",
            "[Epoch 28/200] [Batch 70/938] [D loss: 0.164354] [G loss: 0.265242] [info loss: 1.483021]\n",
            "[Epoch 28/200] [Batch 71/938] [D loss: 0.241205] [G loss: 0.226889] [info loss: 1.482186]\n",
            "[Epoch 28/200] [Batch 72/938] [D loss: 0.164147] [G loss: 0.302322] [info loss: 1.485287]\n",
            "[Epoch 28/200] [Batch 73/938] [D loss: 0.122880] [G loss: 0.353693] [info loss: 1.471496]\n",
            "[Epoch 28/200] [Batch 74/938] [D loss: 0.251430] [G loss: 0.419233] [info loss: 1.478765]\n",
            "[Epoch 28/200] [Batch 75/938] [D loss: 0.241759] [G loss: 0.473440] [info loss: 1.474638]\n",
            "[Epoch 28/200] [Batch 76/938] [D loss: 0.149800] [G loss: 0.416368] [info loss: 1.472167]\n",
            "[Epoch 28/200] [Batch 77/938] [D loss: 0.156829] [G loss: 0.277736] [info loss: 1.473545]\n",
            "[Epoch 28/200] [Batch 78/938] [D loss: 0.384997] [G loss: 0.231011] [info loss: 1.469637]\n",
            "[Epoch 28/200] [Batch 79/938] [D loss: 0.142759] [G loss: 0.260382] [info loss: 1.479466]\n",
            "[Epoch 28/200] [Batch 80/938] [D loss: 0.214596] [G loss: 0.194438] [info loss: 1.474711]\n",
            "[Epoch 28/200] [Batch 81/938] [D loss: 0.170401] [G loss: 0.365686] [info loss: 1.470718]\n",
            "[Epoch 28/200] [Batch 82/938] [D loss: 0.326798] [G loss: 0.287183] [info loss: 1.475439]\n",
            "[Epoch 28/200] [Batch 83/938] [D loss: 0.199915] [G loss: 0.362745] [info loss: 1.469780]\n",
            "[Epoch 28/200] [Batch 84/938] [D loss: 0.152024] [G loss: 0.209746] [info loss: 1.484629]\n",
            "[Epoch 28/200] [Batch 85/938] [D loss: 0.244814] [G loss: 0.386758] [info loss: 1.484827]\n",
            "[Epoch 28/200] [Batch 86/938] [D loss: 0.181785] [G loss: 0.287656] [info loss: 1.470180]\n",
            "[Epoch 28/200] [Batch 87/938] [D loss: 0.194340] [G loss: 0.342515] [info loss: 1.469989]\n",
            "[Epoch 28/200] [Batch 88/938] [D loss: 0.339171] [G loss: 0.460051] [info loss: 1.475191]\n",
            "[Epoch 28/200] [Batch 89/938] [D loss: 0.258810] [G loss: 0.405457] [info loss: 1.469751]\n",
            "[Epoch 28/200] [Batch 90/938] [D loss: 0.262290] [G loss: 0.304963] [info loss: 1.471193]\n",
            "[Epoch 28/200] [Batch 91/938] [D loss: 0.221555] [G loss: 0.458962] [info loss: 1.474223]\n",
            "[Epoch 28/200] [Batch 92/938] [D loss: 0.134326] [G loss: 0.477325] [info loss: 1.477960]\n",
            "[Epoch 28/200] [Batch 93/938] [D loss: 0.319807] [G loss: 0.469423] [info loss: 1.480989]\n",
            "[Epoch 28/200] [Batch 94/938] [D loss: 0.193715] [G loss: 0.315155] [info loss: 1.485388]\n",
            "[Epoch 28/200] [Batch 95/938] [D loss: 0.290224] [G loss: 0.488991] [info loss: 1.482109]\n",
            "[Epoch 28/200] [Batch 96/938] [D loss: 0.241676] [G loss: 0.336509] [info loss: 1.470299]\n",
            "[Epoch 28/200] [Batch 97/938] [D loss: 0.217087] [G loss: 0.195748] [info loss: 1.470284]\n",
            "[Epoch 28/200] [Batch 98/938] [D loss: 0.361525] [G loss: 0.301275] [info loss: 1.488557]\n",
            "[Epoch 28/200] [Batch 99/938] [D loss: 0.199726] [G loss: 0.299708] [info loss: 1.473524]\n",
            "[Epoch 28/200] [Batch 100/938] [D loss: 0.186109] [G loss: 0.299123] [info loss: 1.469749]\n",
            "[Epoch 28/200] [Batch 101/938] [D loss: 0.122771] [G loss: 0.472145] [info loss: 1.470669]\n",
            "[Epoch 28/200] [Batch 102/938] [D loss: 0.201388] [G loss: 0.230888] [info loss: 1.469716]\n",
            "[Epoch 28/200] [Batch 103/938] [D loss: 0.208983] [G loss: 0.397921] [info loss: 1.477347]\n",
            "[Epoch 28/200] [Batch 104/938] [D loss: 0.153432] [G loss: 0.411976] [info loss: 1.470262]\n",
            "[Epoch 28/200] [Batch 105/938] [D loss: 0.327612] [G loss: 0.478652] [info loss: 1.472960]\n",
            "[Epoch 28/200] [Batch 106/938] [D loss: 0.210194] [G loss: 0.151364] [info loss: 1.482579]\n",
            "[Epoch 28/200] [Batch 107/938] [D loss: 0.275432] [G loss: 0.477422] [info loss: 1.471352]\n",
            "[Epoch 28/200] [Batch 108/938] [D loss: 0.149468] [G loss: 0.248609] [info loss: 1.482594]\n",
            "[Epoch 28/200] [Batch 109/938] [D loss: 0.176426] [G loss: 0.448142] [info loss: 1.486458]\n",
            "[Epoch 28/200] [Batch 110/938] [D loss: 0.274913] [G loss: 0.369159] [info loss: 1.470712]\n",
            "[Epoch 28/200] [Batch 111/938] [D loss: 0.185328] [G loss: 0.341345] [info loss: 1.486475]\n",
            "[Epoch 28/200] [Batch 112/938] [D loss: 0.267358] [G loss: 0.408464] [info loss: 1.471405]\n",
            "[Epoch 28/200] [Batch 113/938] [D loss: 0.202456] [G loss: 0.402099] [info loss: 1.472484]\n",
            "[Epoch 28/200] [Batch 114/938] [D loss: 0.110952] [G loss: 0.336254] [info loss: 1.472661]\n",
            "[Epoch 28/200] [Batch 115/938] [D loss: 0.212899] [G loss: 0.385945] [info loss: 1.470918]\n",
            "[Epoch 28/200] [Batch 116/938] [D loss: 0.226735] [G loss: 0.245486] [info loss: 1.469702]\n",
            "[Epoch 28/200] [Batch 117/938] [D loss: 0.205479] [G loss: 0.249360] [info loss: 1.468157]\n",
            "[Epoch 28/200] [Batch 118/938] [D loss: 0.193880] [G loss: 0.287713] [info loss: 1.469211]\n",
            "[Epoch 28/200] [Batch 119/938] [D loss: 0.287015] [G loss: 0.275431] [info loss: 1.469565]\n",
            "[Epoch 28/200] [Batch 120/938] [D loss: 0.305600] [G loss: 0.385626] [info loss: 1.480696]\n",
            "[Epoch 28/200] [Batch 121/938] [D loss: 0.271179] [G loss: 0.269264] [info loss: 1.471895]\n",
            "[Epoch 28/200] [Batch 122/938] [D loss: 0.248984] [G loss: 0.514575] [info loss: 1.481188]\n",
            "[Epoch 28/200] [Batch 123/938] [D loss: 0.265765] [G loss: 0.474264] [info loss: 1.474997]\n",
            "[Epoch 28/200] [Batch 124/938] [D loss: 0.220942] [G loss: 0.287372] [info loss: 1.473626]\n",
            "[Epoch 28/200] [Batch 125/938] [D loss: 0.234042] [G loss: 0.290963] [info loss: 1.492705]\n",
            "[Epoch 28/200] [Batch 126/938] [D loss: 0.138954] [G loss: 0.200336] [info loss: 1.481682]\n",
            "[Epoch 28/200] [Batch 127/938] [D loss: 0.236645] [G loss: 0.351717] [info loss: 1.473238]\n",
            "[Epoch 28/200] [Batch 128/938] [D loss: 0.262069] [G loss: 0.209717] [info loss: 1.472320]\n",
            "[Epoch 28/200] [Batch 129/938] [D loss: 0.182301] [G loss: 0.277168] [info loss: 1.470692]\n",
            "[Epoch 28/200] [Batch 130/938] [D loss: 0.258212] [G loss: 0.415418] [info loss: 1.501320]\n",
            "[Epoch 28/200] [Batch 131/938] [D loss: 0.161626] [G loss: 0.495502] [info loss: 1.505331]\n",
            "[Epoch 28/200] [Batch 132/938] [D loss: 0.137511] [G loss: 0.238561] [info loss: 1.500769]\n",
            "[Epoch 28/200] [Batch 133/938] [D loss: 0.168557] [G loss: 0.190120] [info loss: 1.478105]\n",
            "[Epoch 28/200] [Batch 134/938] [D loss: 0.149770] [G loss: 0.304339] [info loss: 1.467550]\n",
            "[Epoch 28/200] [Batch 135/938] [D loss: 0.257217] [G loss: 0.232738] [info loss: 1.476939]\n",
            "[Epoch 28/200] [Batch 136/938] [D loss: 0.314533] [G loss: 0.268530] [info loss: 1.476102]\n",
            "[Epoch 28/200] [Batch 137/938] [D loss: 0.161889] [G loss: 0.355171] [info loss: 1.473680]\n",
            "[Epoch 28/200] [Batch 138/938] [D loss: 0.147814] [G loss: 0.237712] [info loss: 1.469846]\n",
            "[Epoch 28/200] [Batch 139/938] [D loss: 0.230602] [G loss: 0.232468] [info loss: 1.496809]\n",
            "[Epoch 28/200] [Batch 140/938] [D loss: 0.198700] [G loss: 0.272676] [info loss: 1.481611]\n",
            "[Epoch 28/200] [Batch 141/938] [D loss: 0.191190] [G loss: 0.290492] [info loss: 1.469453]\n",
            "[Epoch 28/200] [Batch 142/938] [D loss: 0.178777] [G loss: 0.592869] [info loss: 1.474685]\n",
            "[Epoch 28/200] [Batch 143/938] [D loss: 0.185124] [G loss: 0.354225] [info loss: 1.469249]\n",
            "[Epoch 28/200] [Batch 144/938] [D loss: 0.174933] [G loss: 0.414919] [info loss: 1.468380]\n",
            "[Epoch 28/200] [Batch 145/938] [D loss: 0.201345] [G loss: 0.500823] [info loss: 1.474983]\n",
            "[Epoch 28/200] [Batch 146/938] [D loss: 0.286166] [G loss: 0.315767] [info loss: 1.470581]\n",
            "[Epoch 28/200] [Batch 147/938] [D loss: 0.173786] [G loss: 0.163953] [info loss: 1.482251]\n",
            "[Epoch 28/200] [Batch 148/938] [D loss: 0.316698] [G loss: 0.470158] [info loss: 1.477593]\n",
            "[Epoch 28/200] [Batch 149/938] [D loss: 0.229653] [G loss: 0.386890] [info loss: 1.472817]\n",
            "[Epoch 28/200] [Batch 150/938] [D loss: 0.240606] [G loss: 0.224845] [info loss: 1.472806]\n",
            "[Epoch 28/200] [Batch 151/938] [D loss: 0.311153] [G loss: 0.273565] [info loss: 1.470796]\n",
            "[Epoch 28/200] [Batch 152/938] [D loss: 0.176027] [G loss: 0.450537] [info loss: 1.489405]\n",
            "[Epoch 28/200] [Batch 153/938] [D loss: 0.210380] [G loss: 0.294427] [info loss: 1.471994]\n",
            "[Epoch 28/200] [Batch 154/938] [D loss: 0.343469] [G loss: 0.262282] [info loss: 1.473013]\n",
            "[Epoch 28/200] [Batch 155/938] [D loss: 0.263991] [G loss: 0.212699] [info loss: 1.492838]\n",
            "[Epoch 28/200] [Batch 156/938] [D loss: 0.260603] [G loss: 0.624320] [info loss: 1.480387]\n",
            "[Epoch 28/200] [Batch 157/938] [D loss: 0.230627] [G loss: 0.199726] [info loss: 1.487821]\n",
            "[Epoch 28/200] [Batch 158/938] [D loss: 0.201216] [G loss: 0.292535] [info loss: 1.470073]\n",
            "[Epoch 28/200] [Batch 159/938] [D loss: 0.220349] [G loss: 0.382465] [info loss: 1.469357]\n",
            "[Epoch 28/200] [Batch 160/938] [D loss: 0.135669] [G loss: 0.554089] [info loss: 1.480610]\n",
            "[Epoch 28/200] [Batch 161/938] [D loss: 0.236520] [G loss: 0.643419] [info loss: 1.470620]\n",
            "[Epoch 28/200] [Batch 162/938] [D loss: 0.212408] [G loss: 0.173833] [info loss: 1.476142]\n",
            "[Epoch 28/200] [Batch 163/938] [D loss: 0.228534] [G loss: 0.133871] [info loss: 1.487598]\n",
            "[Epoch 28/200] [Batch 164/938] [D loss: 0.242116] [G loss: 0.290257] [info loss: 1.486157]\n",
            "[Epoch 28/200] [Batch 165/938] [D loss: 0.213360] [G loss: 0.086063] [info loss: 1.473315]\n",
            "[Epoch 28/200] [Batch 166/938] [D loss: 0.238248] [G loss: 0.451454] [info loss: 1.496709]\n",
            "[Epoch 28/200] [Batch 167/938] [D loss: 0.173609] [G loss: 0.272714] [info loss: 1.470428]\n",
            "[Epoch 28/200] [Batch 168/938] [D loss: 0.197627] [G loss: 0.679150] [info loss: 1.486142]\n",
            "[Epoch 28/200] [Batch 169/938] [D loss: 0.315173] [G loss: 0.369143] [info loss: 1.470573]\n",
            "[Epoch 28/200] [Batch 170/938] [D loss: 0.177701] [G loss: 0.488066] [info loss: 1.468558]\n",
            "[Epoch 28/200] [Batch 171/938] [D loss: 0.252073] [G loss: 0.366903] [info loss: 1.475586]\n",
            "[Epoch 28/200] [Batch 172/938] [D loss: 0.179343] [G loss: 0.361350] [info loss: 1.476107]\n",
            "[Epoch 28/200] [Batch 173/938] [D loss: 0.260487] [G loss: 0.444476] [info loss: 1.487792]\n",
            "[Epoch 28/200] [Batch 174/938] [D loss: 0.388367] [G loss: 0.118393] [info loss: 1.473145]\n",
            "[Epoch 28/200] [Batch 175/938] [D loss: 0.185880] [G loss: 0.228043] [info loss: 1.471497]\n",
            "[Epoch 28/200] [Batch 176/938] [D loss: 0.207328] [G loss: 0.261640] [info loss: 1.474859]\n",
            "[Epoch 28/200] [Batch 177/938] [D loss: 0.259340] [G loss: 0.258409] [info loss: 1.473426]\n",
            "[Epoch 28/200] [Batch 178/938] [D loss: 0.280551] [G loss: 0.285794] [info loss: 1.470732]\n",
            "[Epoch 28/200] [Batch 179/938] [D loss: 0.174626] [G loss: 0.513037] [info loss: 1.490699]\n",
            "[Epoch 28/200] [Batch 180/938] [D loss: 0.109105] [G loss: 0.419349] [info loss: 1.475320]\n",
            "[Epoch 28/200] [Batch 181/938] [D loss: 0.234487] [G loss: 0.495217] [info loss: 1.501823]\n",
            "[Epoch 28/200] [Batch 182/938] [D loss: 0.196112] [G loss: 0.157450] [info loss: 1.469787]\n",
            "[Epoch 28/200] [Batch 183/938] [D loss: 0.238216] [G loss: 0.396061] [info loss: 1.472020]\n",
            "[Epoch 28/200] [Batch 184/938] [D loss: 0.159068] [G loss: 0.374761] [info loss: 1.473652]\n",
            "[Epoch 28/200] [Batch 185/938] [D loss: 0.110091] [G loss: 0.306459] [info loss: 1.472741]\n",
            "[Epoch 28/200] [Batch 186/938] [D loss: 0.240763] [G loss: 0.227905] [info loss: 1.498810]\n",
            "[Epoch 28/200] [Batch 187/938] [D loss: 0.164228] [G loss: 0.251459] [info loss: 1.482322]\n",
            "[Epoch 28/200] [Batch 188/938] [D loss: 0.203811] [G loss: 0.497366] [info loss: 1.491270]\n",
            "[Epoch 28/200] [Batch 189/938] [D loss: 0.223238] [G loss: 0.441088] [info loss: 1.468500]\n",
            "[Epoch 28/200] [Batch 190/938] [D loss: 0.190938] [G loss: 0.381018] [info loss: 1.470082]\n",
            "[Epoch 28/200] [Batch 191/938] [D loss: 0.148923] [G loss: 0.175661] [info loss: 1.479900]\n",
            "[Epoch 28/200] [Batch 192/938] [D loss: 0.209310] [G loss: 0.400581] [info loss: 1.471931]\n",
            "[Epoch 28/200] [Batch 193/938] [D loss: 0.224211] [G loss: 0.207070] [info loss: 1.486526]\n",
            "[Epoch 28/200] [Batch 194/938] [D loss: 0.250273] [G loss: 0.235770] [info loss: 1.481493]\n",
            "[Epoch 28/200] [Batch 195/938] [D loss: 0.223928] [G loss: 0.347600] [info loss: 1.473566]\n",
            "[Epoch 28/200] [Batch 196/938] [D loss: 0.406828] [G loss: 0.170083] [info loss: 1.478776]\n",
            "[Epoch 28/200] [Batch 197/938] [D loss: 0.328980] [G loss: 0.270406] [info loss: 1.472061]\n",
            "[Epoch 28/200] [Batch 198/938] [D loss: 0.209723] [G loss: 0.199408] [info loss: 1.470423]\n",
            "[Epoch 28/200] [Batch 199/938] [D loss: 0.144344] [G loss: 0.272503] [info loss: 1.486173]\n",
            "[Epoch 28/200] [Batch 200/938] [D loss: 0.095737] [G loss: 0.298008] [info loss: 1.474019]\n",
            "[Epoch 28/200] [Batch 201/938] [D loss: 0.166586] [G loss: 0.350095] [info loss: 1.471509]\n",
            "[Epoch 28/200] [Batch 202/938] [D loss: 0.159891] [G loss: 0.576769] [info loss: 1.471952]\n",
            "[Epoch 28/200] [Batch 203/938] [D loss: 0.176325] [G loss: 0.413116] [info loss: 1.478504]\n",
            "[Epoch 28/200] [Batch 204/938] [D loss: 0.209644] [G loss: 0.585824] [info loss: 1.494577]\n",
            "[Epoch 28/200] [Batch 205/938] [D loss: 0.231892] [G loss: 0.234027] [info loss: 1.481889]\n",
            "[Epoch 28/200] [Batch 206/938] [D loss: 0.289508] [G loss: 0.221601] [info loss: 1.471449]\n",
            "[Epoch 28/200] [Batch 207/938] [D loss: 0.208745] [G loss: 0.340654] [info loss: 1.470485]\n",
            "[Epoch 28/200] [Batch 208/938] [D loss: 0.193953] [G loss: 0.292347] [info loss: 1.485261]\n",
            "[Epoch 28/200] [Batch 209/938] [D loss: 0.248561] [G loss: 0.205800] [info loss: 1.470365]\n",
            "[Epoch 28/200] [Batch 210/938] [D loss: 0.220215] [G loss: 0.342133] [info loss: 1.477301]\n",
            "[Epoch 28/200] [Batch 211/938] [D loss: 0.265992] [G loss: 0.270154] [info loss: 1.474743]\n",
            "[Epoch 28/200] [Batch 212/938] [D loss: 0.350417] [G loss: 0.382726] [info loss: 1.470127]\n",
            "[Epoch 28/200] [Batch 213/938] [D loss: 0.157685] [G loss: 0.280905] [info loss: 1.484737]\n",
            "[Epoch 28/200] [Batch 214/938] [D loss: 0.244914] [G loss: 0.300427] [info loss: 1.481551]\n",
            "[Epoch 28/200] [Batch 215/938] [D loss: 0.176619] [G loss: 0.337717] [info loss: 1.486338]\n",
            "[Epoch 28/200] [Batch 216/938] [D loss: 0.216608] [G loss: 0.236230] [info loss: 1.471184]\n",
            "[Epoch 28/200] [Batch 217/938] [D loss: 0.166849] [G loss: 0.462121] [info loss: 1.473787]\n",
            "[Epoch 28/200] [Batch 218/938] [D loss: 0.218462] [G loss: 0.420964] [info loss: 1.476745]\n",
            "[Epoch 28/200] [Batch 219/938] [D loss: 0.232298] [G loss: 0.344123] [info loss: 1.486221]\n",
            "[Epoch 28/200] [Batch 220/938] [D loss: 0.247776] [G loss: 0.414459] [info loss: 1.469052]\n",
            "[Epoch 28/200] [Batch 221/938] [D loss: 0.238883] [G loss: 0.333108] [info loss: 1.471190]\n",
            "[Epoch 28/200] [Batch 222/938] [D loss: 0.192932] [G loss: 0.480435] [info loss: 1.472590]\n",
            "[Epoch 28/200] [Batch 223/938] [D loss: 0.123095] [G loss: 0.460397] [info loss: 1.474763]\n",
            "[Epoch 28/200] [Batch 224/938] [D loss: 0.161542] [G loss: 0.272274] [info loss: 1.478871]\n",
            "[Epoch 28/200] [Batch 225/938] [D loss: 0.146135] [G loss: 0.326500] [info loss: 1.470814]\n",
            "[Epoch 28/200] [Batch 226/938] [D loss: 0.201274] [G loss: 0.317581] [info loss: 1.472871]\n",
            "[Epoch 28/200] [Batch 227/938] [D loss: 0.100386] [G loss: 0.354948] [info loss: 1.478989]\n",
            "[Epoch 28/200] [Batch 228/938] [D loss: 0.181405] [G loss: 0.214437] [info loss: 1.469867]\n",
            "[Epoch 28/200] [Batch 229/938] [D loss: 0.239420] [G loss: 0.532074] [info loss: 1.482608]\n",
            "[Epoch 28/200] [Batch 230/938] [D loss: 0.246414] [G loss: 0.431956] [info loss: 1.486301]\n",
            "[Epoch 28/200] [Batch 231/938] [D loss: 0.235701] [G loss: 0.458386] [info loss: 1.489955]\n",
            "[Epoch 28/200] [Batch 232/938] [D loss: 0.207100] [G loss: 0.093395] [info loss: 1.477391]\n",
            "[Epoch 28/200] [Batch 233/938] [D loss: 0.274773] [G loss: 0.223461] [info loss: 1.471515]\n",
            "[Epoch 28/200] [Batch 234/938] [D loss: 0.258067] [G loss: 0.508719] [info loss: 1.470329]\n",
            "[Epoch 28/200] [Batch 235/938] [D loss: 0.315370] [G loss: 0.522157] [info loss: 1.473404]\n",
            "[Epoch 28/200] [Batch 236/938] [D loss: 0.218279] [G loss: 0.207213] [info loss: 1.471331]\n",
            "[Epoch 28/200] [Batch 237/938] [D loss: 0.143140] [G loss: 0.342795] [info loss: 1.469791]\n",
            "[Epoch 28/200] [Batch 238/938] [D loss: 0.191876] [G loss: 0.226698] [info loss: 1.470505]\n",
            "[Epoch 28/200] [Batch 239/938] [D loss: 0.214973] [G loss: 0.276267] [info loss: 1.477428]\n",
            "[Epoch 28/200] [Batch 240/938] [D loss: 0.147033] [G loss: 0.361868] [info loss: 1.482699]\n",
            "[Epoch 28/200] [Batch 241/938] [D loss: 0.222270] [G loss: 0.365883] [info loss: 1.495507]\n",
            "[Epoch 28/200] [Batch 242/938] [D loss: 0.210133] [G loss: 0.334113] [info loss: 1.486729]\n",
            "[Epoch 28/200] [Batch 243/938] [D loss: 0.202496] [G loss: 0.318601] [info loss: 1.478862]\n",
            "[Epoch 28/200] [Batch 244/938] [D loss: 0.184384] [G loss: 0.276615] [info loss: 1.470051]\n",
            "[Epoch 28/200] [Batch 245/938] [D loss: 0.236929] [G loss: 0.356108] [info loss: 1.490121]\n",
            "[Epoch 28/200] [Batch 246/938] [D loss: 0.323849] [G loss: 0.335669] [info loss: 1.486614]\n",
            "[Epoch 28/200] [Batch 247/938] [D loss: 0.237386] [G loss: 0.336665] [info loss: 1.479847]\n",
            "[Epoch 28/200] [Batch 248/938] [D loss: 0.191807] [G loss: 0.404060] [info loss: 1.500738]\n",
            "[Epoch 28/200] [Batch 249/938] [D loss: 0.224711] [G loss: 0.406035] [info loss: 1.472094]\n",
            "[Epoch 28/200] [Batch 250/938] [D loss: 0.330315] [G loss: 0.365072] [info loss: 1.494948]\n",
            "[Epoch 28/200] [Batch 251/938] [D loss: 0.190309] [G loss: 0.350745] [info loss: 1.480132]\n",
            "[Epoch 28/200] [Batch 252/938] [D loss: 0.185761] [G loss: 0.240708] [info loss: 1.474001]\n",
            "[Epoch 28/200] [Batch 253/938] [D loss: 0.130988] [G loss: 0.199518] [info loss: 1.486969]\n",
            "[Epoch 28/200] [Batch 254/938] [D loss: 0.170437] [G loss: 0.375581] [info loss: 1.519972]\n",
            "[Epoch 28/200] [Batch 255/938] [D loss: 0.216537] [G loss: 0.399202] [info loss: 1.482639]\n",
            "[Epoch 28/200] [Batch 256/938] [D loss: 0.215930] [G loss: 0.214047] [info loss: 1.473509]\n",
            "[Epoch 28/200] [Batch 257/938] [D loss: 0.194877] [G loss: 0.615355] [info loss: 1.498338]\n",
            "[Epoch 28/200] [Batch 258/938] [D loss: 0.199042] [G loss: 0.272387] [info loss: 1.470536]\n",
            "[Epoch 28/200] [Batch 259/938] [D loss: 0.286394] [G loss: 0.305898] [info loss: 1.477664]\n",
            "[Epoch 28/200] [Batch 260/938] [D loss: 0.175781] [G loss: 0.515586] [info loss: 1.477243]\n",
            "[Epoch 28/200] [Batch 261/938] [D loss: 0.239982] [G loss: 0.397441] [info loss: 1.471211]\n",
            "[Epoch 28/200] [Batch 262/938] [D loss: 0.165122] [G loss: 0.256613] [info loss: 1.472080]\n",
            "[Epoch 28/200] [Batch 263/938] [D loss: 0.314623] [G loss: 0.277694] [info loss: 1.494974]\n",
            "[Epoch 28/200] [Batch 264/938] [D loss: 0.152685] [G loss: 0.541493] [info loss: 1.470663]\n",
            "[Epoch 28/200] [Batch 265/938] [D loss: 0.197297] [G loss: 0.637858] [info loss: 1.470692]\n",
            "[Epoch 28/200] [Batch 266/938] [D loss: 0.240382] [G loss: 0.329325] [info loss: 1.476934]\n",
            "[Epoch 28/200] [Batch 267/938] [D loss: 0.200319] [G loss: 0.428325] [info loss: 1.471363]\n",
            "[Epoch 28/200] [Batch 268/938] [D loss: 0.276212] [G loss: 0.160368] [info loss: 1.471636]\n",
            "[Epoch 28/200] [Batch 269/938] [D loss: 0.127776] [G loss: 0.438383] [info loss: 1.472670]\n",
            "[Epoch 28/200] [Batch 270/938] [D loss: 0.237287] [G loss: 0.439424] [info loss: 1.472548]\n",
            "[Epoch 28/200] [Batch 271/938] [D loss: 0.224790] [G loss: 0.438519] [info loss: 1.470009]\n",
            "[Epoch 28/200] [Batch 272/938] [D loss: 0.223652] [G loss: 0.236508] [info loss: 1.502964]\n",
            "[Epoch 28/200] [Batch 273/938] [D loss: 0.246636] [G loss: 0.324073] [info loss: 1.486349]\n",
            "[Epoch 28/200] [Batch 274/938] [D loss: 0.106078] [G loss: 0.104052] [info loss: 1.469359]\n",
            "[Epoch 28/200] [Batch 275/938] [D loss: 0.152855] [G loss: 0.166495] [info loss: 1.490668]\n",
            "[Epoch 28/200] [Batch 276/938] [D loss: 0.213603] [G loss: 0.185120] [info loss: 1.486814]\n",
            "[Epoch 28/200] [Batch 277/938] [D loss: 0.342606] [G loss: 0.627588] [info loss: 1.472693]\n",
            "[Epoch 28/200] [Batch 278/938] [D loss: 0.317808] [G loss: 0.723714] [info loss: 1.480142]\n",
            "[Epoch 28/200] [Batch 279/938] [D loss: 0.166200] [G loss: 0.629397] [info loss: 1.479144]\n",
            "[Epoch 28/200] [Batch 280/938] [D loss: 0.229982] [G loss: 0.511169] [info loss: 1.473902]\n",
            "[Epoch 28/200] [Batch 281/938] [D loss: 0.265567] [G loss: 0.302876] [info loss: 1.478989]\n",
            "[Epoch 28/200] [Batch 282/938] [D loss: 0.215700] [G loss: 0.164610] [info loss: 1.474941]\n",
            "[Epoch 28/200] [Batch 283/938] [D loss: 0.172946] [G loss: 0.333425] [info loss: 1.471203]\n",
            "[Epoch 28/200] [Batch 284/938] [D loss: 0.150419] [G loss: 0.386588] [info loss: 1.472159]\n",
            "[Epoch 28/200] [Batch 285/938] [D loss: 0.121890] [G loss: 0.241663] [info loss: 1.495104]\n",
            "[Epoch 28/200] [Batch 286/938] [D loss: 0.276487] [G loss: 0.423988] [info loss: 1.470605]\n",
            "[Epoch 28/200] [Batch 287/938] [D loss: 0.157673] [G loss: 0.339708] [info loss: 1.472006]\n",
            "[Epoch 28/200] [Batch 288/938] [D loss: 0.209733] [G loss: 0.176708] [info loss: 1.474527]\n",
            "[Epoch 28/200] [Batch 289/938] [D loss: 0.168882] [G loss: 0.478383] [info loss: 1.499264]\n",
            "[Epoch 28/200] [Batch 290/938] [D loss: 0.213115] [G loss: 0.391729] [info loss: 1.491101]\n",
            "[Epoch 28/200] [Batch 291/938] [D loss: 0.312919] [G loss: 0.288199] [info loss: 1.471524]\n",
            "[Epoch 28/200] [Batch 292/938] [D loss: 0.196292] [G loss: 0.328915] [info loss: 1.505837]\n",
            "[Epoch 28/200] [Batch 293/938] [D loss: 0.211089] [G loss: 0.179676] [info loss: 1.472411]\n",
            "[Epoch 28/200] [Batch 294/938] [D loss: 0.264942] [G loss: 0.230317] [info loss: 1.479594]\n",
            "[Epoch 28/200] [Batch 295/938] [D loss: 0.238760] [G loss: 0.214427] [info loss: 1.481484]\n",
            "[Epoch 28/200] [Batch 296/938] [D loss: 0.221270] [G loss: 0.194941] [info loss: 1.485279]\n",
            "[Epoch 28/200] [Batch 297/938] [D loss: 0.221905] [G loss: 0.288732] [info loss: 1.474907]\n",
            "[Epoch 28/200] [Batch 298/938] [D loss: 0.175590] [G loss: 0.479173] [info loss: 1.473596]\n",
            "[Epoch 28/200] [Batch 299/938] [D loss: 0.205029] [G loss: 0.631484] [info loss: 1.484652]\n",
            "[Epoch 28/200] [Batch 300/938] [D loss: 0.218889] [G loss: 0.280355] [info loss: 1.469416]\n",
            "[Epoch 28/200] [Batch 301/938] [D loss: 0.163807] [G loss: 0.449987] [info loss: 1.487797]\n",
            "[Epoch 28/200] [Batch 302/938] [D loss: 0.204375] [G loss: 0.287805] [info loss: 1.471518]\n",
            "[Epoch 28/200] [Batch 303/938] [D loss: 0.218248] [G loss: 0.558713] [info loss: 1.470385]\n",
            "[Epoch 28/200] [Batch 304/938] [D loss: 0.270931] [G loss: 0.477628] [info loss: 1.484368]\n",
            "[Epoch 28/200] [Batch 305/938] [D loss: 0.227984] [G loss: 0.503195] [info loss: 1.471107]\n",
            "[Epoch 28/200] [Batch 306/938] [D loss: 0.268611] [G loss: 0.202994] [info loss: 1.470540]\n",
            "[Epoch 28/200] [Batch 307/938] [D loss: 0.407005] [G loss: 0.360074] [info loss: 1.484969]\n",
            "[Epoch 28/200] [Batch 308/938] [D loss: 0.275395] [G loss: 0.239714] [info loss: 1.486273]\n",
            "[Epoch 28/200] [Batch 309/938] [D loss: 0.212628] [G loss: 0.194266] [info loss: 1.472241]\n",
            "[Epoch 28/200] [Batch 310/938] [D loss: 0.198534] [G loss: 0.234615] [info loss: 1.470186]\n",
            "[Epoch 28/200] [Batch 311/938] [D loss: 0.178843] [G loss: 0.210210] [info loss: 1.498269]\n",
            "[Epoch 28/200] [Batch 312/938] [D loss: 0.256247] [G loss: 0.494792] [info loss: 1.513894]\n",
            "[Epoch 28/200] [Batch 313/938] [D loss: 0.213038] [G loss: 0.292790] [info loss: 1.487479]\n",
            "[Epoch 28/200] [Batch 314/938] [D loss: 0.214266] [G loss: 0.461811] [info loss: 1.483706]\n",
            "[Epoch 28/200] [Batch 315/938] [D loss: 0.170140] [G loss: 0.422096] [info loss: 1.504442]\n",
            "[Epoch 28/200] [Batch 316/938] [D loss: 0.241611] [G loss: 0.252552] [info loss: 1.473804]\n",
            "[Epoch 28/200] [Batch 317/938] [D loss: 0.221151] [G loss: 0.291902] [info loss: 1.469535]\n",
            "[Epoch 28/200] [Batch 318/938] [D loss: 0.236316] [G loss: 0.286539] [info loss: 1.471184]\n",
            "[Epoch 28/200] [Batch 319/938] [D loss: 0.141445] [G loss: 0.291208] [info loss: 1.477930]\n",
            "[Epoch 28/200] [Batch 320/938] [D loss: 0.279956] [G loss: 0.588486] [info loss: 1.470691]\n",
            "[Epoch 28/200] [Batch 321/938] [D loss: 0.234032] [G loss: 0.439280] [info loss: 1.481971]\n",
            "[Epoch 28/200] [Batch 322/938] [D loss: 0.280486] [G loss: 0.240828] [info loss: 1.486427]\n",
            "[Epoch 28/200] [Batch 323/938] [D loss: 0.243585] [G loss: 0.387650] [info loss: 1.473452]\n",
            "[Epoch 28/200] [Batch 324/938] [D loss: 0.178511] [G loss: 0.276409] [info loss: 1.494355]\n",
            "[Epoch 28/200] [Batch 325/938] [D loss: 0.216064] [G loss: 0.279798] [info loss: 1.504340]\n",
            "[Epoch 28/200] [Batch 326/938] [D loss: 0.184303] [G loss: 0.450962] [info loss: 1.470501]\n",
            "[Epoch 28/200] [Batch 327/938] [D loss: 0.240379] [G loss: 0.560379] [info loss: 1.493300]\n",
            "[Epoch 28/200] [Batch 328/938] [D loss: 0.272507] [G loss: 0.300085] [info loss: 1.471628]\n",
            "[Epoch 28/200] [Batch 329/938] [D loss: 0.360484] [G loss: 0.258887] [info loss: 1.472885]\n",
            "[Epoch 28/200] [Batch 330/938] [D loss: 0.262154] [G loss: 0.323045] [info loss: 1.468645]\n",
            "[Epoch 28/200] [Batch 331/938] [D loss: 0.131357] [G loss: 0.279140] [info loss: 1.511031]\n",
            "[Epoch 28/200] [Batch 332/938] [D loss: 0.175771] [G loss: 0.384635] [info loss: 1.473229]\n",
            "[Epoch 28/200] [Batch 333/938] [D loss: 0.227070] [G loss: 0.343928] [info loss: 1.470318]\n",
            "[Epoch 28/200] [Batch 334/938] [D loss: 0.164265] [G loss: 0.342129] [info loss: 1.472425]\n",
            "[Epoch 28/200] [Batch 335/938] [D loss: 0.280283] [G loss: 0.284467] [info loss: 1.472687]\n",
            "[Epoch 28/200] [Batch 336/938] [D loss: 0.243859] [G loss: 0.240886] [info loss: 1.473825]\n",
            "[Epoch 28/200] [Batch 337/938] [D loss: 0.213051] [G loss: 0.387502] [info loss: 1.471853]\n",
            "[Epoch 28/200] [Batch 338/938] [D loss: 0.338817] [G loss: 0.609193] [info loss: 1.479860]\n",
            "[Epoch 28/200] [Batch 339/938] [D loss: 0.173854] [G loss: 0.257739] [info loss: 1.487411]\n",
            "[Epoch 28/200] [Batch 340/938] [D loss: 0.284300] [G loss: 0.198774] [info loss: 1.470054]\n",
            "[Epoch 28/200] [Batch 341/938] [D loss: 0.251233] [G loss: 0.428400] [info loss: 1.498452]\n",
            "[Epoch 28/200] [Batch 342/938] [D loss: 0.271957] [G loss: 0.347270] [info loss: 1.473207]\n",
            "[Epoch 28/200] [Batch 343/938] [D loss: 0.232156] [G loss: 0.470201] [info loss: 1.471295]\n",
            "[Epoch 28/200] [Batch 344/938] [D loss: 0.261811] [G loss: 0.705761] [info loss: 1.472412]\n",
            "[Epoch 28/200] [Batch 345/938] [D loss: 0.180728] [G loss: 0.351691] [info loss: 1.471721]\n",
            "[Epoch 28/200] [Batch 346/938] [D loss: 0.204276] [G loss: 0.177307] [info loss: 1.490122]\n",
            "[Epoch 28/200] [Batch 347/938] [D loss: 0.306456] [G loss: 0.320222] [info loss: 1.487921]\n",
            "[Epoch 28/200] [Batch 348/938] [D loss: 0.166158] [G loss: 0.223281] [info loss: 1.478577]\n",
            "[Epoch 28/200] [Batch 349/938] [D loss: 0.287611] [G loss: 0.433837] [info loss: 1.481776]\n",
            "[Epoch 28/200] [Batch 350/938] [D loss: 0.277643] [G loss: 0.249937] [info loss: 1.476483]\n",
            "[Epoch 28/200] [Batch 351/938] [D loss: 0.119648] [G loss: 0.180400] [info loss: 1.507727]\n",
            "[Epoch 28/200] [Batch 352/938] [D loss: 0.409208] [G loss: 0.192368] [info loss: 1.481177]\n",
            "[Epoch 28/200] [Batch 353/938] [D loss: 0.155886] [G loss: 0.376547] [info loss: 1.472480]\n",
            "[Epoch 28/200] [Batch 354/938] [D loss: 0.210314] [G loss: 0.306607] [info loss: 1.482663]\n",
            "[Epoch 28/200] [Batch 355/938] [D loss: 0.329900] [G loss: 0.291328] [info loss: 1.469502]\n",
            "[Epoch 28/200] [Batch 356/938] [D loss: 0.249128] [G loss: 0.352959] [info loss: 1.473285]\n",
            "[Epoch 28/200] [Batch 357/938] [D loss: 0.213121] [G loss: 0.234495] [info loss: 1.476483]\n",
            "[Epoch 28/200] [Batch 358/938] [D loss: 0.204851] [G loss: 0.163736] [info loss: 1.474022]\n",
            "[Epoch 28/200] [Batch 359/938] [D loss: 0.182902] [G loss: 0.380965] [info loss: 1.487869]\n",
            "[Epoch 28/200] [Batch 360/938] [D loss: 0.172549] [G loss: 0.454090] [info loss: 1.469789]\n",
            "[Epoch 28/200] [Batch 361/938] [D loss: 0.293927] [G loss: 0.333337] [info loss: 1.481368]\n",
            "[Epoch 28/200] [Batch 362/938] [D loss: 0.125929] [G loss: 0.290427] [info loss: 1.488985]\n",
            "[Epoch 28/200] [Batch 363/938] [D loss: 0.233124] [G loss: 0.239911] [info loss: 1.500333]\n",
            "[Epoch 28/200] [Batch 364/938] [D loss: 0.293616] [G loss: 0.245866] [info loss: 1.491768]\n",
            "[Epoch 28/200] [Batch 365/938] [D loss: 0.181675] [G loss: 0.294474] [info loss: 1.478415]\n",
            "[Epoch 28/200] [Batch 366/938] [D loss: 0.232130] [G loss: 0.351530] [info loss: 1.469970]\n",
            "[Epoch 28/200] [Batch 367/938] [D loss: 0.147730] [G loss: 0.536212] [info loss: 1.468994]\n",
            "[Epoch 28/200] [Batch 368/938] [D loss: 0.194069] [G loss: 0.514942] [info loss: 1.483848]\n",
            "[Epoch 28/200] [Batch 369/938] [D loss: 0.302585] [G loss: 0.311572] [info loss: 1.494476]\n",
            "[Epoch 28/200] [Batch 370/938] [D loss: 0.298969] [G loss: 0.391403] [info loss: 1.471502]\n",
            "[Epoch 28/200] [Batch 371/938] [D loss: 0.232796] [G loss: 0.119001] [info loss: 1.497231]\n",
            "[Epoch 28/200] [Batch 372/938] [D loss: 0.226508] [G loss: 0.219482] [info loss: 1.471938]\n",
            "[Epoch 28/200] [Batch 373/938] [D loss: 0.201871] [G loss: 0.330133] [info loss: 1.479488]\n",
            "[Epoch 28/200] [Batch 374/938] [D loss: 0.284191] [G loss: 0.322476] [info loss: 1.471013]\n",
            "[Epoch 28/200] [Batch 375/938] [D loss: 0.256460] [G loss: 0.446050] [info loss: 1.477177]\n",
            "[Epoch 28/200] [Batch 376/938] [D loss: 0.235072] [G loss: 0.395865] [info loss: 1.470078]\n",
            "[Epoch 28/200] [Batch 377/938] [D loss: 0.187814] [G loss: 0.373416] [info loss: 1.472215]\n",
            "[Epoch 28/200] [Batch 378/938] [D loss: 0.175974] [G loss: 0.584376] [info loss: 1.485696]\n",
            "[Epoch 28/200] [Batch 379/938] [D loss: 0.265637] [G loss: 0.201781] [info loss: 1.470071]\n",
            "[Epoch 28/200] [Batch 380/938] [D loss: 0.264216] [G loss: 0.223637] [info loss: 1.486197]\n",
            "[Epoch 28/200] [Batch 381/938] [D loss: 0.257476] [G loss: 0.217469] [info loss: 1.473132]\n",
            "[Epoch 28/200] [Batch 382/938] [D loss: 0.198983] [G loss: 0.211057] [info loss: 1.493950]\n",
            "[Epoch 28/200] [Batch 383/938] [D loss: 0.137142] [G loss: 0.331954] [info loss: 1.474729]\n",
            "[Epoch 28/200] [Batch 384/938] [D loss: 0.258746] [G loss: 0.329686] [info loss: 1.507374]\n",
            "[Epoch 28/200] [Batch 385/938] [D loss: 0.147478] [G loss: 0.218286] [info loss: 1.476669]\n",
            "[Epoch 28/200] [Batch 386/938] [D loss: 0.183049] [G loss: 0.262239] [info loss: 1.470000]\n",
            "[Epoch 28/200] [Batch 387/938] [D loss: 0.211026] [G loss: 0.158159] [info loss: 1.472609]\n",
            "[Epoch 28/200] [Batch 388/938] [D loss: 0.141833] [G loss: 0.514940] [info loss: 1.471611]\n",
            "[Epoch 28/200] [Batch 389/938] [D loss: 0.355376] [G loss: 0.098322] [info loss: 1.470325]\n",
            "[Epoch 28/200] [Batch 390/938] [D loss: 0.232967] [G loss: 0.478307] [info loss: 1.472563]\n",
            "[Epoch 28/200] [Batch 391/938] [D loss: 0.175690] [G loss: 0.396456] [info loss: 1.492810]\n",
            "[Epoch 28/200] [Batch 392/938] [D loss: 0.174733] [G loss: 0.227343] [info loss: 1.472749]\n",
            "[Epoch 28/200] [Batch 393/938] [D loss: 0.118697] [G loss: 0.319785] [info loss: 1.473647]\n",
            "[Epoch 28/200] [Batch 394/938] [D loss: 0.160178] [G loss: 0.350446] [info loss: 1.480320]\n",
            "[Epoch 28/200] [Batch 395/938] [D loss: 0.150142] [G loss: 0.212316] [info loss: 1.480241]\n",
            "[Epoch 28/200] [Batch 396/938] [D loss: 0.234627] [G loss: 0.294868] [info loss: 1.471358]\n",
            "[Epoch 28/200] [Batch 397/938] [D loss: 0.295063] [G loss: 0.222999] [info loss: 1.469763]\n",
            "[Epoch 28/200] [Batch 398/938] [D loss: 0.220512] [G loss: 0.632087] [info loss: 1.478245]\n",
            "[Epoch 28/200] [Batch 399/938] [D loss: 0.244167] [G loss: 0.363871] [info loss: 1.470804]\n",
            "[Epoch 28/200] [Batch 400/938] [D loss: 0.167697] [G loss: 0.437083] [info loss: 1.469515]\n",
            "[Epoch 28/200] [Batch 401/938] [D loss: 0.243478] [G loss: 0.251807] [info loss: 1.467445]\n",
            "[Epoch 28/200] [Batch 402/938] [D loss: 0.250627] [G loss: 0.366385] [info loss: 1.469610]\n",
            "[Epoch 28/200] [Batch 403/938] [D loss: 0.164731] [G loss: 0.505649] [info loss: 1.482864]\n",
            "[Epoch 28/200] [Batch 404/938] [D loss: 0.143638] [G loss: 0.251546] [info loss: 1.473997]\n",
            "[Epoch 28/200] [Batch 405/938] [D loss: 0.174100] [G loss: 0.318466] [info loss: 1.522882]\n",
            "[Epoch 28/200] [Batch 406/938] [D loss: 0.239617] [G loss: 0.332181] [info loss: 1.468390]\n",
            "[Epoch 28/200] [Batch 407/938] [D loss: 0.270158] [G loss: 0.366334] [info loss: 1.480751]\n",
            "[Epoch 28/200] [Batch 408/938] [D loss: 0.168694] [G loss: 0.254704] [info loss: 1.470565]\n",
            "[Epoch 28/200] [Batch 409/938] [D loss: 0.187901] [G loss: 0.361715] [info loss: 1.485375]\n",
            "[Epoch 28/200] [Batch 410/938] [D loss: 0.112457] [G loss: 0.273928] [info loss: 1.469205]\n",
            "[Epoch 28/200] [Batch 411/938] [D loss: 0.222420] [G loss: 0.336672] [info loss: 1.485462]\n",
            "[Epoch 28/200] [Batch 412/938] [D loss: 0.167803] [G loss: 0.321513] [info loss: 1.500220]\n",
            "[Epoch 28/200] [Batch 413/938] [D loss: 0.176836] [G loss: 0.267714] [info loss: 1.469336]\n",
            "[Epoch 28/200] [Batch 414/938] [D loss: 0.140330] [G loss: 0.222387] [info loss: 1.469923]\n",
            "[Epoch 28/200] [Batch 415/938] [D loss: 0.177101] [G loss: 0.296097] [info loss: 1.469894]\n",
            "[Epoch 28/200] [Batch 416/938] [D loss: 0.176413] [G loss: 0.516411] [info loss: 1.472653]\n",
            "[Epoch 28/200] [Batch 417/938] [D loss: 0.140396] [G loss: 0.309412] [info loss: 1.473206]\n",
            "[Epoch 28/200] [Batch 418/938] [D loss: 0.266651] [G loss: 0.304362] [info loss: 1.480263]\n",
            "[Epoch 28/200] [Batch 419/938] [D loss: 0.204864] [G loss: 0.248745] [info loss: 1.469317]\n",
            "[Epoch 28/200] [Batch 420/938] [D loss: 0.227165] [G loss: 0.234920] [info loss: 1.474862]\n",
            "[Epoch 28/200] [Batch 421/938] [D loss: 0.225074] [G loss: 0.259754] [info loss: 1.468958]\n",
            "[Epoch 28/200] [Batch 422/938] [D loss: 0.232109] [G loss: 0.212657] [info loss: 1.498831]\n",
            "[Epoch 28/200] [Batch 423/938] [D loss: 0.155577] [G loss: 0.335429] [info loss: 1.470184]\n",
            "[Epoch 28/200] [Batch 424/938] [D loss: 0.087701] [G loss: 0.528230] [info loss: 1.517525]\n",
            "[Epoch 28/200] [Batch 425/938] [D loss: 0.246252] [G loss: 0.245657] [info loss: 1.477522]\n",
            "[Epoch 28/200] [Batch 426/938] [D loss: 0.228256] [G loss: 0.285703] [info loss: 1.480910]\n",
            "[Epoch 28/200] [Batch 427/938] [D loss: 0.164806] [G loss: 0.426309] [info loss: 1.513230]\n",
            "[Epoch 28/200] [Batch 428/938] [D loss: 0.183702] [G loss: 0.519649] [info loss: 1.515797]\n",
            "[Epoch 28/200] [Batch 429/938] [D loss: 0.279755] [G loss: 0.211492] [info loss: 1.472009]\n",
            "[Epoch 28/200] [Batch 430/938] [D loss: 0.238216] [G loss: 0.311122] [info loss: 1.472812]\n",
            "[Epoch 28/200] [Batch 431/938] [D loss: 0.306905] [G loss: 0.323458] [info loss: 1.473901]\n",
            "[Epoch 28/200] [Batch 432/938] [D loss: 0.263621] [G loss: 0.343778] [info loss: 1.472749]\n",
            "[Epoch 28/200] [Batch 433/938] [D loss: 0.318815] [G loss: 0.331059] [info loss: 1.473660]\n",
            "[Epoch 28/200] [Batch 434/938] [D loss: 0.140890] [G loss: 0.410532] [info loss: 1.473396]\n",
            "[Epoch 28/200] [Batch 435/938] [D loss: 0.249633] [G loss: 0.393220] [info loss: 1.470066]\n",
            "[Epoch 28/200] [Batch 436/938] [D loss: 0.186493] [G loss: 0.370438] [info loss: 1.487300]\n",
            "[Epoch 28/200] [Batch 437/938] [D loss: 0.262288] [G loss: 0.121653] [info loss: 1.493408]\n",
            "[Epoch 28/200] [Batch 438/938] [D loss: 0.253697] [G loss: 0.385446] [info loss: 1.471276]\n",
            "[Epoch 28/200] [Batch 439/938] [D loss: 0.212429] [G loss: 0.441371] [info loss: 1.482785]\n",
            "[Epoch 28/200] [Batch 440/938] [D loss: 0.290933] [G loss: 0.315570] [info loss: 1.472207]\n",
            "[Epoch 28/200] [Batch 441/938] [D loss: 0.215528] [G loss: 0.258667] [info loss: 1.482413]\n",
            "[Epoch 28/200] [Batch 442/938] [D loss: 0.176477] [G loss: 0.286023] [info loss: 1.499794]\n",
            "[Epoch 28/200] [Batch 443/938] [D loss: 0.163775] [G loss: 0.426247] [info loss: 1.468935]\n",
            "[Epoch 28/200] [Batch 444/938] [D loss: 0.207371] [G loss: 0.510268] [info loss: 1.488821]\n",
            "[Epoch 28/200] [Batch 445/938] [D loss: 0.199792] [G loss: 0.369271] [info loss: 1.484211]\n",
            "[Epoch 28/200] [Batch 446/938] [D loss: 0.206591] [G loss: 0.176750] [info loss: 1.478669]\n",
            "[Epoch 28/200] [Batch 447/938] [D loss: 0.303514] [G loss: 0.414077] [info loss: 1.469106]\n",
            "[Epoch 28/200] [Batch 448/938] [D loss: 0.256716] [G loss: 0.503715] [info loss: 1.487590]\n",
            "[Epoch 28/200] [Batch 449/938] [D loss: 0.209211] [G loss: 0.110217] [info loss: 1.486361]\n",
            "[Epoch 28/200] [Batch 450/938] [D loss: 0.299483] [G loss: 0.267524] [info loss: 1.483671]\n",
            "[Epoch 28/200] [Batch 451/938] [D loss: 0.229933] [G loss: 0.326382] [info loss: 1.469794]\n",
            "[Epoch 28/200] [Batch 452/938] [D loss: 0.176360] [G loss: 0.472415] [info loss: 1.472302]\n",
            "[Epoch 28/200] [Batch 453/938] [D loss: 0.114626] [G loss: 0.520803] [info loss: 1.487025]\n",
            "[Epoch 28/200] [Batch 454/938] [D loss: 0.114334] [G loss: 0.446220] [info loss: 1.474830]\n",
            "[Epoch 28/200] [Batch 455/938] [D loss: 0.215281] [G loss: 0.761375] [info loss: 1.471858]\n",
            "[Epoch 28/200] [Batch 456/938] [D loss: 0.144638] [G loss: 0.239748] [info loss: 1.494754]\n",
            "[Epoch 28/200] [Batch 457/938] [D loss: 0.140447] [G loss: 0.515762] [info loss: 1.469164]\n",
            "[Epoch 28/200] [Batch 458/938] [D loss: 0.207908] [G loss: 0.509723] [info loss: 1.478550]\n",
            "[Epoch 28/200] [Batch 459/938] [D loss: 0.275622] [G loss: 0.263878] [info loss: 1.480007]\n",
            "[Epoch 28/200] [Batch 460/938] [D loss: 0.122759] [G loss: 0.331322] [info loss: 1.495032]\n",
            "[Epoch 28/200] [Batch 461/938] [D loss: 0.185208] [G loss: 0.357922] [info loss: 1.484340]\n",
            "[Epoch 28/200] [Batch 462/938] [D loss: 0.223156] [G loss: 0.271529] [info loss: 1.486832]\n",
            "[Epoch 28/200] [Batch 463/938] [D loss: 0.282146] [G loss: 0.286565] [info loss: 1.470553]\n",
            "[Epoch 28/200] [Batch 464/938] [D loss: 0.173945] [G loss: 0.322546] [info loss: 1.470743]\n",
            "[Epoch 28/200] [Batch 465/938] [D loss: 0.222563] [G loss: 0.225711] [info loss: 1.469498]\n",
            "[Epoch 28/200] [Batch 466/938] [D loss: 0.269907] [G loss: 0.278972] [info loss: 1.496678]\n",
            "[Epoch 28/200] [Batch 467/938] [D loss: 0.280924] [G loss: 0.627779] [info loss: 1.468740]\n",
            "[Epoch 28/200] [Batch 468/938] [D loss: 0.158343] [G loss: 0.381920] [info loss: 1.485429]\n",
            "[Epoch 28/200] [Batch 469/938] [D loss: 0.317161] [G loss: 0.245936] [info loss: 1.470623]\n",
            "[Epoch 28/200] [Batch 470/938] [D loss: 0.215059] [G loss: 0.554365] [info loss: 1.469783]\n",
            "[Epoch 28/200] [Batch 471/938] [D loss: 0.220083] [G loss: 0.235510] [info loss: 1.480585]\n",
            "[Epoch 28/200] [Batch 472/938] [D loss: 0.283327] [G loss: 0.224472] [info loss: 1.470117]\n",
            "[Epoch 28/200] [Batch 473/938] [D loss: 0.234530] [G loss: 0.241417] [info loss: 1.471172]\n",
            "[Epoch 28/200] [Batch 474/938] [D loss: 0.246195] [G loss: 0.423248] [info loss: 1.484049]\n",
            "[Epoch 28/200] [Batch 475/938] [D loss: 0.196934] [G loss: 0.151391] [info loss: 1.486589]\n",
            "[Epoch 28/200] [Batch 476/938] [D loss: 0.273170] [G loss: 0.461961] [info loss: 1.500144]\n",
            "[Epoch 28/200] [Batch 477/938] [D loss: 0.255296] [G loss: 0.361164] [info loss: 1.468684]\n",
            "[Epoch 28/200] [Batch 478/938] [D loss: 0.215238] [G loss: 0.691253] [info loss: 1.483661]\n",
            "[Epoch 28/200] [Batch 479/938] [D loss: 0.292380] [G loss: 0.304634] [info loss: 1.477580]\n",
            "[Epoch 28/200] [Batch 480/938] [D loss: 0.278633] [G loss: 0.300358] [info loss: 1.469524]\n",
            "[Epoch 28/200] [Batch 481/938] [D loss: 0.227250] [G loss: 0.378598] [info loss: 1.473696]\n",
            "[Epoch 28/200] [Batch 482/938] [D loss: 0.183404] [G loss: 0.214624] [info loss: 1.470163]\n",
            "[Epoch 28/200] [Batch 483/938] [D loss: 0.276079] [G loss: 0.347222] [info loss: 1.468928]\n",
            "[Epoch 28/200] [Batch 484/938] [D loss: 0.195810] [G loss: 0.362327] [info loss: 1.469580]\n",
            "[Epoch 28/200] [Batch 485/938] [D loss: 0.238669] [G loss: 0.311524] [info loss: 1.482689]\n",
            "[Epoch 28/200] [Batch 486/938] [D loss: 0.196109] [G loss: 0.359647] [info loss: 1.475737]\n",
            "[Epoch 28/200] [Batch 487/938] [D loss: 0.279514] [G loss: 0.374436] [info loss: 1.469048]\n",
            "[Epoch 28/200] [Batch 488/938] [D loss: 0.252404] [G loss: 0.255196] [info loss: 1.468567]\n",
            "[Epoch 28/200] [Batch 489/938] [D loss: 0.218064] [G loss: 0.383729] [info loss: 1.475644]\n",
            "[Epoch 28/200] [Batch 490/938] [D loss: 0.241395] [G loss: 0.583363] [info loss: 1.487052]\n",
            "[Epoch 28/200] [Batch 491/938] [D loss: 0.230647] [G loss: 0.298578] [info loss: 1.476713]\n",
            "[Epoch 28/200] [Batch 492/938] [D loss: 0.248701] [G loss: 0.395055] [info loss: 1.469539]\n",
            "[Epoch 28/200] [Batch 493/938] [D loss: 0.230290] [G loss: 0.231524] [info loss: 1.471487]\n",
            "[Epoch 28/200] [Batch 494/938] [D loss: 0.109445] [G loss: 0.412133] [info loss: 1.480744]\n",
            "[Epoch 28/200] [Batch 495/938] [D loss: 0.236875] [G loss: 0.278372] [info loss: 1.480087]\n",
            "[Epoch 28/200] [Batch 496/938] [D loss: 0.212168] [G loss: 0.608098] [info loss: 1.475832]\n",
            "[Epoch 28/200] [Batch 497/938] [D loss: 0.226288] [G loss: 0.471775] [info loss: 1.480551]\n",
            "[Epoch 28/200] [Batch 498/938] [D loss: 0.211046] [G loss: 0.283695] [info loss: 1.471499]\n",
            "[Epoch 28/200] [Batch 499/938] [D loss: 0.227709] [G loss: 0.208033] [info loss: 1.473053]\n",
            "[Epoch 28/200] [Batch 500/938] [D loss: 0.277830] [G loss: 0.231193] [info loss: 1.466760]\n",
            "[Epoch 28/200] [Batch 501/938] [D loss: 0.201856] [G loss: 0.320888] [info loss: 1.484817]\n",
            "[Epoch 28/200] [Batch 502/938] [D loss: 0.206576] [G loss: 0.432542] [info loss: 1.469106]\n",
            "[Epoch 28/200] [Batch 503/938] [D loss: 0.347103] [G loss: 0.494190] [info loss: 1.471834]\n",
            "[Epoch 28/200] [Batch 504/938] [D loss: 0.287045] [G loss: 0.205975] [info loss: 1.470725]\n",
            "[Epoch 28/200] [Batch 505/938] [D loss: 0.188359] [G loss: 0.267279] [info loss: 1.479271]\n",
            "[Epoch 28/200] [Batch 506/938] [D loss: 0.206685] [G loss: 0.422617] [info loss: 1.484829]\n",
            "[Epoch 28/200] [Batch 507/938] [D loss: 0.188142] [G loss: 0.317476] [info loss: 1.474739]\n",
            "[Epoch 28/200] [Batch 508/938] [D loss: 0.255491] [G loss: 0.359698] [info loss: 1.472440]\n",
            "[Epoch 28/200] [Batch 509/938] [D loss: 0.185007] [G loss: 0.461354] [info loss: 1.478937]\n",
            "[Epoch 28/200] [Batch 510/938] [D loss: 0.220776] [G loss: 0.440131] [info loss: 1.480881]\n",
            "[Epoch 28/200] [Batch 511/938] [D loss: 0.167151] [G loss: 0.496441] [info loss: 1.472807]\n",
            "[Epoch 28/200] [Batch 512/938] [D loss: 0.166297] [G loss: 0.437732] [info loss: 1.478741]\n",
            "[Epoch 28/200] [Batch 513/938] [D loss: 0.165055] [G loss: 0.351479] [info loss: 1.477455]\n",
            "[Epoch 28/200] [Batch 514/938] [D loss: 0.257850] [G loss: 0.291489] [info loss: 1.470304]\n",
            "[Epoch 28/200] [Batch 515/938] [D loss: 0.137528] [G loss: 0.349405] [info loss: 1.476587]\n",
            "[Epoch 28/200] [Batch 516/938] [D loss: 0.262790] [G loss: 0.296502] [info loss: 1.476689]\n",
            "[Epoch 28/200] [Batch 517/938] [D loss: 0.175584] [G loss: 0.163602] [info loss: 1.471650]\n",
            "[Epoch 28/200] [Batch 518/938] [D loss: 0.289410] [G loss: 0.332253] [info loss: 1.471539]\n",
            "[Epoch 28/200] [Batch 519/938] [D loss: 0.230473] [G loss: 0.400244] [info loss: 1.487957]\n",
            "[Epoch 28/200] [Batch 520/938] [D loss: 0.121103] [G loss: 0.310587] [info loss: 1.488850]\n",
            "[Epoch 28/200] [Batch 521/938] [D loss: 0.172943] [G loss: 0.393803] [info loss: 1.479941]\n",
            "[Epoch 28/200] [Batch 522/938] [D loss: 0.178036] [G loss: 0.474191] [info loss: 1.481863]\n",
            "[Epoch 28/200] [Batch 523/938] [D loss: 0.262824] [G loss: 0.426241] [info loss: 1.484491]\n",
            "[Epoch 28/200] [Batch 524/938] [D loss: 0.170225] [G loss: 0.329060] [info loss: 1.476224]\n",
            "[Epoch 28/200] [Batch 525/938] [D loss: 0.235518] [G loss: 0.319930] [info loss: 1.482767]\n",
            "[Epoch 28/200] [Batch 526/938] [D loss: 0.221495] [G loss: 0.315250] [info loss: 1.489819]\n",
            "[Epoch 28/200] [Batch 527/938] [D loss: 0.257268] [G loss: 0.365016] [info loss: 1.472988]\n",
            "[Epoch 28/200] [Batch 528/938] [D loss: 0.259151] [G loss: 0.226166] [info loss: 1.499781]\n",
            "[Epoch 28/200] [Batch 529/938] [D loss: 0.197729] [G loss: 0.430696] [info loss: 1.488485]\n",
            "[Epoch 28/200] [Batch 530/938] [D loss: 0.268403] [G loss: 0.151156] [info loss: 1.470895]\n",
            "[Epoch 28/200] [Batch 531/938] [D loss: 0.175167] [G loss: 0.111631] [info loss: 1.490213]\n",
            "[Epoch 28/200] [Batch 532/938] [D loss: 0.135564] [G loss: 0.146010] [info loss: 1.469305]\n",
            "[Epoch 28/200] [Batch 533/938] [D loss: 0.138542] [G loss: 0.354143] [info loss: 1.470001]\n",
            "[Epoch 28/200] [Batch 534/938] [D loss: 0.296746] [G loss: 0.243582] [info loss: 1.473207]\n",
            "[Epoch 28/200] [Batch 535/938] [D loss: 0.290328] [G loss: 0.202822] [info loss: 1.472802]\n",
            "[Epoch 28/200] [Batch 536/938] [D loss: 0.190774] [G loss: 0.293938] [info loss: 1.489811]\n",
            "[Epoch 28/200] [Batch 537/938] [D loss: 0.328496] [G loss: 0.272703] [info loss: 1.483017]\n",
            "[Epoch 28/200] [Batch 538/938] [D loss: 0.163183] [G loss: 0.397744] [info loss: 1.482947]\n",
            "[Epoch 28/200] [Batch 539/938] [D loss: 0.225029] [G loss: 0.188074] [info loss: 1.469020]\n",
            "[Epoch 28/200] [Batch 540/938] [D loss: 0.202050] [G loss: 0.221210] [info loss: 1.471729]\n",
            "[Epoch 28/200] [Batch 541/938] [D loss: 0.229373] [G loss: 0.260937] [info loss: 1.470731]\n",
            "[Epoch 28/200] [Batch 542/938] [D loss: 0.154584] [G loss: 0.093906] [info loss: 1.483999]\n",
            "[Epoch 28/200] [Batch 543/938] [D loss: 0.204842] [G loss: 0.312068] [info loss: 1.469947]\n",
            "[Epoch 28/200] [Batch 544/938] [D loss: 0.200334] [G loss: 0.580894] [info loss: 1.485100]\n",
            "[Epoch 28/200] [Batch 545/938] [D loss: 0.285158] [G loss: 0.432533] [info loss: 1.496236]\n",
            "[Epoch 28/200] [Batch 546/938] [D loss: 0.220778] [G loss: 0.467009] [info loss: 1.471861]\n",
            "[Epoch 28/200] [Batch 547/938] [D loss: 0.264267] [G loss: 0.546266] [info loss: 1.469839]\n",
            "[Epoch 28/200] [Batch 548/938] [D loss: 0.164105] [G loss: 0.205913] [info loss: 1.471411]\n",
            "[Epoch 28/200] [Batch 549/938] [D loss: 0.152155] [G loss: 0.359292] [info loss: 1.476814]\n",
            "[Epoch 28/200] [Batch 550/938] [D loss: 0.207723] [G loss: 0.151730] [info loss: 1.490590]\n",
            "[Epoch 28/200] [Batch 551/938] [D loss: 0.272394] [G loss: 0.455056] [info loss: 1.484286]\n",
            "[Epoch 28/200] [Batch 552/938] [D loss: 0.203359] [G loss: 0.577205] [info loss: 1.491411]\n",
            "[Epoch 28/200] [Batch 553/938] [D loss: 0.384895] [G loss: 0.250188] [info loss: 1.471568]\n",
            "[Epoch 28/200] [Batch 554/938] [D loss: 0.257069] [G loss: 0.265839] [info loss: 1.473800]\n",
            "[Epoch 28/200] [Batch 555/938] [D loss: 0.233498] [G loss: 0.464663] [info loss: 1.473220]\n",
            "[Epoch 28/200] [Batch 556/938] [D loss: 0.217474] [G loss: 0.464692] [info loss: 1.482762]\n",
            "[Epoch 28/200] [Batch 557/938] [D loss: 0.170521] [G loss: 0.323419] [info loss: 1.471647]\n",
            "[Epoch 28/200] [Batch 558/938] [D loss: 0.154789] [G loss: 0.396395] [info loss: 1.478791]\n",
            "[Epoch 28/200] [Batch 559/938] [D loss: 0.268406] [G loss: 0.293565] [info loss: 1.484117]\n",
            "[Epoch 28/200] [Batch 560/938] [D loss: 0.243056] [G loss: 0.404887] [info loss: 1.471526]\n",
            "[Epoch 28/200] [Batch 561/938] [D loss: 0.222789] [G loss: 0.221217] [info loss: 1.471474]\n",
            "[Epoch 28/200] [Batch 562/938] [D loss: 0.169239] [G loss: 0.343917] [info loss: 1.472362]\n",
            "[Epoch 28/200] [Batch 563/938] [D loss: 0.157486] [G loss: 0.253348] [info loss: 1.471768]\n",
            "[Epoch 28/200] [Batch 564/938] [D loss: 0.299929] [G loss: 0.401862] [info loss: 1.473843]\n",
            "[Epoch 28/200] [Batch 565/938] [D loss: 0.255145] [G loss: 0.239209] [info loss: 1.475755]\n",
            "[Epoch 28/200] [Batch 566/938] [D loss: 0.329277] [G loss: 0.232265] [info loss: 1.478460]\n",
            "[Epoch 28/200] [Batch 567/938] [D loss: 0.095024] [G loss: 0.294681] [info loss: 1.472464]\n",
            "[Epoch 28/200] [Batch 568/938] [D loss: 0.220000] [G loss: 0.434364] [info loss: 1.469978]\n",
            "[Epoch 28/200] [Batch 569/938] [D loss: 0.283602] [G loss: 0.431457] [info loss: 1.468945]\n",
            "[Epoch 28/200] [Batch 570/938] [D loss: 0.284127] [G loss: 0.347825] [info loss: 1.470976]\n",
            "[Epoch 28/200] [Batch 571/938] [D loss: 0.350169] [G loss: 0.341392] [info loss: 1.488351]\n",
            "[Epoch 28/200] [Batch 572/938] [D loss: 0.333922] [G loss: 0.511800] [info loss: 1.470789]\n",
            "[Epoch 28/200] [Batch 573/938] [D loss: 0.194826] [G loss: 0.377906] [info loss: 1.476457]\n",
            "[Epoch 28/200] [Batch 574/938] [D loss: 0.126096] [G loss: 0.308766] [info loss: 1.474177]\n",
            "[Epoch 28/200] [Batch 575/938] [D loss: 0.117206] [G loss: 0.588966] [info loss: 1.473879]\n",
            "[Epoch 28/200] [Batch 576/938] [D loss: 0.239688] [G loss: 0.203372] [info loss: 1.470554]\n",
            "[Epoch 28/200] [Batch 577/938] [D loss: 0.298362] [G loss: 0.261586] [info loss: 1.489574]\n",
            "[Epoch 28/200] [Batch 578/938] [D loss: 0.239601] [G loss: 0.342066] [info loss: 1.480874]\n",
            "[Epoch 28/200] [Batch 579/938] [D loss: 0.223115] [G loss: 0.479573] [info loss: 1.486218]\n",
            "[Epoch 28/200] [Batch 580/938] [D loss: 0.281819] [G loss: 0.218553] [info loss: 1.483533]\n",
            "[Epoch 28/200] [Batch 581/938] [D loss: 0.197784] [G loss: 0.207337] [info loss: 1.474371]\n",
            "[Epoch 28/200] [Batch 582/938] [D loss: 0.254271] [G loss: 0.298213] [info loss: 1.470744]\n",
            "[Epoch 28/200] [Batch 583/938] [D loss: 0.187848] [G loss: 0.275153] [info loss: 1.469633]\n",
            "[Epoch 28/200] [Batch 584/938] [D loss: 0.226726] [G loss: 0.323940] [info loss: 1.481028]\n",
            "[Epoch 28/200] [Batch 585/938] [D loss: 0.257825] [G loss: 0.571119] [info loss: 1.483033]\n",
            "[Epoch 28/200] [Batch 586/938] [D loss: 0.279835] [G loss: 0.233694] [info loss: 1.486177]\n",
            "[Epoch 28/200] [Batch 587/938] [D loss: 0.245732] [G loss: 0.169500] [info loss: 1.476139]\n",
            "[Epoch 28/200] [Batch 588/938] [D loss: 0.267079] [G loss: 0.209296] [info loss: 1.484944]\n",
            "[Epoch 28/200] [Batch 589/938] [D loss: 0.153666] [G loss: 0.453096] [info loss: 1.470462]\n",
            "[Epoch 28/200] [Batch 590/938] [D loss: 0.301564] [G loss: 0.397666] [info loss: 1.479086]\n",
            "[Epoch 28/200] [Batch 591/938] [D loss: 0.232407] [G loss: 0.232899] [info loss: 1.486590]\n",
            "[Epoch 28/200] [Batch 592/938] [D loss: 0.212713] [G loss: 0.332712] [info loss: 1.483360]\n",
            "[Epoch 28/200] [Batch 593/938] [D loss: 0.202528] [G loss: 0.614662] [info loss: 1.468831]\n",
            "[Epoch 28/200] [Batch 594/938] [D loss: 0.360142] [G loss: 0.350899] [info loss: 1.472519]\n",
            "[Epoch 28/200] [Batch 595/938] [D loss: 0.215841] [G loss: 0.418398] [info loss: 1.485161]\n",
            "[Epoch 28/200] [Batch 596/938] [D loss: 0.178062] [G loss: 0.409960] [info loss: 1.472576]\n",
            "[Epoch 28/200] [Batch 597/938] [D loss: 0.308232] [G loss: 0.369163] [info loss: 1.485411]\n",
            "[Epoch 28/200] [Batch 598/938] [D loss: 0.249370] [G loss: 0.301037] [info loss: 1.471151]\n",
            "[Epoch 28/200] [Batch 599/938] [D loss: 0.218884] [G loss: 0.188121] [info loss: 1.473080]\n",
            "[Epoch 28/200] [Batch 600/938] [D loss: 0.224166] [G loss: 0.424938] [info loss: 1.468219]\n",
            "[Epoch 28/200] [Batch 601/938] [D loss: 0.140682] [G loss: 0.551210] [info loss: 1.484367]\n",
            "[Epoch 28/200] [Batch 602/938] [D loss: 0.188089] [G loss: 0.339320] [info loss: 1.474597]\n",
            "[Epoch 28/200] [Batch 603/938] [D loss: 0.267060] [G loss: 0.386517] [info loss: 1.470992]\n",
            "[Epoch 28/200] [Batch 604/938] [D loss: 0.120879] [G loss: 0.292955] [info loss: 1.479914]\n",
            "[Epoch 28/200] [Batch 605/938] [D loss: 0.243847] [G loss: 0.478331] [info loss: 1.498835]\n",
            "[Epoch 28/200] [Batch 606/938] [D loss: 0.217143] [G loss: 0.307178] [info loss: 1.470518]\n",
            "[Epoch 28/200] [Batch 607/938] [D loss: 0.209987] [G loss: 0.493741] [info loss: 1.478711]\n",
            "[Epoch 28/200] [Batch 608/938] [D loss: 0.233086] [G loss: 0.449539] [info loss: 1.485624]\n",
            "[Epoch 28/200] [Batch 609/938] [D loss: 0.259438] [G loss: 0.447791] [info loss: 1.505131]\n",
            "[Epoch 28/200] [Batch 610/938] [D loss: 0.239944] [G loss: 0.508816] [info loss: 1.475593]\n",
            "[Epoch 28/200] [Batch 611/938] [D loss: 0.199428] [G loss: 0.195975] [info loss: 1.478760]\n",
            "[Epoch 28/200] [Batch 612/938] [D loss: 0.304094] [G loss: 0.256618] [info loss: 1.483836]\n",
            "[Epoch 28/200] [Batch 613/938] [D loss: 0.242155] [G loss: 0.306945] [info loss: 1.483977]\n",
            "[Epoch 28/200] [Batch 614/938] [D loss: 0.197001] [G loss: 0.282394] [info loss: 1.469182]\n",
            "[Epoch 28/200] [Batch 615/938] [D loss: 0.326995] [G loss: 0.443821] [info loss: 1.476591]\n",
            "[Epoch 28/200] [Batch 616/938] [D loss: 0.350696] [G loss: 0.271811] [info loss: 1.470452]\n",
            "[Epoch 28/200] [Batch 617/938] [D loss: 0.177574] [G loss: 0.553875] [info loss: 1.472342]\n",
            "[Epoch 28/200] [Batch 618/938] [D loss: 0.276511] [G loss: 0.391078] [info loss: 1.508213]\n",
            "[Epoch 28/200] [Batch 619/938] [D loss: 0.229121] [G loss: 0.241838] [info loss: 1.470034]\n",
            "[Epoch 28/200] [Batch 620/938] [D loss: 0.207732] [G loss: 0.110176] [info loss: 1.469288]\n",
            "[Epoch 28/200] [Batch 621/938] [D loss: 0.170384] [G loss: 0.335865] [info loss: 1.473902]\n",
            "[Epoch 28/200] [Batch 622/938] [D loss: 0.229127] [G loss: 0.257797] [info loss: 1.482109]\n",
            "[Epoch 28/200] [Batch 623/938] [D loss: 0.181847] [G loss: 0.231924] [info loss: 1.474442]\n",
            "[Epoch 28/200] [Batch 624/938] [D loss: 0.151354] [G loss: 0.742745] [info loss: 1.491744]\n",
            "[Epoch 28/200] [Batch 625/938] [D loss: 0.175084] [G loss: 0.338115] [info loss: 1.470732]\n",
            "[Epoch 28/200] [Batch 626/938] [D loss: 0.234459] [G loss: 0.408573] [info loss: 1.480347]\n",
            "[Epoch 28/200] [Batch 627/938] [D loss: 0.218865] [G loss: 0.148798] [info loss: 1.472939]\n",
            "[Epoch 28/200] [Batch 628/938] [D loss: 0.233087] [G loss: 0.299521] [info loss: 1.476815]\n",
            "[Epoch 28/200] [Batch 629/938] [D loss: 0.292746] [G loss: 0.249358] [info loss: 1.484227]\n",
            "[Epoch 28/200] [Batch 630/938] [D loss: 0.234908] [G loss: 0.255351] [info loss: 1.483023]\n",
            "[Epoch 28/200] [Batch 631/938] [D loss: 0.193345] [G loss: 0.526751] [info loss: 1.486118]\n",
            "[Epoch 28/200] [Batch 632/938] [D loss: 0.294367] [G loss: 0.100039] [info loss: 1.474492]\n",
            "[Epoch 28/200] [Batch 633/938] [D loss: 0.298558] [G loss: 0.312980] [info loss: 1.487579]\n",
            "[Epoch 28/200] [Batch 634/938] [D loss: 0.231103] [G loss: 0.304521] [info loss: 1.481755]\n",
            "[Epoch 28/200] [Batch 635/938] [D loss: 0.225235] [G loss: 0.214243] [info loss: 1.473467]\n",
            "[Epoch 28/200] [Batch 636/938] [D loss: 0.140849] [G loss: 0.570364] [info loss: 1.494455]\n",
            "[Epoch 28/200] [Batch 637/938] [D loss: 0.131107] [G loss: 0.207911] [info loss: 1.493421]\n",
            "[Epoch 28/200] [Batch 638/938] [D loss: 0.244308] [G loss: 0.308038] [info loss: 1.500524]\n",
            "[Epoch 28/200] [Batch 639/938] [D loss: 0.272462] [G loss: 0.286921] [info loss: 1.469665]\n",
            "[Epoch 28/200] [Batch 640/938] [D loss: 0.166207] [G loss: 0.236167] [info loss: 1.485817]\n",
            "[Epoch 28/200] [Batch 641/938] [D loss: 0.271162] [G loss: 0.321635] [info loss: 1.469861]\n",
            "[Epoch 28/200] [Batch 642/938] [D loss: 0.205286] [G loss: 0.094639] [info loss: 1.484899]\n",
            "[Epoch 28/200] [Batch 643/938] [D loss: 0.196466] [G loss: 0.542323] [info loss: 1.474770]\n",
            "[Epoch 28/200] [Batch 644/938] [D loss: 0.210635] [G loss: 0.285737] [info loss: 1.484221]\n",
            "[Epoch 28/200] [Batch 645/938] [D loss: 0.154006] [G loss: 0.263106] [info loss: 1.482136]\n",
            "[Epoch 28/200] [Batch 646/938] [D loss: 0.283797] [G loss: 0.150726] [info loss: 1.475608]\n",
            "[Epoch 28/200] [Batch 647/938] [D loss: 0.224701] [G loss: 0.292355] [info loss: 1.481382]\n",
            "[Epoch 28/200] [Batch 648/938] [D loss: 0.221581] [G loss: 0.425595] [info loss: 1.489342]\n",
            "[Epoch 28/200] [Batch 649/938] [D loss: 0.137100] [G loss: 0.324893] [info loss: 1.472363]\n",
            "[Epoch 28/200] [Batch 650/938] [D loss: 0.186687] [G loss: 0.358253] [info loss: 1.476646]\n",
            "[Epoch 28/200] [Batch 651/938] [D loss: 0.253140] [G loss: 0.369265] [info loss: 1.477164]\n",
            "[Epoch 28/200] [Batch 652/938] [D loss: 0.229010] [G loss: 0.289401] [info loss: 1.472090]\n",
            "[Epoch 28/200] [Batch 653/938] [D loss: 0.201570] [G loss: 0.255415] [info loss: 1.476032]\n",
            "[Epoch 28/200] [Batch 654/938] [D loss: 0.181059] [G loss: 0.363400] [info loss: 1.468118]\n",
            "[Epoch 28/200] [Batch 655/938] [D loss: 0.148096] [G loss: 0.273952] [info loss: 1.490975]\n",
            "[Epoch 28/200] [Batch 656/938] [D loss: 0.259516] [G loss: 0.251948] [info loss: 1.484548]\n",
            "[Epoch 28/200] [Batch 657/938] [D loss: 0.230703] [G loss: 0.116661] [info loss: 1.469454]\n",
            "[Epoch 28/200] [Batch 658/938] [D loss: 0.234939] [G loss: 0.144421] [info loss: 1.479785]\n",
            "[Epoch 28/200] [Batch 659/938] [D loss: 0.206468] [G loss: 0.264246] [info loss: 1.473355]\n",
            "[Epoch 28/200] [Batch 660/938] [D loss: 0.181850] [G loss: 0.275158] [info loss: 1.470921]\n",
            "[Epoch 28/200] [Batch 661/938] [D loss: 0.218071] [G loss: 0.242156] [info loss: 1.485481]\n",
            "[Epoch 28/200] [Batch 662/938] [D loss: 0.191386] [G loss: 0.574238] [info loss: 1.470620]\n",
            "[Epoch 28/200] [Batch 663/938] [D loss: 0.300327] [G loss: 0.309736] [info loss: 1.469147]\n",
            "[Epoch 28/200] [Batch 664/938] [D loss: 0.133122] [G loss: 0.479760] [info loss: 1.483836]\n",
            "[Epoch 28/200] [Batch 665/938] [D loss: 0.191795] [G loss: 0.186822] [info loss: 1.477590]\n",
            "[Epoch 28/200] [Batch 666/938] [D loss: 0.199397] [G loss: 0.336018] [info loss: 1.469494]\n",
            "[Epoch 28/200] [Batch 667/938] [D loss: 0.239919] [G loss: 0.460874] [info loss: 1.490536]\n",
            "[Epoch 28/200] [Batch 668/938] [D loss: 0.218834] [G loss: 0.331671] [info loss: 1.470238]\n",
            "[Epoch 28/200] [Batch 669/938] [D loss: 0.194244] [G loss: 0.561509] [info loss: 1.484131]\n",
            "[Epoch 28/200] [Batch 670/938] [D loss: 0.241346] [G loss: 0.314664] [info loss: 1.487916]\n",
            "[Epoch 28/200] [Batch 671/938] [D loss: 0.173881] [G loss: 0.325523] [info loss: 1.472602]\n",
            "[Epoch 28/200] [Batch 672/938] [D loss: 0.119134] [G loss: 0.370781] [info loss: 1.476171]\n",
            "[Epoch 28/200] [Batch 673/938] [D loss: 0.335771] [G loss: 0.451924] [info loss: 1.486905]\n",
            "[Epoch 28/200] [Batch 674/938] [D loss: 0.222105] [G loss: 0.163718] [info loss: 1.484789]\n",
            "[Epoch 28/200] [Batch 675/938] [D loss: 0.245198] [G loss: 0.428351] [info loss: 1.473844]\n",
            "[Epoch 28/200] [Batch 676/938] [D loss: 0.238454] [G loss: 0.346564] [info loss: 1.472247]\n",
            "[Epoch 28/200] [Batch 677/938] [D loss: 0.259470] [G loss: 0.382596] [info loss: 1.485372]\n",
            "[Epoch 28/200] [Batch 678/938] [D loss: 0.185754] [G loss: 0.510856] [info loss: 1.469009]\n",
            "[Epoch 28/200] [Batch 679/938] [D loss: 0.165054] [G loss: 0.355446] [info loss: 1.471503]\n",
            "[Epoch 28/200] [Batch 680/938] [D loss: 0.247176] [G loss: 0.318913] [info loss: 1.470854]\n",
            "[Epoch 28/200] [Batch 681/938] [D loss: 0.309000] [G loss: 0.275759] [info loss: 1.470569]\n",
            "[Epoch 28/200] [Batch 682/938] [D loss: 0.170085] [G loss: 0.289470] [info loss: 1.476010]\n",
            "[Epoch 28/200] [Batch 683/938] [D loss: 0.243226] [G loss: 0.274612] [info loss: 1.483427]\n",
            "[Epoch 28/200] [Batch 684/938] [D loss: 0.199056] [G loss: 0.444684] [info loss: 1.471412]\n",
            "[Epoch 28/200] [Batch 685/938] [D loss: 0.260356] [G loss: 0.194856] [info loss: 1.472879]\n",
            "[Epoch 28/200] [Batch 686/938] [D loss: 0.182564] [G loss: 0.241703] [info loss: 1.480726]\n",
            "[Epoch 28/200] [Batch 687/938] [D loss: 0.223129] [G loss: 0.414459] [info loss: 1.471740]\n",
            "[Epoch 28/200] [Batch 688/938] [D loss: 0.100267] [G loss: 0.399615] [info loss: 1.470507]\n",
            "[Epoch 28/200] [Batch 689/938] [D loss: 0.213667] [G loss: 0.454124] [info loss: 1.506101]\n",
            "[Epoch 28/200] [Batch 690/938] [D loss: 0.221428] [G loss: 0.181325] [info loss: 1.471901]\n",
            "[Epoch 28/200] [Batch 691/938] [D loss: 0.118072] [G loss: 0.253275] [info loss: 1.469794]\n",
            "[Epoch 28/200] [Batch 692/938] [D loss: 0.269067] [G loss: 0.399348] [info loss: 1.470815]\n",
            "[Epoch 28/200] [Batch 693/938] [D loss: 0.225452] [G loss: 0.385901] [info loss: 1.472504]\n",
            "[Epoch 28/200] [Batch 694/938] [D loss: 0.207408] [G loss: 0.281319] [info loss: 1.469244]\n",
            "[Epoch 28/200] [Batch 695/938] [D loss: 0.163492] [G loss: 0.288718] [info loss: 1.488865]\n",
            "[Epoch 28/200] [Batch 696/938] [D loss: 0.192672] [G loss: 0.421608] [info loss: 1.471043]\n",
            "[Epoch 28/200] [Batch 697/938] [D loss: 0.097371] [G loss: 0.328221] [info loss: 1.477861]\n",
            "[Epoch 28/200] [Batch 698/938] [D loss: 0.231454] [G loss: 0.337096] [info loss: 1.486601]\n",
            "[Epoch 28/200] [Batch 699/938] [D loss: 0.188019] [G loss: 0.389387] [info loss: 1.470047]\n",
            "[Epoch 28/200] [Batch 700/938] [D loss: 0.221472] [G loss: 0.163175] [info loss: 1.488366]\n",
            "[Epoch 28/200] [Batch 701/938] [D loss: 0.181272] [G loss: 0.394661] [info loss: 1.479514]\n",
            "[Epoch 28/200] [Batch 702/938] [D loss: 0.245187] [G loss: 0.276922] [info loss: 1.470937]\n",
            "[Epoch 28/200] [Batch 703/938] [D loss: 0.183444] [G loss: 0.236623] [info loss: 1.471949]\n",
            "[Epoch 28/200] [Batch 704/938] [D loss: 0.209330] [G loss: 0.617314] [info loss: 1.470585]\n",
            "[Epoch 28/200] [Batch 705/938] [D loss: 0.168370] [G loss: 0.315542] [info loss: 1.470311]\n",
            "[Epoch 28/200] [Batch 706/938] [D loss: 0.236680] [G loss: 0.342985] [info loss: 1.487503]\n",
            "[Epoch 28/200] [Batch 707/938] [D loss: 0.196156] [G loss: 0.491904] [info loss: 1.483249]\n",
            "[Epoch 28/200] [Batch 708/938] [D loss: 0.254253] [G loss: 0.278585] [info loss: 1.470863]\n",
            "[Epoch 28/200] [Batch 709/938] [D loss: 0.169229] [G loss: 0.225976] [info loss: 1.485967]\n",
            "[Epoch 28/200] [Batch 710/938] [D loss: 0.221194] [G loss: 0.250404] [info loss: 1.476996]\n",
            "[Epoch 28/200] [Batch 711/938] [D loss: 0.202378] [G loss: 0.211409] [info loss: 1.481956]\n",
            "[Epoch 28/200] [Batch 712/938] [D loss: 0.220022] [G loss: 0.194843] [info loss: 1.472688]\n",
            "[Epoch 28/200] [Batch 713/938] [D loss: 0.145098] [G loss: 0.177462] [info loss: 1.469352]\n",
            "[Epoch 28/200] [Batch 714/938] [D loss: 0.193485] [G loss: 0.488793] [info loss: 1.470083]\n",
            "[Epoch 28/200] [Batch 715/938] [D loss: 0.363879] [G loss: 0.519863] [info loss: 1.496609]\n",
            "[Epoch 28/200] [Batch 716/938] [D loss: 0.206340] [G loss: 0.222897] [info loss: 1.478194]\n",
            "[Epoch 28/200] [Batch 717/938] [D loss: 0.292442] [G loss: 0.373954] [info loss: 1.487854]\n",
            "[Epoch 28/200] [Batch 718/938] [D loss: 0.132103] [G loss: 0.271927] [info loss: 1.492552]\n",
            "[Epoch 28/200] [Batch 719/938] [D loss: 0.220813] [G loss: 0.361087] [info loss: 1.472767]\n",
            "[Epoch 28/200] [Batch 720/938] [D loss: 0.273338] [G loss: 0.249694] [info loss: 1.500834]\n",
            "[Epoch 28/200] [Batch 721/938] [D loss: 0.234003] [G loss: 0.347129] [info loss: 1.471460]\n",
            "[Epoch 28/200] [Batch 722/938] [D loss: 0.182613] [G loss: 0.349962] [info loss: 1.472212]\n",
            "[Epoch 28/200] [Batch 723/938] [D loss: 0.192686] [G loss: 0.229058] [info loss: 1.483422]\n",
            "[Epoch 28/200] [Batch 724/938] [D loss: 0.274121] [G loss: 0.467663] [info loss: 1.471072]\n",
            "[Epoch 28/200] [Batch 725/938] [D loss: 0.267398] [G loss: 0.178593] [info loss: 1.483643]\n",
            "[Epoch 28/200] [Batch 726/938] [D loss: 0.115376] [G loss: 0.371661] [info loss: 1.469590]\n",
            "[Epoch 28/200] [Batch 727/938] [D loss: 0.239494] [G loss: 0.263703] [info loss: 1.480095]\n",
            "[Epoch 28/200] [Batch 728/938] [D loss: 0.140562] [G loss: 0.382764] [info loss: 1.473980]\n",
            "[Epoch 28/200] [Batch 729/938] [D loss: 0.197539] [G loss: 0.239138] [info loss: 1.486651]\n",
            "[Epoch 28/200] [Batch 730/938] [D loss: 0.255960] [G loss: 0.314939] [info loss: 1.496253]\n",
            "[Epoch 28/200] [Batch 731/938] [D loss: 0.195812] [G loss: 0.249192] [info loss: 1.469980]\n",
            "[Epoch 28/200] [Batch 732/938] [D loss: 0.257966] [G loss: 0.359580] [info loss: 1.482403]\n",
            "[Epoch 28/200] [Batch 733/938] [D loss: 0.212505] [G loss: 0.202894] [info loss: 1.488507]\n",
            "[Epoch 28/200] [Batch 734/938] [D loss: 0.231687] [G loss: 0.249260] [info loss: 1.485262]\n",
            "[Epoch 28/200] [Batch 735/938] [D loss: 0.254904] [G loss: 0.361478] [info loss: 1.483866]\n",
            "[Epoch 28/200] [Batch 736/938] [D loss: 0.187747] [G loss: 0.450157] [info loss: 1.468731]\n",
            "[Epoch 28/200] [Batch 737/938] [D loss: 0.276038] [G loss: 0.221469] [info loss: 1.473053]\n",
            "[Epoch 28/200] [Batch 738/938] [D loss: 0.192512] [G loss: 0.371822] [info loss: 1.489168]\n",
            "[Epoch 28/200] [Batch 739/938] [D loss: 0.187172] [G loss: 0.189086] [info loss: 1.470868]\n",
            "[Epoch 28/200] [Batch 740/938] [D loss: 0.155327] [G loss: 0.330063] [info loss: 1.496284]\n",
            "[Epoch 28/200] [Batch 741/938] [D loss: 0.217207] [G loss: 0.631136] [info loss: 1.494262]\n",
            "[Epoch 28/200] [Batch 742/938] [D loss: 0.228198] [G loss: 0.386678] [info loss: 1.486861]\n",
            "[Epoch 28/200] [Batch 743/938] [D loss: 0.089178] [G loss: 0.406118] [info loss: 1.480237]\n",
            "[Epoch 28/200] [Batch 744/938] [D loss: 0.250771] [G loss: 0.312832] [info loss: 1.479546]\n",
            "[Epoch 28/200] [Batch 745/938] [D loss: 0.166724] [G loss: 0.315528] [info loss: 1.484411]\n",
            "[Epoch 28/200] [Batch 746/938] [D loss: 0.290308] [G loss: 0.307468] [info loss: 1.475021]\n",
            "[Epoch 28/200] [Batch 747/938] [D loss: 0.191375] [G loss: 0.757366] [info loss: 1.483214]\n",
            "[Epoch 28/200] [Batch 748/938] [D loss: 0.303486] [G loss: 0.448480] [info loss: 1.484787]\n",
            "[Epoch 28/200] [Batch 749/938] [D loss: 0.267191] [G loss: 0.430835] [info loss: 1.474243]\n",
            "[Epoch 28/200] [Batch 750/938] [D loss: 0.123409] [G loss: 0.135426] [info loss: 1.475065]\n",
            "[Epoch 28/200] [Batch 751/938] [D loss: 0.196820] [G loss: 0.278672] [info loss: 1.502830]\n",
            "[Epoch 28/200] [Batch 752/938] [D loss: 0.198076] [G loss: 0.197702] [info loss: 1.474549]\n",
            "[Epoch 28/200] [Batch 753/938] [D loss: 0.216775] [G loss: 0.283342] [info loss: 1.485963]\n",
            "[Epoch 28/200] [Batch 754/938] [D loss: 0.254839] [G loss: 0.565671] [info loss: 1.470737]\n",
            "[Epoch 28/200] [Batch 755/938] [D loss: 0.199415] [G loss: 0.390971] [info loss: 1.471988]\n",
            "[Epoch 28/200] [Batch 756/938] [D loss: 0.271924] [G loss: 0.326165] [info loss: 1.473011]\n",
            "[Epoch 28/200] [Batch 757/938] [D loss: 0.141696] [G loss: 0.442431] [info loss: 1.469236]\n",
            "[Epoch 28/200] [Batch 758/938] [D loss: 0.187260] [G loss: 0.529125] [info loss: 1.484171]\n",
            "[Epoch 28/200] [Batch 759/938] [D loss: 0.284107] [G loss: 0.151056] [info loss: 1.474938]\n",
            "[Epoch 28/200] [Batch 760/938] [D loss: 0.160417] [G loss: 0.273654] [info loss: 1.475564]\n",
            "[Epoch 28/200] [Batch 761/938] [D loss: 0.287687] [G loss: 0.277872] [info loss: 1.480922]\n",
            "[Epoch 28/200] [Batch 762/938] [D loss: 0.171639] [G loss: 0.325860] [info loss: 1.477552]\n",
            "[Epoch 28/200] [Batch 763/938] [D loss: 0.237227] [G loss: 0.212993] [info loss: 1.480467]\n",
            "[Epoch 28/200] [Batch 764/938] [D loss: 0.348810] [G loss: 0.203549] [info loss: 1.470012]\n",
            "[Epoch 28/200] [Batch 765/938] [D loss: 0.162190] [G loss: 0.311255] [info loss: 1.471381]\n",
            "[Epoch 28/200] [Batch 766/938] [D loss: 0.127026] [G loss: 0.321855] [info loss: 1.483859]\n",
            "[Epoch 28/200] [Batch 767/938] [D loss: 0.134811] [G loss: 0.400530] [info loss: 1.472045]\n",
            "[Epoch 28/200] [Batch 768/938] [D loss: 0.253018] [G loss: 0.312197] [info loss: 1.479926]\n",
            "[Epoch 28/200] [Batch 769/938] [D loss: 0.209809] [G loss: 0.222617] [info loss: 1.472229]\n",
            "[Epoch 28/200] [Batch 770/938] [D loss: 0.160740] [G loss: 0.309037] [info loss: 1.478658]\n",
            "[Epoch 28/200] [Batch 771/938] [D loss: 0.200743] [G loss: 0.358925] [info loss: 1.471755]\n",
            "[Epoch 28/200] [Batch 772/938] [D loss: 0.311683] [G loss: 0.236301] [info loss: 1.470880]\n",
            "[Epoch 28/200] [Batch 773/938] [D loss: 0.278401] [G loss: 0.090801] [info loss: 1.481158]\n",
            "[Epoch 28/200] [Batch 774/938] [D loss: 0.283541] [G loss: 0.151149] [info loss: 1.480209]\n",
            "[Epoch 28/200] [Batch 775/938] [D loss: 0.174940] [G loss: 0.350349] [info loss: 1.483613]\n",
            "[Epoch 28/200] [Batch 776/938] [D loss: 0.138215] [G loss: 0.333656] [info loss: 1.486679]\n",
            "[Epoch 28/200] [Batch 777/938] [D loss: 0.206386] [G loss: 0.259458] [info loss: 1.473416]\n",
            "[Epoch 28/200] [Batch 778/938] [D loss: 0.210352] [G loss: 0.174854] [info loss: 1.480664]\n",
            "[Epoch 28/200] [Batch 779/938] [D loss: 0.235935] [G loss: 0.347591] [info loss: 1.485643]\n",
            "[Epoch 28/200] [Batch 780/938] [D loss: 0.205191] [G loss: 0.397612] [info loss: 1.477438]\n",
            "[Epoch 28/200] [Batch 781/938] [D loss: 0.106378] [G loss: 0.264479] [info loss: 1.472967]\n",
            "[Epoch 28/200] [Batch 782/938] [D loss: 0.241465] [G loss: 0.445763] [info loss: 1.499238]\n",
            "[Epoch 28/200] [Batch 783/938] [D loss: 0.280529] [G loss: 0.490703] [info loss: 1.471529]\n",
            "[Epoch 28/200] [Batch 784/938] [D loss: 0.178216] [G loss: 0.402644] [info loss: 1.471629]\n",
            "[Epoch 28/200] [Batch 785/938] [D loss: 0.256877] [G loss: 0.320959] [info loss: 1.476096]\n",
            "[Epoch 28/200] [Batch 786/938] [D loss: 0.260657] [G loss: 0.328570] [info loss: 1.491967]\n",
            "[Epoch 28/200] [Batch 787/938] [D loss: 0.186930] [G loss: 0.150356] [info loss: 1.472658]\n",
            "[Epoch 28/200] [Batch 788/938] [D loss: 0.233163] [G loss: 0.185513] [info loss: 1.488191]\n",
            "[Epoch 28/200] [Batch 789/938] [D loss: 0.117892] [G loss: 0.364091] [info loss: 1.483749]\n",
            "[Epoch 28/200] [Batch 790/938] [D loss: 0.139459] [G loss: 0.372052] [info loss: 1.469395]\n",
            "[Epoch 28/200] [Batch 791/938] [D loss: 0.254909] [G loss: 0.312798] [info loss: 1.473023]\n",
            "[Epoch 28/200] [Batch 792/938] [D loss: 0.210029] [G loss: 0.173691] [info loss: 1.476097]\n",
            "[Epoch 28/200] [Batch 793/938] [D loss: 0.405845] [G loss: 0.409771] [info loss: 1.472410]\n",
            "[Epoch 28/200] [Batch 794/938] [D loss: 0.228100] [G loss: 0.272059] [info loss: 1.486996]\n",
            "[Epoch 28/200] [Batch 795/938] [D loss: 0.159722] [G loss: 0.508319] [info loss: 1.479637]\n",
            "[Epoch 28/200] [Batch 796/938] [D loss: 0.281768] [G loss: 0.364374] [info loss: 1.469906]\n",
            "[Epoch 28/200] [Batch 797/938] [D loss: 0.236315] [G loss: 0.208145] [info loss: 1.472195]\n",
            "[Epoch 28/200] [Batch 798/938] [D loss: 0.350528] [G loss: 0.301049] [info loss: 1.472387]\n",
            "[Epoch 28/200] [Batch 799/938] [D loss: 0.139047] [G loss: 0.278830] [info loss: 1.481531]\n",
            "[Epoch 28/200] [Batch 800/938] [D loss: 0.176285] [G loss: 0.253834] [info loss: 1.479177]\n",
            "[Epoch 28/200] [Batch 801/938] [D loss: 0.303065] [G loss: 0.313929] [info loss: 1.470957]\n",
            "[Epoch 28/200] [Batch 802/938] [D loss: 0.177187] [G loss: 0.293049] [info loss: 1.480555]\n",
            "[Epoch 28/200] [Batch 803/938] [D loss: 0.216839] [G loss: 0.089430] [info loss: 1.482932]\n",
            "[Epoch 28/200] [Batch 804/938] [D loss: 0.177222] [G loss: 0.473478] [info loss: 1.469944]\n",
            "[Epoch 28/200] [Batch 805/938] [D loss: 0.123143] [G loss: 0.330333] [info loss: 1.491179]\n",
            "[Epoch 28/200] [Batch 806/938] [D loss: 0.163336] [G loss: 0.439536] [info loss: 1.470647]\n",
            "[Epoch 28/200] [Batch 807/938] [D loss: 0.301467] [G loss: 0.417235] [info loss: 1.471749]\n",
            "[Epoch 28/200] [Batch 808/938] [D loss: 0.134399] [G loss: 0.179141] [info loss: 1.478609]\n",
            "[Epoch 28/200] [Batch 809/938] [D loss: 0.164029] [G loss: 0.343244] [info loss: 1.474468]\n",
            "[Epoch 28/200] [Batch 810/938] [D loss: 0.268151] [G loss: 0.241586] [info loss: 1.477587]\n",
            "[Epoch 28/200] [Batch 811/938] [D loss: 0.178660] [G loss: 0.459647] [info loss: 1.488847]\n",
            "[Epoch 28/200] [Batch 812/938] [D loss: 0.179133] [G loss: 0.379047] [info loss: 1.471759]\n",
            "[Epoch 28/200] [Batch 813/938] [D loss: 0.213990] [G loss: 0.289660] [info loss: 1.470019]\n",
            "[Epoch 28/200] [Batch 814/938] [D loss: 0.195481] [G loss: 0.224217] [info loss: 1.483655]\n",
            "[Epoch 28/200] [Batch 815/938] [D loss: 0.303791] [G loss: 0.176591] [info loss: 1.480339]\n",
            "[Epoch 28/200] [Batch 816/938] [D loss: 0.222889] [G loss: 0.346245] [info loss: 1.488170]\n",
            "[Epoch 28/200] [Batch 817/938] [D loss: 0.138182] [G loss: 0.382977] [info loss: 1.472849]\n",
            "[Epoch 28/200] [Batch 818/938] [D loss: 0.159078] [G loss: 0.265819] [info loss: 1.471329]\n",
            "[Epoch 28/200] [Batch 819/938] [D loss: 0.185935] [G loss: 0.330778] [info loss: 1.471322]\n",
            "[Epoch 28/200] [Batch 820/938] [D loss: 0.203567] [G loss: 0.405336] [info loss: 1.472016]\n",
            "[Epoch 28/200] [Batch 821/938] [D loss: 0.222258] [G loss: 0.556642] [info loss: 1.489812]\n",
            "[Epoch 28/200] [Batch 822/938] [D loss: 0.191463] [G loss: 0.304173] [info loss: 1.502276]\n",
            "[Epoch 28/200] [Batch 823/938] [D loss: 0.099786] [G loss: 0.213679] [info loss: 1.469313]\n",
            "[Epoch 28/200] [Batch 824/938] [D loss: 0.159302] [G loss: 0.314836] [info loss: 1.470019]\n",
            "[Epoch 28/200] [Batch 825/938] [D loss: 0.257568] [G loss: 0.381955] [info loss: 1.514203]\n",
            "[Epoch 28/200] [Batch 826/938] [D loss: 0.202284] [G loss: 0.617773] [info loss: 1.472512]\n",
            "[Epoch 28/200] [Batch 827/938] [D loss: 0.268963] [G loss: 0.243295] [info loss: 1.473430]\n",
            "[Epoch 28/200] [Batch 828/938] [D loss: 0.168187] [G loss: 0.324704] [info loss: 1.483675]\n",
            "[Epoch 28/200] [Batch 829/938] [D loss: 0.169422] [G loss: 0.189310] [info loss: 1.470134]\n",
            "[Epoch 28/200] [Batch 830/938] [D loss: 0.202266] [G loss: 0.307200] [info loss: 1.477128]\n",
            "[Epoch 28/200] [Batch 831/938] [D loss: 0.232637] [G loss: 0.369408] [info loss: 1.486528]\n",
            "[Epoch 28/200] [Batch 832/938] [D loss: 0.175902] [G loss: 0.404322] [info loss: 1.495274]\n",
            "[Epoch 28/200] [Batch 833/938] [D loss: 0.132769] [G loss: 0.332202] [info loss: 1.503268]\n",
            "[Epoch 28/200] [Batch 834/938] [D loss: 0.209753] [G loss: 0.337648] [info loss: 1.481926]\n",
            "[Epoch 28/200] [Batch 835/938] [D loss: 0.316060] [G loss: 0.263507] [info loss: 1.469637]\n",
            "[Epoch 28/200] [Batch 836/938] [D loss: 0.217682] [G loss: 0.271644] [info loss: 1.472910]\n",
            "[Epoch 28/200] [Batch 837/938] [D loss: 0.231507] [G loss: 0.474137] [info loss: 1.476073]\n",
            "[Epoch 28/200] [Batch 838/938] [D loss: 0.197303] [G loss: 0.419667] [info loss: 1.471449]\n",
            "[Epoch 28/200] [Batch 839/938] [D loss: 0.315344] [G loss: 0.142247] [info loss: 1.470403]\n",
            "[Epoch 28/200] [Batch 840/938] [D loss: 0.301429] [G loss: 0.612952] [info loss: 1.480168]\n",
            "[Epoch 28/200] [Batch 841/938] [D loss: 0.123270] [G loss: 0.252018] [info loss: 1.470085]\n",
            "[Epoch 28/200] [Batch 842/938] [D loss: 0.224817] [G loss: 0.189693] [info loss: 1.468825]\n",
            "[Epoch 28/200] [Batch 843/938] [D loss: 0.278603] [G loss: 0.309238] [info loss: 1.470516]\n",
            "[Epoch 28/200] [Batch 844/938] [D loss: 0.158690] [G loss: 0.332761] [info loss: 1.469382]\n",
            "[Epoch 28/200] [Batch 845/938] [D loss: 0.127962] [G loss: 0.601067] [info loss: 1.479952]\n",
            "[Epoch 28/200] [Batch 846/938] [D loss: 0.245850] [G loss: 0.401190] [info loss: 1.470977]\n",
            "[Epoch 28/200] [Batch 847/938] [D loss: 0.203227] [G loss: 0.393337] [info loss: 1.473495]\n",
            "[Epoch 28/200] [Batch 848/938] [D loss: 0.142556] [G loss: 0.324160] [info loss: 1.483543]\n",
            "[Epoch 28/200] [Batch 849/938] [D loss: 0.227534] [G loss: 0.498969] [info loss: 1.483854]\n",
            "[Epoch 28/200] [Batch 850/938] [D loss: 0.153142] [G loss: 0.301129] [info loss: 1.478741]\n",
            "[Epoch 28/200] [Batch 851/938] [D loss: 0.260288] [G loss: 0.408651] [info loss: 1.504724]\n",
            "[Epoch 28/200] [Batch 852/938] [D loss: 0.191458] [G loss: 0.266511] [info loss: 1.487963]\n",
            "[Epoch 28/200] [Batch 853/938] [D loss: 0.239615] [G loss: 0.165471] [info loss: 1.497699]\n",
            "[Epoch 28/200] [Batch 854/938] [D loss: 0.239628] [G loss: 0.205919] [info loss: 1.469571]\n",
            "[Epoch 28/200] [Batch 855/938] [D loss: 0.212960] [G loss: 0.455785] [info loss: 1.470573]\n",
            "[Epoch 28/200] [Batch 856/938] [D loss: 0.209341] [G loss: 0.276239] [info loss: 1.479810]\n",
            "[Epoch 28/200] [Batch 857/938] [D loss: 0.104680] [G loss: 0.388669] [info loss: 1.491502]\n",
            "[Epoch 28/200] [Batch 858/938] [D loss: 0.234399] [G loss: 0.352617] [info loss: 1.478407]\n",
            "[Epoch 28/200] [Batch 859/938] [D loss: 0.147641] [G loss: 0.339721] [info loss: 1.473564]\n",
            "[Epoch 28/200] [Batch 860/938] [D loss: 0.380019] [G loss: 0.411261] [info loss: 1.471409]\n",
            "[Epoch 28/200] [Batch 861/938] [D loss: 0.192633] [G loss: 0.302319] [info loss: 1.479465]\n",
            "[Epoch 28/200] [Batch 862/938] [D loss: 0.257265] [G loss: 0.744645] [info loss: 1.471236]\n",
            "[Epoch 28/200] [Batch 863/938] [D loss: 0.215157] [G loss: 0.322646] [info loss: 1.480450]\n",
            "[Epoch 28/200] [Batch 864/938] [D loss: 0.238774] [G loss: 0.174913] [info loss: 1.484252]\n",
            "[Epoch 28/200] [Batch 865/938] [D loss: 0.185124] [G loss: 0.377201] [info loss: 1.528595]\n",
            "[Epoch 28/200] [Batch 866/938] [D loss: 0.208223] [G loss: 0.311465] [info loss: 1.484602]\n",
            "[Epoch 28/200] [Batch 867/938] [D loss: 0.254533] [G loss: 0.415011] [info loss: 1.473470]\n",
            "[Epoch 28/200] [Batch 868/938] [D loss: 0.161875] [G loss: 0.377549] [info loss: 1.471834]\n",
            "[Epoch 28/200] [Batch 869/938] [D loss: 0.294821] [G loss: 0.387261] [info loss: 1.470882]\n",
            "[Epoch 28/200] [Batch 870/938] [D loss: 0.286735] [G loss: 0.192054] [info loss: 1.470903]\n",
            "[Epoch 28/200] [Batch 871/938] [D loss: 0.251249] [G loss: 0.603939] [info loss: 1.473221]\n",
            "[Epoch 28/200] [Batch 872/938] [D loss: 0.159584] [G loss: 0.349994] [info loss: 1.477308]\n",
            "[Epoch 28/200] [Batch 873/938] [D loss: 0.225127] [G loss: 0.175497] [info loss: 1.479029]\n",
            "[Epoch 28/200] [Batch 874/938] [D loss: 0.183104] [G loss: 0.568773] [info loss: 1.469589]\n",
            "[Epoch 28/200] [Batch 875/938] [D loss: 0.293796] [G loss: 0.482736] [info loss: 1.479358]\n",
            "[Epoch 28/200] [Batch 876/938] [D loss: 0.142223] [G loss: 0.518821] [info loss: 1.470964]\n",
            "[Epoch 28/200] [Batch 877/938] [D loss: 0.172427] [G loss: 0.308488] [info loss: 1.483405]\n",
            "[Epoch 28/200] [Batch 878/938] [D loss: 0.147001] [G loss: 0.506419] [info loss: 1.470832]\n",
            "[Epoch 28/200] [Batch 879/938] [D loss: 0.210990] [G loss: 0.329299] [info loss: 1.486977]\n",
            "[Epoch 28/200] [Batch 880/938] [D loss: 0.331494] [G loss: 0.500425] [info loss: 1.487925]\n",
            "[Epoch 28/200] [Batch 881/938] [D loss: 0.220787] [G loss: 0.380284] [info loss: 1.471727]\n",
            "[Epoch 28/200] [Batch 882/938] [D loss: 0.220087] [G loss: 0.350685] [info loss: 1.470110]\n",
            "[Epoch 28/200] [Batch 883/938] [D loss: 0.143397] [G loss: 0.201847] [info loss: 1.471878]\n",
            "[Epoch 28/200] [Batch 884/938] [D loss: 0.240752] [G loss: 0.426548] [info loss: 1.469242]\n",
            "[Epoch 28/200] [Batch 885/938] [D loss: 0.220786] [G loss: 0.412567] [info loss: 1.471284]\n",
            "[Epoch 28/200] [Batch 886/938] [D loss: 0.121854] [G loss: 0.358669] [info loss: 1.490829]\n",
            "[Epoch 28/200] [Batch 887/938] [D loss: 0.321738] [G loss: 0.336701] [info loss: 1.481845]\n",
            "[Epoch 28/200] [Batch 888/938] [D loss: 0.173261] [G loss: 0.181843] [info loss: 1.471943]\n",
            "[Epoch 28/200] [Batch 889/938] [D loss: 0.186500] [G loss: 0.228913] [info loss: 1.474660]\n",
            "[Epoch 28/200] [Batch 890/938] [D loss: 0.310200] [G loss: 0.557489] [info loss: 1.486441]\n",
            "[Epoch 28/200] [Batch 891/938] [D loss: 0.113213] [G loss: 0.499774] [info loss: 1.474743]\n",
            "[Epoch 28/200] [Batch 892/938] [D loss: 0.251576] [G loss: 0.386580] [info loss: 1.469171]\n",
            "[Epoch 28/200] [Batch 893/938] [D loss: 0.122642] [G loss: 0.279999] [info loss: 1.489104]\n",
            "[Epoch 28/200] [Batch 894/938] [D loss: 0.184689] [G loss: 0.204521] [info loss: 1.472861]\n",
            "[Epoch 28/200] [Batch 895/938] [D loss: 0.228518] [G loss: 0.243845] [info loss: 1.478701]\n",
            "[Epoch 28/200] [Batch 896/938] [D loss: 0.315530] [G loss: 0.300334] [info loss: 1.468930]\n",
            "[Epoch 28/200] [Batch 897/938] [D loss: 0.263924] [G loss: 0.209971] [info loss: 1.472034]\n",
            "[Epoch 28/200] [Batch 898/938] [D loss: 0.263023] [G loss: 0.292971] [info loss: 1.489943]\n",
            "[Epoch 28/200] [Batch 899/938] [D loss: 0.192862] [G loss: 0.431813] [info loss: 1.470105]\n",
            "[Epoch 28/200] [Batch 900/938] [D loss: 0.317789] [G loss: 0.212290] [info loss: 1.471088]\n",
            "[Epoch 28/200] [Batch 901/938] [D loss: 0.299881] [G loss: 0.525411] [info loss: 1.471048]\n",
            "[Epoch 28/200] [Batch 902/938] [D loss: 0.178654] [G loss: 0.309923] [info loss: 1.487850]\n",
            "[Epoch 28/200] [Batch 903/938] [D loss: 0.321773] [G loss: 0.253847] [info loss: 1.473001]\n",
            "[Epoch 28/200] [Batch 904/938] [D loss: 0.175403] [G loss: 0.187293] [info loss: 1.470068]\n",
            "[Epoch 28/200] [Batch 905/938] [D loss: 0.288542] [G loss: 0.174292] [info loss: 1.485614]\n",
            "[Epoch 28/200] [Batch 906/938] [D loss: 0.102743] [G loss: 0.415466] [info loss: 1.500219]\n",
            "[Epoch 28/200] [Batch 907/938] [D loss: 0.182524] [G loss: 0.316285] [info loss: 1.469858]\n",
            "[Epoch 28/200] [Batch 908/938] [D loss: 0.208337] [G loss: 0.291795] [info loss: 1.485789]\n",
            "[Epoch 28/200] [Batch 909/938] [D loss: 0.272048] [G loss: 0.244055] [info loss: 1.470933]\n",
            "[Epoch 28/200] [Batch 910/938] [D loss: 0.282581] [G loss: 0.343909] [info loss: 1.490479]\n",
            "[Epoch 28/200] [Batch 911/938] [D loss: 0.246085] [G loss: 0.372624] [info loss: 1.472138]\n",
            "[Epoch 28/200] [Batch 912/938] [D loss: 0.210245] [G loss: 0.427745] [info loss: 1.471344]\n",
            "[Epoch 28/200] [Batch 913/938] [D loss: 0.209832] [G loss: 0.271754] [info loss: 1.473833]\n",
            "[Epoch 28/200] [Batch 914/938] [D loss: 0.214715] [G loss: 0.131372] [info loss: 1.479587]\n",
            "[Epoch 28/200] [Batch 915/938] [D loss: 0.260536] [G loss: 0.185737] [info loss: 1.486786]\n",
            "[Epoch 28/200] [Batch 916/938] [D loss: 0.176764] [G loss: 0.364256] [info loss: 1.468519]\n",
            "[Epoch 28/200] [Batch 917/938] [D loss: 0.206461] [G loss: 0.442026] [info loss: 1.470345]\n",
            "[Epoch 28/200] [Batch 918/938] [D loss: 0.152287] [G loss: 0.388904] [info loss: 1.473964]\n",
            "[Epoch 28/200] [Batch 919/938] [D loss: 0.247706] [G loss: 0.241574] [info loss: 1.473291]\n",
            "[Epoch 28/200] [Batch 920/938] [D loss: 0.198818] [G loss: 0.223029] [info loss: 1.471341]\n",
            "[Epoch 28/200] [Batch 921/938] [D loss: 0.282288] [G loss: 0.483996] [info loss: 1.470450]\n",
            "[Epoch 28/200] [Batch 922/938] [D loss: 0.175912] [G loss: 0.541962] [info loss: 1.487613]\n",
            "[Epoch 28/200] [Batch 923/938] [D loss: 0.142873] [G loss: 0.426616] [info loss: 1.469321]\n",
            "[Epoch 28/200] [Batch 924/938] [D loss: 0.178972] [G loss: 0.461769] [info loss: 1.471065]\n",
            "[Epoch 28/200] [Batch 925/938] [D loss: 0.160863] [G loss: 0.318682] [info loss: 1.474988]\n",
            "[Epoch 28/200] [Batch 926/938] [D loss: 0.268666] [G loss: 0.345710] [info loss: 1.471027]\n",
            "[Epoch 28/200] [Batch 927/938] [D loss: 0.182348] [G loss: 0.218709] [info loss: 1.471743]\n",
            "[Epoch 28/200] [Batch 928/938] [D loss: 0.251067] [G loss: 0.351679] [info loss: 1.471246]\n",
            "[Epoch 28/200] [Batch 929/938] [D loss: 0.223694] [G loss: 0.344503] [info loss: 1.479092]\n",
            "[Epoch 28/200] [Batch 930/938] [D loss: 0.196230] [G loss: 0.220111] [info loss: 1.494327]\n",
            "[Epoch 28/200] [Batch 931/938] [D loss: 0.170566] [G loss: 0.357565] [info loss: 1.475265]\n",
            "[Epoch 28/200] [Batch 932/938] [D loss: 0.142846] [G loss: 0.293451] [info loss: 1.478436]\n",
            "[Epoch 28/200] [Batch 933/938] [D loss: 0.230639] [G loss: 0.232123] [info loss: 1.482249]\n",
            "[Epoch 28/200] [Batch 934/938] [D loss: 0.143694] [G loss: 0.264351] [info loss: 1.470127]\n",
            "[Epoch 28/200] [Batch 935/938] [D loss: 0.167194] [G loss: 0.341169] [info loss: 1.469681]\n",
            "[Epoch 28/200] [Batch 936/938] [D loss: 0.160327] [G loss: 0.227952] [info loss: 1.473013]\n",
            "[Epoch 28/200] [Batch 937/938] [D loss: 0.119063] [G loss: 0.397602] [info loss: 1.469612]\n",
            "[Epoch 29/200] [Batch 0/938] [D loss: 0.209452] [G loss: 0.415684] [info loss: 1.471743]\n",
            "[Epoch 29/200] [Batch 1/938] [D loss: 0.184212] [G loss: 0.222517] [info loss: 1.502940]\n",
            "[Epoch 29/200] [Batch 2/938] [D loss: 0.224479] [G loss: 0.332005] [info loss: 1.472223]\n",
            "[Epoch 29/200] [Batch 3/938] [D loss: 0.217981] [G loss: 0.271381] [info loss: 1.486518]\n",
            "[Epoch 29/200] [Batch 4/938] [D loss: 0.280980] [G loss: 0.398142] [info loss: 1.488553]\n",
            "[Epoch 29/200] [Batch 5/938] [D loss: 0.214710] [G loss: 0.521937] [info loss: 1.469492]\n",
            "[Epoch 29/200] [Batch 6/938] [D loss: 0.262821] [G loss: 0.310350] [info loss: 1.491312]\n",
            "[Epoch 29/200] [Batch 7/938] [D loss: 0.206614] [G loss: 0.235190] [info loss: 1.490089]\n",
            "[Epoch 29/200] [Batch 8/938] [D loss: 0.200820] [G loss: 0.511052] [info loss: 1.469982]\n",
            "[Epoch 29/200] [Batch 9/938] [D loss: 0.291960] [G loss: 0.654043] [info loss: 1.495949]\n",
            "[Epoch 29/200] [Batch 10/938] [D loss: 0.255739] [G loss: 0.229364] [info loss: 1.481312]\n",
            "[Epoch 29/200] [Batch 11/938] [D loss: 0.220545] [G loss: 0.168756] [info loss: 1.470524]\n",
            "[Epoch 29/200] [Batch 12/938] [D loss: 0.196392] [G loss: 0.311950] [info loss: 1.508435]\n",
            "[Epoch 29/200] [Batch 13/938] [D loss: 0.307732] [G loss: 0.483303] [info loss: 1.472111]\n",
            "[Epoch 29/200] [Batch 14/938] [D loss: 0.247303] [G loss: 0.275320] [info loss: 1.487919]\n",
            "[Epoch 29/200] [Batch 15/938] [D loss: 0.125319] [G loss: 0.442863] [info loss: 1.472483]\n",
            "[Epoch 29/200] [Batch 16/938] [D loss: 0.205497] [G loss: 0.459596] [info loss: 1.487586]\n",
            "[Epoch 29/200] [Batch 17/938] [D loss: 0.213867] [G loss: 0.263351] [info loss: 1.470432]\n",
            "[Epoch 29/200] [Batch 18/938] [D loss: 0.239216] [G loss: 0.268084] [info loss: 1.490220]\n",
            "[Epoch 29/200] [Batch 19/938] [D loss: 0.263803] [G loss: 0.239575] [info loss: 1.477674]\n",
            "[Epoch 29/200] [Batch 20/938] [D loss: 0.208694] [G loss: 0.280923] [info loss: 1.502153]\n",
            "[Epoch 29/200] [Batch 21/938] [D loss: 0.180093] [G loss: 0.209734] [info loss: 1.488392]\n",
            "[Epoch 29/200] [Batch 22/938] [D loss: 0.194905] [G loss: 0.248662] [info loss: 1.486390]\n",
            "[Epoch 29/200] [Batch 23/938] [D loss: 0.297627] [G loss: 0.343253] [info loss: 1.473187]\n",
            "[Epoch 29/200] [Batch 24/938] [D loss: 0.233421] [G loss: 0.406248] [info loss: 1.480223]\n",
            "[Epoch 29/200] [Batch 25/938] [D loss: 0.157689] [G loss: 0.108394] [info loss: 1.479933]\n",
            "[Epoch 29/200] [Batch 26/938] [D loss: 0.227400] [G loss: 0.293106] [info loss: 1.482495]\n",
            "[Epoch 29/200] [Batch 27/938] [D loss: 0.146058] [G loss: 0.363483] [info loss: 1.480717]\n",
            "[Epoch 29/200] [Batch 28/938] [D loss: 0.194647] [G loss: 0.288250] [info loss: 1.503285]\n",
            "[Epoch 29/200] [Batch 29/938] [D loss: 0.287995] [G loss: 0.578161] [info loss: 1.469425]\n",
            "[Epoch 29/200] [Batch 30/938] [D loss: 0.153731] [G loss: 0.356405] [info loss: 1.473877]\n",
            "[Epoch 29/200] [Batch 31/938] [D loss: 0.210245] [G loss: 0.494265] [info loss: 1.493123]\n",
            "[Epoch 29/200] [Batch 32/938] [D loss: 0.124199] [G loss: 0.275229] [info loss: 1.474692]\n",
            "[Epoch 29/200] [Batch 33/938] [D loss: 0.164833] [G loss: 0.337045] [info loss: 1.491360]\n",
            "[Epoch 29/200] [Batch 34/938] [D loss: 0.261827] [G loss: 0.188369] [info loss: 1.474789]\n",
            "[Epoch 29/200] [Batch 35/938] [D loss: 0.209058] [G loss: 0.201002] [info loss: 1.478837]\n",
            "[Epoch 29/200] [Batch 36/938] [D loss: 0.310188] [G loss: 0.525100] [info loss: 1.499568]\n",
            "[Epoch 29/200] [Batch 37/938] [D loss: 0.265573] [G loss: 0.268253] [info loss: 1.470730]\n",
            "[Epoch 29/200] [Batch 38/938] [D loss: 0.181011] [G loss: 0.326836] [info loss: 1.486302]\n",
            "[Epoch 29/200] [Batch 39/938] [D loss: 0.149682] [G loss: 0.552288] [info loss: 1.470020]\n",
            "[Epoch 29/200] [Batch 40/938] [D loss: 0.280966] [G loss: 0.392291] [info loss: 1.491117]\n",
            "[Epoch 29/200] [Batch 41/938] [D loss: 0.276087] [G loss: 0.371537] [info loss: 1.478662]\n",
            "[Epoch 29/200] [Batch 42/938] [D loss: 0.305309] [G loss: 0.258484] [info loss: 1.469778]\n",
            "[Epoch 29/200] [Batch 43/938] [D loss: 0.219442] [G loss: 0.327181] [info loss: 1.472645]\n",
            "[Epoch 29/200] [Batch 44/938] [D loss: 0.245247] [G loss: 0.417319] [info loss: 1.470848]\n",
            "[Epoch 29/200] [Batch 45/938] [D loss: 0.193749] [G loss: 0.317403] [info loss: 1.475958]\n",
            "[Epoch 29/200] [Batch 46/938] [D loss: 0.183512] [G loss: 0.261051] [info loss: 1.478757]\n",
            "[Epoch 29/200] [Batch 47/938] [D loss: 0.251815] [G loss: 0.207821] [info loss: 1.471295]\n",
            "[Epoch 29/200] [Batch 48/938] [D loss: 0.225413] [G loss: 0.309607] [info loss: 1.489052]\n",
            "[Epoch 29/200] [Batch 49/938] [D loss: 0.175151] [G loss: 0.751963] [info loss: 1.495082]\n",
            "[Epoch 29/200] [Batch 50/938] [D loss: 0.189538] [G loss: 0.318534] [info loss: 1.478524]\n",
            "[Epoch 29/200] [Batch 51/938] [D loss: 0.150879] [G loss: 0.333142] [info loss: 1.472277]\n",
            "[Epoch 29/200] [Batch 52/938] [D loss: 0.232043] [G loss: 0.207321] [info loss: 1.486007]\n",
            "[Epoch 29/200] [Batch 53/938] [D loss: 0.098599] [G loss: 0.343893] [info loss: 1.474640]\n",
            "[Epoch 29/200] [Batch 54/938] [D loss: 0.176739] [G loss: 0.400405] [info loss: 1.475170]\n",
            "[Epoch 29/200] [Batch 55/938] [D loss: 0.239384] [G loss: 0.310116] [info loss: 1.470501]\n",
            "[Epoch 29/200] [Batch 56/938] [D loss: 0.214546] [G loss: 0.331458] [info loss: 1.481379]\n",
            "[Epoch 29/200] [Batch 57/938] [D loss: 0.148032] [G loss: 0.310196] [info loss: 1.471335]\n",
            "[Epoch 29/200] [Batch 58/938] [D loss: 0.274326] [G loss: 0.255310] [info loss: 1.468816]\n",
            "[Epoch 29/200] [Batch 59/938] [D loss: 0.363366] [G loss: 0.208441] [info loss: 1.501151]\n",
            "[Epoch 29/200] [Batch 60/938] [D loss: 0.266392] [G loss: 0.240864] [info loss: 1.493832]\n",
            "[Epoch 29/200] [Batch 61/938] [D loss: 0.135839] [G loss: 0.374244] [info loss: 1.476232]\n",
            "[Epoch 29/200] [Batch 62/938] [D loss: 0.110063] [G loss: 0.466054] [info loss: 1.476987]\n",
            "[Epoch 29/200] [Batch 63/938] [D loss: 0.183145] [G loss: 0.388645] [info loss: 1.471132]\n",
            "[Epoch 29/200] [Batch 64/938] [D loss: 0.211801] [G loss: 0.346363] [info loss: 1.469408]\n",
            "[Epoch 29/200] [Batch 65/938] [D loss: 0.212565] [G loss: 0.319996] [info loss: 1.476234]\n",
            "[Epoch 29/200] [Batch 66/938] [D loss: 0.262084] [G loss: 0.212272] [info loss: 1.499227]\n",
            "[Epoch 29/200] [Batch 67/938] [D loss: 0.209585] [G loss: 0.163755] [info loss: 1.473676]\n",
            "[Epoch 29/200] [Batch 68/938] [D loss: 0.219498] [G loss: 0.261832] [info loss: 1.489371]\n",
            "[Epoch 29/200] [Batch 69/938] [D loss: 0.320963] [G loss: 0.454365] [info loss: 1.479136]\n",
            "[Epoch 29/200] [Batch 70/938] [D loss: 0.217378] [G loss: 0.335471] [info loss: 1.478600]\n",
            "[Epoch 29/200] [Batch 71/938] [D loss: 0.204574] [G loss: 0.497037] [info loss: 1.496106]\n",
            "[Epoch 29/200] [Batch 72/938] [D loss: 0.285976] [G loss: 0.455806] [info loss: 1.473153]\n",
            "[Epoch 29/200] [Batch 73/938] [D loss: 0.249808] [G loss: 0.426113] [info loss: 1.479968]\n",
            "[Epoch 29/200] [Batch 74/938] [D loss: 0.219184] [G loss: 0.112746] [info loss: 1.469419]\n",
            "[Epoch 29/200] [Batch 75/938] [D loss: 0.170433] [G loss: 0.236576] [info loss: 1.470825]\n",
            "[Epoch 29/200] [Batch 76/938] [D loss: 0.152995] [G loss: 0.355872] [info loss: 1.485894]\n",
            "[Epoch 29/200] [Batch 77/938] [D loss: 0.117195] [G loss: 0.269007] [info loss: 1.481659]\n",
            "[Epoch 29/200] [Batch 78/938] [D loss: 0.222348] [G loss: 0.517361] [info loss: 1.486083]\n",
            "[Epoch 29/200] [Batch 79/938] [D loss: 0.179169] [G loss: 0.428719] [info loss: 1.471016]\n",
            "[Epoch 29/200] [Batch 80/938] [D loss: 0.229513] [G loss: 0.341624] [info loss: 1.470821]\n",
            "[Epoch 29/200] [Batch 81/938] [D loss: 0.256773] [G loss: 0.508614] [info loss: 1.478730]\n",
            "[Epoch 29/200] [Batch 82/938] [D loss: 0.167867] [G loss: 0.297829] [info loss: 1.469565]\n",
            "[Epoch 29/200] [Batch 83/938] [D loss: 0.201347] [G loss: 0.226495] [info loss: 1.471050]\n",
            "[Epoch 29/200] [Batch 84/938] [D loss: 0.255915] [G loss: 0.415882] [info loss: 1.472196]\n",
            "[Epoch 29/200] [Batch 85/938] [D loss: 0.172264] [G loss: 0.224827] [info loss: 1.470453]\n",
            "[Epoch 29/200] [Batch 86/938] [D loss: 0.225545] [G loss: 0.357810] [info loss: 1.485442]\n",
            "[Epoch 29/200] [Batch 87/938] [D loss: 0.212464] [G loss: 0.411084] [info loss: 1.471637]\n",
            "[Epoch 29/200] [Batch 88/938] [D loss: 0.177594] [G loss: 0.174886] [info loss: 1.475909]\n",
            "[Epoch 29/200] [Batch 89/938] [D loss: 0.239862] [G loss: 0.349639] [info loss: 1.479417]\n",
            "[Epoch 29/200] [Batch 90/938] [D loss: 0.240533] [G loss: 0.237611] [info loss: 1.475574]\n",
            "[Epoch 29/200] [Batch 91/938] [D loss: 0.173362] [G loss: 0.159648] [info loss: 1.471684]\n",
            "[Epoch 29/200] [Batch 92/938] [D loss: 0.209221] [G loss: 0.313010] [info loss: 1.492773]\n",
            "[Epoch 29/200] [Batch 93/938] [D loss: 0.156732] [G loss: 0.359101] [info loss: 1.484334]\n",
            "[Epoch 29/200] [Batch 94/938] [D loss: 0.238398] [G loss: 0.365725] [info loss: 1.494059]\n",
            "[Epoch 29/200] [Batch 95/938] [D loss: 0.234032] [G loss: 0.398459] [info loss: 1.484596]\n",
            "[Epoch 29/200] [Batch 96/938] [D loss: 0.167474] [G loss: 0.141231] [info loss: 1.469902]\n",
            "[Epoch 29/200] [Batch 97/938] [D loss: 0.181625] [G loss: 0.268778] [info loss: 1.476866]\n",
            "[Epoch 29/200] [Batch 98/938] [D loss: 0.152743] [G loss: 0.167407] [info loss: 1.484300]\n",
            "[Epoch 29/200] [Batch 99/938] [D loss: 0.189640] [G loss: 0.274311] [info loss: 1.490474]\n",
            "[Epoch 29/200] [Batch 100/938] [D loss: 0.256855] [G loss: 0.364721] [info loss: 1.471583]\n",
            "[Epoch 29/200] [Batch 101/938] [D loss: 0.178695] [G loss: 0.376846] [info loss: 1.471746]\n",
            "[Epoch 29/200] [Batch 102/938] [D loss: 0.192493] [G loss: 0.392133] [info loss: 1.470454]\n",
            "[Epoch 29/200] [Batch 103/938] [D loss: 0.158471] [G loss: 0.257902] [info loss: 1.478803]\n",
            "[Epoch 29/200] [Batch 104/938] [D loss: 0.229004] [G loss: 0.435396] [info loss: 1.472490]\n",
            "[Epoch 29/200] [Batch 105/938] [D loss: 0.157278] [G loss: 0.388796] [info loss: 1.486145]\n",
            "[Epoch 29/200] [Batch 106/938] [D loss: 0.258061] [G loss: 0.223693] [info loss: 1.471315]\n",
            "[Epoch 29/200] [Batch 107/938] [D loss: 0.192212] [G loss: 0.318306] [info loss: 1.475121]\n",
            "[Epoch 29/200] [Batch 108/938] [D loss: 0.217551] [G loss: 0.140149] [info loss: 1.502562]\n",
            "[Epoch 29/200] [Batch 109/938] [D loss: 0.254914] [G loss: 0.162215] [info loss: 1.469287]\n",
            "[Epoch 29/200] [Batch 110/938] [D loss: 0.158786] [G loss: 0.477199] [info loss: 1.469257]\n",
            "[Epoch 29/200] [Batch 111/938] [D loss: 0.235799] [G loss: 0.513842] [info loss: 1.493462]\n",
            "[Epoch 29/200] [Batch 112/938] [D loss: 0.265096] [G loss: 0.228754] [info loss: 1.470904]\n",
            "[Epoch 29/200] [Batch 113/938] [D loss: 0.308061] [G loss: 0.368856] [info loss: 1.471694]\n",
            "[Epoch 29/200] [Batch 114/938] [D loss: 0.205129] [G loss: 0.266817] [info loss: 1.488623]\n",
            "[Epoch 29/200] [Batch 115/938] [D loss: 0.164285] [G loss: 0.487247] [info loss: 1.484702]\n",
            "[Epoch 29/200] [Batch 116/938] [D loss: 0.354333] [G loss: 0.131476] [info loss: 1.513150]\n",
            "[Epoch 29/200] [Batch 117/938] [D loss: 0.231709] [G loss: 0.156699] [info loss: 1.475761]\n",
            "[Epoch 29/200] [Batch 118/938] [D loss: 0.171390] [G loss: 0.373965] [info loss: 1.473824]\n",
            "[Epoch 29/200] [Batch 119/938] [D loss: 0.125509] [G loss: 0.473785] [info loss: 1.496341]\n",
            "[Epoch 29/200] [Batch 120/938] [D loss: 0.265276] [G loss: 0.469796] [info loss: 1.479917]\n",
            "[Epoch 29/200] [Batch 121/938] [D loss: 0.265953] [G loss: 0.112409] [info loss: 1.471174]\n",
            "[Epoch 29/200] [Batch 122/938] [D loss: 0.164694] [G loss: 0.598077] [info loss: 1.514833]\n",
            "[Epoch 29/200] [Batch 123/938] [D loss: 0.203596] [G loss: 0.423225] [info loss: 1.472332]\n",
            "[Epoch 29/200] [Batch 124/938] [D loss: 0.344926] [G loss: 0.427255] [info loss: 1.469794]\n",
            "[Epoch 29/200] [Batch 125/938] [D loss: 0.165252] [G loss: 0.575112] [info loss: 1.483714]\n",
            "[Epoch 29/200] [Batch 126/938] [D loss: 0.265193] [G loss: 0.357606] [info loss: 1.469198]\n",
            "[Epoch 29/200] [Batch 127/938] [D loss: 0.207305] [G loss: 0.268692] [info loss: 1.491236]\n",
            "[Epoch 29/200] [Batch 128/938] [D loss: 0.264256] [G loss: 0.351638] [info loss: 1.469466]\n",
            "[Epoch 29/200] [Batch 129/938] [D loss: 0.224889] [G loss: 0.670500] [info loss: 1.490086]\n",
            "[Epoch 29/200] [Batch 130/938] [D loss: 0.245214] [G loss: 0.424801] [info loss: 1.470129]\n",
            "[Epoch 29/200] [Batch 131/938] [D loss: 0.213740] [G loss: 0.566806] [info loss: 1.506833]\n",
            "[Epoch 29/200] [Batch 132/938] [D loss: 0.282911] [G loss: 0.383275] [info loss: 1.470196]\n",
            "[Epoch 29/200] [Batch 133/938] [D loss: 0.202669] [G loss: 0.133564] [info loss: 1.469756]\n",
            "[Epoch 29/200] [Batch 134/938] [D loss: 0.180989] [G loss: 0.219796] [info loss: 1.475287]\n",
            "[Epoch 29/200] [Batch 135/938] [D loss: 0.225903] [G loss: 0.087265] [info loss: 1.491967]\n",
            "[Epoch 29/200] [Batch 136/938] [D loss: 0.171430] [G loss: 0.292132] [info loss: 1.486406]\n",
            "[Epoch 29/200] [Batch 137/938] [D loss: 0.244990] [G loss: 0.205581] [info loss: 1.484948]\n",
            "[Epoch 29/200] [Batch 138/938] [D loss: 0.185880] [G loss: 0.323938] [info loss: 1.492019]\n",
            "[Epoch 29/200] [Batch 139/938] [D loss: 0.262917] [G loss: 0.141629] [info loss: 1.472143]\n",
            "[Epoch 29/200] [Batch 140/938] [D loss: 0.173724] [G loss: 0.389982] [info loss: 1.475560]\n",
            "[Epoch 29/200] [Batch 141/938] [D loss: 0.253150] [G loss: 0.493178] [info loss: 1.485223]\n",
            "[Epoch 29/200] [Batch 142/938] [D loss: 0.174000] [G loss: 0.201568] [info loss: 1.473830]\n",
            "[Epoch 29/200] [Batch 143/938] [D loss: 0.246154] [G loss: 0.207748] [info loss: 1.486817]\n",
            "[Epoch 29/200] [Batch 144/938] [D loss: 0.236478] [G loss: 0.320502] [info loss: 1.471963]\n",
            "[Epoch 29/200] [Batch 145/938] [D loss: 0.189777] [G loss: 0.265387] [info loss: 1.477626]\n",
            "[Epoch 29/200] [Batch 146/938] [D loss: 0.209315] [G loss: 0.743783] [info loss: 1.471495]\n",
            "[Epoch 29/200] [Batch 147/938] [D loss: 0.209046] [G loss: 0.579691] [info loss: 1.476679]\n",
            "[Epoch 29/200] [Batch 148/938] [D loss: 0.165631] [G loss: 0.359373] [info loss: 1.471488]\n",
            "[Epoch 29/200] [Batch 149/938] [D loss: 0.192300] [G loss: 0.203726] [info loss: 1.492392]\n",
            "[Epoch 29/200] [Batch 150/938] [D loss: 0.245222] [G loss: 0.114393] [info loss: 1.470036]\n",
            "[Epoch 29/200] [Batch 151/938] [D loss: 0.177864] [G loss: 0.524482] [info loss: 1.471590]\n",
            "[Epoch 29/200] [Batch 152/938] [D loss: 0.232853] [G loss: 0.699134] [info loss: 1.470245]\n",
            "[Epoch 29/200] [Batch 153/938] [D loss: 0.223717] [G loss: 0.497556] [info loss: 1.471032]\n",
            "[Epoch 29/200] [Batch 154/938] [D loss: 0.237528] [G loss: 0.285568] [info loss: 1.495398]\n",
            "[Epoch 29/200] [Batch 155/938] [D loss: 0.285746] [G loss: 0.594999] [info loss: 1.497392]\n",
            "[Epoch 29/200] [Batch 156/938] [D loss: 0.332498] [G loss: 0.257480] [info loss: 1.468783]\n",
            "[Epoch 29/200] [Batch 157/938] [D loss: 0.207490] [G loss: 0.155551] [info loss: 1.472766]\n",
            "[Epoch 29/200] [Batch 158/938] [D loss: 0.257186] [G loss: 0.152125] [info loss: 1.487630]\n",
            "[Epoch 29/200] [Batch 159/938] [D loss: 0.260676] [G loss: 0.266437] [info loss: 1.472100]\n",
            "[Epoch 29/200] [Batch 160/938] [D loss: 0.174859] [G loss: 0.332608] [info loss: 1.470403]\n",
            "[Epoch 29/200] [Batch 161/938] [D loss: 0.305080] [G loss: 0.212780] [info loss: 1.470398]\n",
            "[Epoch 29/200] [Batch 162/938] [D loss: 0.132478] [G loss: 0.300901] [info loss: 1.471608]\n",
            "[Epoch 29/200] [Batch 163/938] [D loss: 0.195986] [G loss: 0.332414] [info loss: 1.471451]\n",
            "[Epoch 29/200] [Batch 164/938] [D loss: 0.194500] [G loss: 0.355048] [info loss: 1.475599]\n",
            "[Epoch 29/200] [Batch 165/938] [D loss: 0.232827] [G loss: 0.354130] [info loss: 1.506350]\n",
            "[Epoch 29/200] [Batch 166/938] [D loss: 0.226893] [G loss: 0.335373] [info loss: 1.479239]\n",
            "[Epoch 29/200] [Batch 167/938] [D loss: 0.267853] [G loss: 0.300750] [info loss: 1.471052]\n",
            "[Epoch 29/200] [Batch 168/938] [D loss: 0.221301] [G loss: 0.322587] [info loss: 1.490205]\n",
            "[Epoch 29/200] [Batch 169/938] [D loss: 0.146586] [G loss: 0.236408] [info loss: 1.495752]\n",
            "[Epoch 29/200] [Batch 170/938] [D loss: 0.167069] [G loss: 0.266026] [info loss: 1.507987]\n",
            "[Epoch 29/200] [Batch 171/938] [D loss: 0.145362] [G loss: 0.231566] [info loss: 1.470334]\n",
            "[Epoch 29/200] [Batch 172/938] [D loss: 0.360404] [G loss: 0.402145] [info loss: 1.471343]\n",
            "[Epoch 29/200] [Batch 173/938] [D loss: 0.117114] [G loss: 0.136376] [info loss: 1.475364]\n",
            "[Epoch 29/200] [Batch 174/938] [D loss: 0.192366] [G loss: 0.282719] [info loss: 1.479529]\n",
            "[Epoch 29/200] [Batch 175/938] [D loss: 0.339732] [G loss: 0.447862] [info loss: 1.472995]\n",
            "[Epoch 29/200] [Batch 176/938] [D loss: 0.223314] [G loss: 0.155862] [info loss: 1.491135]\n",
            "[Epoch 29/200] [Batch 177/938] [D loss: 0.210090] [G loss: 0.240362] [info loss: 1.474017]\n",
            "[Epoch 29/200] [Batch 178/938] [D loss: 0.155013] [G loss: 0.347923] [info loss: 1.469951]\n",
            "[Epoch 29/200] [Batch 179/938] [D loss: 0.270569] [G loss: 0.428860] [info loss: 1.471655]\n",
            "[Epoch 29/200] [Batch 180/938] [D loss: 0.236195] [G loss: 0.253753] [info loss: 1.485480]\n",
            "[Epoch 29/200] [Batch 181/938] [D loss: 0.329999] [G loss: 0.148677] [info loss: 1.486072]\n",
            "[Epoch 29/200] [Batch 182/938] [D loss: 0.227213] [G loss: 0.185396] [info loss: 1.488598]\n",
            "[Epoch 29/200] [Batch 183/938] [D loss: 0.184818] [G loss: 0.311469] [info loss: 1.471164]\n",
            "[Epoch 29/200] [Batch 184/938] [D loss: 0.297498] [G loss: 0.533033] [info loss: 1.473006]\n",
            "[Epoch 29/200] [Batch 185/938] [D loss: 0.182545] [G loss: 0.468428] [info loss: 1.484388]\n",
            "[Epoch 29/200] [Batch 186/938] [D loss: 0.278884] [G loss: 0.229312] [info loss: 1.471099]\n",
            "[Epoch 29/200] [Batch 187/938] [D loss: 0.223772] [G loss: 0.298739] [info loss: 1.472203]\n",
            "[Epoch 29/200] [Batch 188/938] [D loss: 0.208403] [G loss: 0.425533] [info loss: 1.471471]\n",
            "[Epoch 29/200] [Batch 189/938] [D loss: 0.203990] [G loss: 0.386331] [info loss: 1.488214]\n",
            "[Epoch 29/200] [Batch 190/938] [D loss: 0.158522] [G loss: 0.459421] [info loss: 1.478712]\n",
            "[Epoch 29/200] [Batch 191/938] [D loss: 0.230523] [G loss: 0.392359] [info loss: 1.486282]\n",
            "[Epoch 29/200] [Batch 192/938] [D loss: 0.298354] [G loss: 0.483872] [info loss: 1.472942]\n",
            "[Epoch 29/200] [Batch 193/938] [D loss: 0.273116] [G loss: 0.446630] [info loss: 1.496093]\n",
            "[Epoch 29/200] [Batch 194/938] [D loss: 0.197876] [G loss: 0.435758] [info loss: 1.482401]\n",
            "[Epoch 29/200] [Batch 195/938] [D loss: 0.226264] [G loss: 0.327258] [info loss: 1.476969]\n",
            "[Epoch 29/200] [Batch 196/938] [D loss: 0.155768] [G loss: 0.265466] [info loss: 1.471946]\n",
            "[Epoch 29/200] [Batch 197/938] [D loss: 0.233732] [G loss: 0.438263] [info loss: 1.470340]\n",
            "[Epoch 29/200] [Batch 198/938] [D loss: 0.228000] [G loss: 0.596564] [info loss: 1.493007]\n",
            "[Epoch 29/200] [Batch 199/938] [D loss: 0.138553] [G loss: 0.422061] [info loss: 1.473256]\n",
            "[Epoch 29/200] [Batch 200/938] [D loss: 0.163223] [G loss: 0.506249] [info loss: 1.473822]\n",
            "[Epoch 29/200] [Batch 201/938] [D loss: 0.150580] [G loss: 0.684682] [info loss: 1.488258]\n",
            "[Epoch 29/200] [Batch 202/938] [D loss: 0.333781] [G loss: 0.213728] [info loss: 1.485964]\n",
            "[Epoch 29/200] [Batch 203/938] [D loss: 0.173512] [G loss: 0.270281] [info loss: 1.486277]\n",
            "[Epoch 29/200] [Batch 204/938] [D loss: 0.285437] [G loss: 0.269913] [info loss: 1.495615]\n",
            "[Epoch 29/200] [Batch 205/938] [D loss: 0.262878] [G loss: 0.148671] [info loss: 1.490387]\n",
            "[Epoch 29/200] [Batch 206/938] [D loss: 0.179216] [G loss: 0.261038] [info loss: 1.472156]\n",
            "[Epoch 29/200] [Batch 207/938] [D loss: 0.238969] [G loss: 0.297383] [info loss: 1.482023]\n",
            "[Epoch 29/200] [Batch 208/938] [D loss: 0.260901] [G loss: 0.290268] [info loss: 1.485742]\n",
            "[Epoch 29/200] [Batch 209/938] [D loss: 0.247397] [G loss: 0.381493] [info loss: 1.485846]\n",
            "[Epoch 29/200] [Batch 210/938] [D loss: 0.223064] [G loss: 0.305825] [info loss: 1.474479]\n",
            "[Epoch 29/200] [Batch 211/938] [D loss: 0.212269] [G loss: 0.315673] [info loss: 1.497890]\n",
            "[Epoch 29/200] [Batch 212/938] [D loss: 0.104673] [G loss: 0.331918] [info loss: 1.498576]\n",
            "[Epoch 29/200] [Batch 213/938] [D loss: 0.099648] [G loss: 0.273746] [info loss: 1.491299]\n",
            "[Epoch 29/200] [Batch 214/938] [D loss: 0.188590] [G loss: 0.358148] [info loss: 1.471090]\n",
            "[Epoch 29/200] [Batch 215/938] [D loss: 0.153980] [G loss: 0.381358] [info loss: 1.481309]\n",
            "[Epoch 29/200] [Batch 216/938] [D loss: 0.220948] [G loss: 0.459295] [info loss: 1.489288]\n",
            "[Epoch 29/200] [Batch 217/938] [D loss: 0.126851] [G loss: 0.353171] [info loss: 1.470157]\n",
            "[Epoch 29/200] [Batch 218/938] [D loss: 0.200564] [G loss: 0.206045] [info loss: 1.470032]\n",
            "[Epoch 29/200] [Batch 219/938] [D loss: 0.274203] [G loss: 0.293878] [info loss: 1.488091]\n",
            "[Epoch 29/200] [Batch 220/938] [D loss: 0.128736] [G loss: 0.333659] [info loss: 1.481902]\n",
            "[Epoch 29/200] [Batch 221/938] [D loss: 0.226324] [G loss: 0.538301] [info loss: 1.475248]\n",
            "[Epoch 29/200] [Batch 222/938] [D loss: 0.204257] [G loss: 0.270747] [info loss: 1.471407]\n",
            "[Epoch 29/200] [Batch 223/938] [D loss: 0.272748] [G loss: 0.436101] [info loss: 1.477429]\n",
            "[Epoch 29/200] [Batch 224/938] [D loss: 0.241783] [G loss: 0.230048] [info loss: 1.491698]\n",
            "[Epoch 29/200] [Batch 225/938] [D loss: 0.154255] [G loss: 0.359305] [info loss: 1.474136]\n",
            "[Epoch 29/200] [Batch 226/938] [D loss: 0.175578] [G loss: 0.299441] [info loss: 1.470017]\n",
            "[Epoch 29/200] [Batch 227/938] [D loss: 0.195802] [G loss: 0.481683] [info loss: 1.473736]\n",
            "[Epoch 29/200] [Batch 228/938] [D loss: 0.243860] [G loss: 0.708243] [info loss: 1.473337]\n",
            "[Epoch 29/200] [Batch 229/938] [D loss: 0.267210] [G loss: 0.502283] [info loss: 1.491651]\n",
            "[Epoch 29/200] [Batch 230/938] [D loss: 0.183096] [G loss: 0.241874] [info loss: 1.490744]\n",
            "[Epoch 29/200] [Batch 231/938] [D loss: 0.171602] [G loss: 0.238598] [info loss: 1.470315]\n",
            "[Epoch 29/200] [Batch 232/938] [D loss: 0.317753] [G loss: 0.152011] [info loss: 1.469670]\n",
            "[Epoch 29/200] [Batch 233/938] [D loss: 0.184736] [G loss: 0.260967] [info loss: 1.488234]\n",
            "[Epoch 29/200] [Batch 234/938] [D loss: 0.194513] [G loss: 0.330299] [info loss: 1.472771]\n",
            "[Epoch 29/200] [Batch 235/938] [D loss: 0.187401] [G loss: 0.352514] [info loss: 1.473367]\n",
            "[Epoch 29/200] [Batch 236/938] [D loss: 0.251756] [G loss: 0.354589] [info loss: 1.485053]\n",
            "[Epoch 29/200] [Batch 237/938] [D loss: 0.341894] [G loss: 0.475019] [info loss: 1.475393]\n",
            "[Epoch 29/200] [Batch 238/938] [D loss: 0.194873] [G loss: 0.446988] [info loss: 1.479954]\n",
            "[Epoch 29/200] [Batch 239/938] [D loss: 0.220614] [G loss: 0.244004] [info loss: 1.475922]\n",
            "[Epoch 29/200] [Batch 240/938] [D loss: 0.322648] [G loss: 0.439269] [info loss: 1.487626]\n",
            "[Epoch 29/200] [Batch 241/938] [D loss: 0.228753] [G loss: 0.429137] [info loss: 1.477516]\n",
            "[Epoch 29/200] [Batch 242/938] [D loss: 0.218039] [G loss: 0.221025] [info loss: 1.494714]\n",
            "[Epoch 29/200] [Batch 243/938] [D loss: 0.262901] [G loss: 0.453340] [info loss: 1.468192]\n",
            "[Epoch 29/200] [Batch 244/938] [D loss: 0.166466] [G loss: 0.297202] [info loss: 1.475805]\n",
            "[Epoch 29/200] [Batch 245/938] [D loss: 0.214295] [G loss: 0.052700] [info loss: 1.477724]\n",
            "[Epoch 29/200] [Batch 246/938] [D loss: 0.291616] [G loss: 0.171561] [info loss: 1.489919]\n",
            "[Epoch 29/200] [Batch 247/938] [D loss: 0.151200] [G loss: 0.267088] [info loss: 1.471393]\n",
            "[Epoch 29/200] [Batch 248/938] [D loss: 0.058016] [G loss: 0.171891] [info loss: 1.490889]\n",
            "[Epoch 29/200] [Batch 249/938] [D loss: 0.193624] [G loss: 0.335160] [info loss: 1.485656]\n",
            "[Epoch 29/200] [Batch 250/938] [D loss: 0.165280] [G loss: 0.162231] [info loss: 1.472485]\n",
            "[Epoch 29/200] [Batch 251/938] [D loss: 0.365560] [G loss: 0.288078] [info loss: 1.477202]\n",
            "[Epoch 29/200] [Batch 252/938] [D loss: 0.207701] [G loss: 0.216076] [info loss: 1.470453]\n",
            "[Epoch 29/200] [Batch 253/938] [D loss: 0.256451] [G loss: 0.369710] [info loss: 1.483017]\n",
            "[Epoch 29/200] [Batch 254/938] [D loss: 0.177821] [G loss: 0.209636] [info loss: 1.487531]\n",
            "[Epoch 29/200] [Batch 255/938] [D loss: 0.307159] [G loss: 0.114590] [info loss: 1.485185]\n",
            "[Epoch 29/200] [Batch 256/938] [D loss: 0.176951] [G loss: 0.203292] [info loss: 1.473680]\n",
            "[Epoch 29/200] [Batch 257/938] [D loss: 0.200991] [G loss: 0.257975] [info loss: 1.498040]\n",
            "[Epoch 29/200] [Batch 258/938] [D loss: 0.224857] [G loss: 0.283368] [info loss: 1.488674]\n",
            "[Epoch 29/200] [Batch 259/938] [D loss: 0.185589] [G loss: 0.251060] [info loss: 1.478557]\n",
            "[Epoch 29/200] [Batch 260/938] [D loss: 0.310795] [G loss: 0.157495] [info loss: 1.474619]\n",
            "[Epoch 29/200] [Batch 261/938] [D loss: 0.216106] [G loss: 0.153615] [info loss: 1.470370]\n",
            "[Epoch 29/200] [Batch 262/938] [D loss: 0.272328] [G loss: 0.306684] [info loss: 1.502108]\n",
            "[Epoch 29/200] [Batch 263/938] [D loss: 0.188759] [G loss: 0.317222] [info loss: 1.492291]\n",
            "[Epoch 29/200] [Batch 264/938] [D loss: 0.183159] [G loss: 0.178315] [info loss: 1.485895]\n",
            "[Epoch 29/200] [Batch 265/938] [D loss: 0.326059] [G loss: 0.445400] [info loss: 1.471478]\n",
            "[Epoch 29/200] [Batch 266/938] [D loss: 0.149108] [G loss: 0.202469] [info loss: 1.482238]\n",
            "[Epoch 29/200] [Batch 267/938] [D loss: 0.251956] [G loss: 0.164945] [info loss: 1.469673]\n",
            "[Epoch 29/200] [Batch 268/938] [D loss: 0.202166] [G loss: 0.410324] [info loss: 1.488170]\n",
            "[Epoch 29/200] [Batch 269/938] [D loss: 0.238702] [G loss: 0.290977] [info loss: 1.482446]\n",
            "[Epoch 29/200] [Batch 270/938] [D loss: 0.214884] [G loss: 0.279411] [info loss: 1.472732]\n",
            "[Epoch 29/200] [Batch 271/938] [D loss: 0.165903] [G loss: 0.358169] [info loss: 1.475569]\n",
            "[Epoch 29/200] [Batch 272/938] [D loss: 0.444282] [G loss: 0.234567] [info loss: 1.471737]\n",
            "[Epoch 29/200] [Batch 273/938] [D loss: 0.271250] [G loss: 0.371593] [info loss: 1.487774]\n",
            "[Epoch 29/200] [Batch 274/938] [D loss: 0.141621] [G loss: 0.234089] [info loss: 1.493688]\n",
            "[Epoch 29/200] [Batch 275/938] [D loss: 0.170893] [G loss: 0.146215] [info loss: 1.472528]\n",
            "[Epoch 29/200] [Batch 276/938] [D loss: 0.240307] [G loss: 0.210353] [info loss: 1.472159]\n",
            "[Epoch 29/200] [Batch 277/938] [D loss: 0.204486] [G loss: 0.270072] [info loss: 1.487915]\n",
            "[Epoch 29/200] [Batch 278/938] [D loss: 0.259576] [G loss: 0.394978] [info loss: 1.481105]\n",
            "[Epoch 29/200] [Batch 279/938] [D loss: 0.152745] [G loss: 0.358205] [info loss: 1.485023]\n",
            "[Epoch 29/200] [Batch 280/938] [D loss: 0.197408] [G loss: 0.505050] [info loss: 1.481116]\n",
            "[Epoch 29/200] [Batch 281/938] [D loss: 0.227371] [G loss: 0.284049] [info loss: 1.469390]\n",
            "[Epoch 29/200] [Batch 282/938] [D loss: 0.249079] [G loss: 0.153921] [info loss: 1.472677]\n",
            "[Epoch 29/200] [Batch 283/938] [D loss: 0.162937] [G loss: 0.367876] [info loss: 1.475254]\n",
            "[Epoch 29/200] [Batch 284/938] [D loss: 0.189003] [G loss: 0.209972] [info loss: 1.471939]\n",
            "[Epoch 29/200] [Batch 285/938] [D loss: 0.300260] [G loss: 0.483737] [info loss: 1.474511]\n",
            "[Epoch 29/200] [Batch 286/938] [D loss: 0.192072] [G loss: 0.530075] [info loss: 1.469564]\n",
            "[Epoch 29/200] [Batch 287/938] [D loss: 0.208348] [G loss: 0.434416] [info loss: 1.486649]\n",
            "[Epoch 29/200] [Batch 288/938] [D loss: 0.159437] [G loss: 0.274683] [info loss: 1.469760]\n",
            "[Epoch 29/200] [Batch 289/938] [D loss: 0.167688] [G loss: 0.432748] [info loss: 1.479882]\n",
            "[Epoch 29/200] [Batch 290/938] [D loss: 0.140263] [G loss: 0.182847] [info loss: 1.473372]\n",
            "[Epoch 29/200] [Batch 291/938] [D loss: 0.179182] [G loss: 0.316650] [info loss: 1.476751]\n",
            "[Epoch 29/200] [Batch 292/938] [D loss: 0.228534] [G loss: 0.338923] [info loss: 1.471160]\n",
            "[Epoch 29/200] [Batch 293/938] [D loss: 0.206934] [G loss: 0.363467] [info loss: 1.475375]\n",
            "[Epoch 29/200] [Batch 294/938] [D loss: 0.294025] [G loss: 0.638028] [info loss: 1.469476]\n",
            "[Epoch 29/200] [Batch 295/938] [D loss: 0.205306] [G loss: 0.196008] [info loss: 1.480290]\n",
            "[Epoch 29/200] [Batch 296/938] [D loss: 0.200192] [G loss: 0.367112] [info loss: 1.471708]\n",
            "[Epoch 29/200] [Batch 297/938] [D loss: 0.251419] [G loss: 0.303566] [info loss: 1.502557]\n",
            "[Epoch 29/200] [Batch 298/938] [D loss: 0.203962] [G loss: 0.189943] [info loss: 1.470821]\n",
            "[Epoch 29/200] [Batch 299/938] [D loss: 0.206558] [G loss: 0.332250] [info loss: 1.478573]\n",
            "[Epoch 29/200] [Batch 300/938] [D loss: 0.220781] [G loss: 0.536788] [info loss: 1.474968]\n",
            "[Epoch 29/200] [Batch 301/938] [D loss: 0.248839] [G loss: 0.418194] [info loss: 1.491609]\n",
            "[Epoch 29/200] [Batch 302/938] [D loss: 0.247552] [G loss: 0.442935] [info loss: 1.471848]\n",
            "[Epoch 29/200] [Batch 303/938] [D loss: 0.166131] [G loss: 0.296381] [info loss: 1.488240]\n",
            "[Epoch 29/200] [Batch 304/938] [D loss: 0.216341] [G loss: 0.287090] [info loss: 1.500982]\n",
            "[Epoch 29/200] [Batch 305/938] [D loss: 0.212580] [G loss: 0.366103] [info loss: 1.472677]\n",
            "[Epoch 29/200] [Batch 306/938] [D loss: 0.142791] [G loss: 0.370982] [info loss: 1.494295]\n",
            "[Epoch 29/200] [Batch 307/938] [D loss: 0.217816] [G loss: 0.292133] [info loss: 1.486089]\n",
            "[Epoch 29/200] [Batch 308/938] [D loss: 0.146475] [G loss: 0.177771] [info loss: 1.473816]\n",
            "[Epoch 29/200] [Batch 309/938] [D loss: 0.205445] [G loss: 0.282910] [info loss: 1.473645]\n",
            "[Epoch 29/200] [Batch 310/938] [D loss: 0.254441] [G loss: 0.533424] [info loss: 1.504655]\n",
            "[Epoch 29/200] [Batch 311/938] [D loss: 0.139449] [G loss: 0.357857] [info loss: 1.470912]\n",
            "[Epoch 29/200] [Batch 312/938] [D loss: 0.214128] [G loss: 0.529584] [info loss: 1.471642]\n",
            "[Epoch 29/200] [Batch 313/938] [D loss: 0.245672] [G loss: 0.284745] [info loss: 1.499390]\n",
            "[Epoch 29/200] [Batch 314/938] [D loss: 0.297022] [G loss: 0.260496] [info loss: 1.476734]\n",
            "[Epoch 29/200] [Batch 315/938] [D loss: 0.228771] [G loss: 0.343024] [info loss: 1.481860]\n",
            "[Epoch 29/200] [Batch 316/938] [D loss: 0.269416] [G loss: 0.400827] [info loss: 1.475855]\n",
            "[Epoch 29/200] [Batch 317/938] [D loss: 0.264578] [G loss: 0.533794] [info loss: 1.470894]\n",
            "[Epoch 29/200] [Batch 318/938] [D loss: 0.163608] [G loss: 0.393375] [info loss: 1.477951]\n",
            "[Epoch 29/200] [Batch 319/938] [D loss: 0.149822] [G loss: 0.378828] [info loss: 1.502390]\n",
            "[Epoch 29/200] [Batch 320/938] [D loss: 0.179183] [G loss: 0.132355] [info loss: 1.526211]\n",
            "[Epoch 29/200] [Batch 321/938] [D loss: 0.262656] [G loss: 0.350267] [info loss: 1.503713]\n",
            "[Epoch 29/200] [Batch 322/938] [D loss: 0.238782] [G loss: 0.518459] [info loss: 1.470088]\n",
            "[Epoch 29/200] [Batch 323/938] [D loss: 0.196476] [G loss: 0.408478] [info loss: 1.471466]\n",
            "[Epoch 29/200] [Batch 324/938] [D loss: 0.120822] [G loss: 0.286012] [info loss: 1.472944]\n",
            "[Epoch 29/200] [Batch 325/938] [D loss: 0.216545] [G loss: 0.315985] [info loss: 1.484432]\n",
            "[Epoch 29/200] [Batch 326/938] [D loss: 0.180038] [G loss: 0.345982] [info loss: 1.469998]\n",
            "[Epoch 29/200] [Batch 327/938] [D loss: 0.287219] [G loss: 0.170978] [info loss: 1.472771]\n",
            "[Epoch 29/200] [Batch 328/938] [D loss: 0.163001] [G loss: 0.361275] [info loss: 1.478139]\n",
            "[Epoch 29/200] [Batch 329/938] [D loss: 0.202916] [G loss: 0.368965] [info loss: 1.485450]\n",
            "[Epoch 29/200] [Batch 330/938] [D loss: 0.140505] [G loss: 0.444965] [info loss: 1.468973]\n",
            "[Epoch 29/200] [Batch 331/938] [D loss: 0.189599] [G loss: 0.304763] [info loss: 1.471943]\n",
            "[Epoch 29/200] [Batch 332/938] [D loss: 0.347660] [G loss: 0.336236] [info loss: 1.476309]\n",
            "[Epoch 29/200] [Batch 333/938] [D loss: 0.277669] [G loss: 0.313423] [info loss: 1.488573]\n",
            "[Epoch 29/200] [Batch 334/938] [D loss: 0.153952] [G loss: 0.411436] [info loss: 1.475232]\n",
            "[Epoch 29/200] [Batch 335/938] [D loss: 0.212069] [G loss: 0.462592] [info loss: 1.470147]\n",
            "[Epoch 29/200] [Batch 336/938] [D loss: 0.206329] [G loss: 0.339906] [info loss: 1.477898]\n",
            "[Epoch 29/200] [Batch 337/938] [D loss: 0.225039] [G loss: 0.338016] [info loss: 1.481236]\n",
            "[Epoch 29/200] [Batch 338/938] [D loss: 0.178928] [G loss: 0.273872] [info loss: 1.481586]\n",
            "[Epoch 29/200] [Batch 339/938] [D loss: 0.242006] [G loss: 0.214192] [info loss: 1.469063]\n",
            "[Epoch 29/200] [Batch 340/938] [D loss: 0.176076] [G loss: 0.195794] [info loss: 1.477184]\n",
            "[Epoch 29/200] [Batch 341/938] [D loss: 0.215099] [G loss: 0.357756] [info loss: 1.473992]\n",
            "[Epoch 29/200] [Batch 342/938] [D loss: 0.136197] [G loss: 0.185411] [info loss: 1.472771]\n",
            "[Epoch 29/200] [Batch 343/938] [D loss: 0.256462] [G loss: 0.122442] [info loss: 1.496334]\n",
            "[Epoch 29/200] [Batch 344/938] [D loss: 0.200660] [G loss: 0.374033] [info loss: 1.495673]\n",
            "[Epoch 29/200] [Batch 345/938] [D loss: 0.190301] [G loss: 0.364575] [info loss: 1.471157]\n",
            "[Epoch 29/200] [Batch 346/938] [D loss: 0.229280] [G loss: 0.353286] [info loss: 1.471770]\n",
            "[Epoch 29/200] [Batch 347/938] [D loss: 0.239226] [G loss: 0.392360] [info loss: 1.471351]\n",
            "[Epoch 29/200] [Batch 348/938] [D loss: 0.220966] [G loss: 0.374599] [info loss: 1.487223]\n",
            "[Epoch 29/200] [Batch 349/938] [D loss: 0.281509] [G loss: 0.191332] [info loss: 1.471719]\n",
            "[Epoch 29/200] [Batch 350/938] [D loss: 0.216555] [G loss: 0.267920] [info loss: 1.498988]\n",
            "[Epoch 29/200] [Batch 351/938] [D loss: 0.226403] [G loss: 0.356610] [info loss: 1.478272]\n",
            "[Epoch 29/200] [Batch 352/938] [D loss: 0.289633] [G loss: 0.423602] [info loss: 1.474315]\n",
            "[Epoch 29/200] [Batch 353/938] [D loss: 0.251322] [G loss: 0.265198] [info loss: 1.478502]\n",
            "[Epoch 29/200] [Batch 354/938] [D loss: 0.202214] [G loss: 0.234552] [info loss: 1.493743]\n",
            "[Epoch 29/200] [Batch 355/938] [D loss: 0.227606] [G loss: 0.311457] [info loss: 1.484245]\n",
            "[Epoch 29/200] [Batch 356/938] [D loss: 0.169629] [G loss: 0.210669] [info loss: 1.475683]\n",
            "[Epoch 29/200] [Batch 357/938] [D loss: 0.194133] [G loss: 0.243693] [info loss: 1.471185]\n",
            "[Epoch 29/200] [Batch 358/938] [D loss: 0.136917] [G loss: 0.246027] [info loss: 1.485861]\n",
            "[Epoch 29/200] [Batch 359/938] [D loss: 0.188586] [G loss: 0.406327] [info loss: 1.488553]\n",
            "[Epoch 29/200] [Batch 360/938] [D loss: 0.217194] [G loss: 0.360345] [info loss: 1.470481]\n",
            "[Epoch 29/200] [Batch 361/938] [D loss: 0.293906] [G loss: 0.504016] [info loss: 1.485104]\n",
            "[Epoch 29/200] [Batch 362/938] [D loss: 0.159538] [G loss: 0.679993] [info loss: 1.470823]\n",
            "[Epoch 29/200] [Batch 363/938] [D loss: 0.247934] [G loss: 0.369580] [info loss: 1.471589]\n",
            "[Epoch 29/200] [Batch 364/938] [D loss: 0.204876] [G loss: 0.242490] [info loss: 1.475771]\n",
            "[Epoch 29/200] [Batch 365/938] [D loss: 0.174520] [G loss: 0.144449] [info loss: 1.484287]\n",
            "[Epoch 29/200] [Batch 366/938] [D loss: 0.175992] [G loss: 0.484378] [info loss: 1.470865]\n",
            "[Epoch 29/200] [Batch 367/938] [D loss: 0.147648] [G loss: 0.246871] [info loss: 1.469266]\n",
            "[Epoch 29/200] [Batch 368/938] [D loss: 0.179094] [G loss: 0.382103] [info loss: 1.471594]\n",
            "[Epoch 29/200] [Batch 369/938] [D loss: 0.302071] [G loss: 0.357489] [info loss: 1.485445]\n",
            "[Epoch 29/200] [Batch 370/938] [D loss: 0.177519] [G loss: 0.227881] [info loss: 1.483132]\n",
            "[Epoch 29/200] [Batch 371/938] [D loss: 0.191586] [G loss: 0.125204] [info loss: 1.482645]\n",
            "[Epoch 29/200] [Batch 372/938] [D loss: 0.301304] [G loss: 0.440203] [info loss: 1.468295]\n",
            "[Epoch 29/200] [Batch 373/938] [D loss: 0.277472] [G loss: 0.528132] [info loss: 1.491759]\n",
            "[Epoch 29/200] [Batch 374/938] [D loss: 0.230359] [G loss: 0.409914] [info loss: 1.486795]\n",
            "[Epoch 29/200] [Batch 375/938] [D loss: 0.210964] [G loss: 0.202880] [info loss: 1.472871]\n",
            "[Epoch 29/200] [Batch 376/938] [D loss: 0.165189] [G loss: 0.434133] [info loss: 1.476385]\n",
            "[Epoch 29/200] [Batch 377/938] [D loss: 0.204072] [G loss: 0.380221] [info loss: 1.483691]\n",
            "[Epoch 29/200] [Batch 378/938] [D loss: 0.196223] [G loss: 0.370188] [info loss: 1.471526]\n",
            "[Epoch 29/200] [Batch 379/938] [D loss: 0.278080] [G loss: 0.257723] [info loss: 1.472080]\n",
            "[Epoch 29/200] [Batch 380/938] [D loss: 0.202967] [G loss: 0.248139] [info loss: 1.479276]\n",
            "[Epoch 29/200] [Batch 381/938] [D loss: 0.253848] [G loss: 0.134954] [info loss: 1.470744]\n",
            "[Epoch 29/200] [Batch 382/938] [D loss: 0.234180] [G loss: 0.297702] [info loss: 1.497291]\n",
            "[Epoch 29/200] [Batch 383/938] [D loss: 0.174420] [G loss: 0.403997] [info loss: 1.488656]\n",
            "[Epoch 29/200] [Batch 384/938] [D loss: 0.298501] [G loss: 0.238838] [info loss: 1.471369]\n",
            "[Epoch 29/200] [Batch 385/938] [D loss: 0.184825] [G loss: 0.158966] [info loss: 1.490010]\n",
            "[Epoch 29/200] [Batch 386/938] [D loss: 0.272079] [G loss: 0.471867] [info loss: 1.482343]\n",
            "[Epoch 29/200] [Batch 387/938] [D loss: 0.255722] [G loss: 0.605353] [info loss: 1.472701]\n",
            "[Epoch 29/200] [Batch 388/938] [D loss: 0.290707] [G loss: 0.407880] [info loss: 1.490133]\n",
            "[Epoch 29/200] [Batch 389/938] [D loss: 0.247750] [G loss: 0.142646] [info loss: 1.473220]\n",
            "[Epoch 29/200] [Batch 390/938] [D loss: 0.288615] [G loss: 0.095493] [info loss: 1.472542]\n",
            "[Epoch 29/200] [Batch 391/938] [D loss: 0.218217] [G loss: 0.239449] [info loss: 1.481495]\n",
            "[Epoch 29/200] [Batch 392/938] [D loss: 0.203958] [G loss: 0.383217] [info loss: 1.483895]\n",
            "[Epoch 29/200] [Batch 393/938] [D loss: 0.191925] [G loss: 0.210091] [info loss: 1.471582]\n",
            "[Epoch 29/200] [Batch 394/938] [D loss: 0.177716] [G loss: 0.336966] [info loss: 1.475421]\n",
            "[Epoch 29/200] [Batch 395/938] [D loss: 0.209787] [G loss: 0.348644] [info loss: 1.490897]\n",
            "[Epoch 29/200] [Batch 396/938] [D loss: 0.175436] [G loss: 0.355253] [info loss: 1.474263]\n",
            "[Epoch 29/200] [Batch 397/938] [D loss: 0.219543] [G loss: 0.586514] [info loss: 1.472107]\n",
            "[Epoch 29/200] [Batch 398/938] [D loss: 0.231690] [G loss: 0.298818] [info loss: 1.484190]\n",
            "[Epoch 29/200] [Batch 399/938] [D loss: 0.198261] [G loss: 0.192833] [info loss: 1.484373]\n",
            "[Epoch 29/200] [Batch 400/938] [D loss: 0.209587] [G loss: 0.377444] [info loss: 1.484175]\n",
            "[Epoch 29/200] [Batch 401/938] [D loss: 0.270812] [G loss: 0.230403] [info loss: 1.475156]\n",
            "[Epoch 29/200] [Batch 402/938] [D loss: 0.134114] [G loss: 0.273904] [info loss: 1.480606]\n",
            "[Epoch 29/200] [Batch 403/938] [D loss: 0.160005] [G loss: 0.137168] [info loss: 1.474958]\n",
            "[Epoch 29/200] [Batch 404/938] [D loss: 0.152325] [G loss: 0.517186] [info loss: 1.481705]\n",
            "[Epoch 29/200] [Batch 405/938] [D loss: 0.201536] [G loss: 0.299018] [info loss: 1.514825]\n",
            "[Epoch 29/200] [Batch 406/938] [D loss: 0.247451] [G loss: 0.463727] [info loss: 1.470746]\n",
            "[Epoch 29/200] [Batch 407/938] [D loss: 0.224503] [G loss: 0.249447] [info loss: 1.500320]\n",
            "[Epoch 29/200] [Batch 408/938] [D loss: 0.190452] [G loss: 0.244951] [info loss: 1.470603]\n",
            "[Epoch 29/200] [Batch 409/938] [D loss: 0.257693] [G loss: 0.492697] [info loss: 1.469140]\n",
            "[Epoch 29/200] [Batch 410/938] [D loss: 0.330391] [G loss: 0.292500] [info loss: 1.484518]\n",
            "[Epoch 29/200] [Batch 411/938] [D loss: 0.267164] [G loss: 0.528422] [info loss: 1.469064]\n",
            "[Epoch 29/200] [Batch 412/938] [D loss: 0.329354] [G loss: 0.439829] [info loss: 1.470743]\n",
            "[Epoch 29/200] [Batch 413/938] [D loss: 0.137027] [G loss: 0.283675] [info loss: 1.470672]\n",
            "[Epoch 29/200] [Batch 414/938] [D loss: 0.204438] [G loss: 0.195895] [info loss: 1.478472]\n",
            "[Epoch 29/200] [Batch 415/938] [D loss: 0.289597] [G loss: 0.515622] [info loss: 1.486026]\n",
            "[Epoch 29/200] [Batch 416/938] [D loss: 0.167343] [G loss: 0.575791] [info loss: 1.489372]\n",
            "[Epoch 29/200] [Batch 417/938] [D loss: 0.320053] [G loss: 0.213972] [info loss: 1.481974]\n",
            "[Epoch 29/200] [Batch 418/938] [D loss: 0.225461] [G loss: 0.287660] [info loss: 1.467382]\n",
            "[Epoch 29/200] [Batch 419/938] [D loss: 0.224622] [G loss: 0.690076] [info loss: 1.482056]\n",
            "[Epoch 29/200] [Batch 420/938] [D loss: 0.188690] [G loss: 0.271049] [info loss: 1.470048]\n",
            "[Epoch 29/200] [Batch 421/938] [D loss: 0.101141] [G loss: 0.258662] [info loss: 1.506393]\n",
            "[Epoch 29/200] [Batch 422/938] [D loss: 0.141883] [G loss: 0.176419] [info loss: 1.488069]\n",
            "[Epoch 29/200] [Batch 423/938] [D loss: 0.257875] [G loss: 0.390455] [info loss: 1.469751]\n",
            "[Epoch 29/200] [Batch 424/938] [D loss: 0.233754] [G loss: 0.370259] [info loss: 1.471773]\n",
            "[Epoch 29/200] [Batch 425/938] [D loss: 0.264926] [G loss: 0.238684] [info loss: 1.470335]\n",
            "[Epoch 29/200] [Batch 426/938] [D loss: 0.192813] [G loss: 0.298536] [info loss: 1.532339]\n",
            "[Epoch 29/200] [Batch 427/938] [D loss: 0.229205] [G loss: 0.175779] [info loss: 1.499335]\n",
            "[Epoch 29/200] [Batch 428/938] [D loss: 0.236225] [G loss: 0.291716] [info loss: 1.494844]\n",
            "[Epoch 29/200] [Batch 429/938] [D loss: 0.178730] [G loss: 0.293372] [info loss: 1.501646]\n",
            "[Epoch 29/200] [Batch 430/938] [D loss: 0.215064] [G loss: 0.336946] [info loss: 1.473285]\n",
            "[Epoch 29/200] [Batch 431/938] [D loss: 0.283878] [G loss: 0.278387] [info loss: 1.477415]\n",
            "[Epoch 29/200] [Batch 432/938] [D loss: 0.144257] [G loss: 0.277440] [info loss: 1.489706]\n",
            "[Epoch 29/200] [Batch 433/938] [D loss: 0.241408] [G loss: 0.237573] [info loss: 1.475798]\n",
            "[Epoch 29/200] [Batch 434/938] [D loss: 0.274236] [G loss: 0.183473] [info loss: 1.472225]\n",
            "[Epoch 29/200] [Batch 435/938] [D loss: 0.158119] [G loss: 0.301373] [info loss: 1.483988]\n",
            "[Epoch 29/200] [Batch 436/938] [D loss: 0.257575] [G loss: 0.390713] [info loss: 1.483791]\n",
            "[Epoch 29/200] [Batch 437/938] [D loss: 0.205707] [G loss: 0.372826] [info loss: 1.482667]\n",
            "[Epoch 29/200] [Batch 438/938] [D loss: 0.222400] [G loss: 0.228573] [info loss: 1.468862]\n",
            "[Epoch 29/200] [Batch 439/938] [D loss: 0.230259] [G loss: 0.451482] [info loss: 1.470263]\n",
            "[Epoch 29/200] [Batch 440/938] [D loss: 0.169388] [G loss: 0.249978] [info loss: 1.483018]\n",
            "[Epoch 29/200] [Batch 441/938] [D loss: 0.327678] [G loss: 0.173927] [info loss: 1.468515]\n",
            "[Epoch 29/200] [Batch 442/938] [D loss: 0.246850] [G loss: 0.257053] [info loss: 1.471098]\n",
            "[Epoch 29/200] [Batch 443/938] [D loss: 0.185061] [G loss: 0.209929] [info loss: 1.469411]\n",
            "[Epoch 29/200] [Batch 444/938] [D loss: 0.176134] [G loss: 0.413271] [info loss: 1.472762]\n",
            "[Epoch 29/200] [Batch 445/938] [D loss: 0.185502] [G loss: 0.270227] [info loss: 1.473372]\n",
            "[Epoch 29/200] [Batch 446/938] [D loss: 0.202794] [G loss: 0.345711] [info loss: 1.475116]\n",
            "[Epoch 29/200] [Batch 447/938] [D loss: 0.221292] [G loss: 0.227221] [info loss: 1.490991]\n",
            "[Epoch 29/200] [Batch 448/938] [D loss: 0.158951] [G loss: 0.310416] [info loss: 1.478644]\n",
            "[Epoch 29/200] [Batch 449/938] [D loss: 0.214413] [G loss: 0.290677] [info loss: 1.481144]\n",
            "[Epoch 29/200] [Batch 450/938] [D loss: 0.183130] [G loss: 0.323731] [info loss: 1.471510]\n",
            "[Epoch 29/200] [Batch 451/938] [D loss: 0.306360] [G loss: 0.157632] [info loss: 1.488041]\n",
            "[Epoch 29/200] [Batch 452/938] [D loss: 0.258429] [G loss: 0.527633] [info loss: 1.470151]\n",
            "[Epoch 29/200] [Batch 453/938] [D loss: 0.148637] [G loss: 0.234261] [info loss: 1.471342]\n",
            "[Epoch 29/200] [Batch 454/938] [D loss: 0.419812] [G loss: 0.356443] [info loss: 1.485006]\n",
            "[Epoch 29/200] [Batch 455/938] [D loss: 0.203966] [G loss: 0.269235] [info loss: 1.494808]\n",
            "[Epoch 29/200] [Batch 456/938] [D loss: 0.214023] [G loss: 0.355448] [info loss: 1.512473]\n",
            "[Epoch 29/200] [Batch 457/938] [D loss: 0.288646] [G loss: 0.511738] [info loss: 1.483183]\n",
            "[Epoch 29/200] [Batch 458/938] [D loss: 0.242070] [G loss: 0.399435] [info loss: 1.473627]\n",
            "[Epoch 29/200] [Batch 459/938] [D loss: 0.284858] [G loss: 0.500652] [info loss: 1.489344]\n",
            "[Epoch 29/200] [Batch 460/938] [D loss: 0.230040] [G loss: 0.290899] [info loss: 1.472609]\n",
            "[Epoch 29/200] [Batch 461/938] [D loss: 0.189181] [G loss: 0.283726] [info loss: 1.470948]\n",
            "[Epoch 29/200] [Batch 462/938] [D loss: 0.223483] [G loss: 0.254439] [info loss: 1.468868]\n",
            "[Epoch 29/200] [Batch 463/938] [D loss: 0.321975] [G loss: 0.410924] [info loss: 1.485405]\n",
            "[Epoch 29/200] [Batch 464/938] [D loss: 0.268317] [G loss: 0.405410] [info loss: 1.489010]\n",
            "[Epoch 29/200] [Batch 465/938] [D loss: 0.269365] [G loss: 0.243468] [info loss: 1.470890]\n",
            "[Epoch 29/200] [Batch 466/938] [D loss: 0.201809] [G loss: 0.328196] [info loss: 1.472102]\n",
            "[Epoch 29/200] [Batch 467/938] [D loss: 0.273363] [G loss: 0.609701] [info loss: 1.475639]\n",
            "[Epoch 29/200] [Batch 468/938] [D loss: 0.225316] [G loss: 0.555835] [info loss: 1.472585]\n",
            "[Epoch 29/200] [Batch 469/938] [D loss: 0.165078] [G loss: 0.283183] [info loss: 1.469081]\n",
            "[Epoch 29/200] [Batch 470/938] [D loss: 0.164658] [G loss: 0.366540] [info loss: 1.499566]\n",
            "[Epoch 29/200] [Batch 471/938] [D loss: 0.164887] [G loss: 0.337305] [info loss: 1.485973]\n",
            "[Epoch 29/200] [Batch 472/938] [D loss: 0.184537] [G loss: 0.177640] [info loss: 1.476675]\n",
            "[Epoch 29/200] [Batch 473/938] [D loss: 0.220002] [G loss: 0.269584] [info loss: 1.506457]\n",
            "[Epoch 29/200] [Batch 474/938] [D loss: 0.273460] [G loss: 0.122352] [info loss: 1.470869]\n",
            "[Epoch 29/200] [Batch 475/938] [D loss: 0.232627] [G loss: 0.290786] [info loss: 1.476890]\n",
            "[Epoch 29/200] [Batch 476/938] [D loss: 0.216186] [G loss: 0.128406] [info loss: 1.468651]\n",
            "[Epoch 29/200] [Batch 477/938] [D loss: 0.171862] [G loss: 0.393661] [info loss: 1.476163]\n",
            "[Epoch 29/200] [Batch 478/938] [D loss: 0.194979] [G loss: 0.341785] [info loss: 1.474871]\n",
            "[Epoch 29/200] [Batch 479/938] [D loss: 0.204828] [G loss: 0.164952] [info loss: 1.470716]\n",
            "[Epoch 29/200] [Batch 480/938] [D loss: 0.221613] [G loss: 0.670515] [info loss: 1.487894]\n",
            "[Epoch 29/200] [Batch 481/938] [D loss: 0.284515] [G loss: 0.556771] [info loss: 1.475483]\n",
            "[Epoch 29/200] [Batch 482/938] [D loss: 0.391266] [G loss: 0.385589] [info loss: 1.500490]\n",
            "[Epoch 29/200] [Batch 483/938] [D loss: 0.148092] [G loss: 0.146184] [info loss: 1.470988]\n",
            "[Epoch 29/200] [Batch 484/938] [D loss: 0.190888] [G loss: 0.417668] [info loss: 1.485717]\n",
            "[Epoch 29/200] [Batch 485/938] [D loss: 0.326463] [G loss: 0.293652] [info loss: 1.472258]\n",
            "[Epoch 29/200] [Batch 486/938] [D loss: 0.245364] [G loss: 0.266227] [info loss: 1.487090]\n",
            "[Epoch 29/200] [Batch 487/938] [D loss: 0.214492] [G loss: 0.157403] [info loss: 1.487282]\n",
            "[Epoch 29/200] [Batch 488/938] [D loss: 0.310457] [G loss: 0.421013] [info loss: 1.470478]\n",
            "[Epoch 29/200] [Batch 489/938] [D loss: 0.162082] [G loss: 0.224794] [info loss: 1.474524]\n",
            "[Epoch 29/200] [Batch 490/938] [D loss: 0.332861] [G loss: 0.203984] [info loss: 1.499676]\n",
            "[Epoch 29/200] [Batch 491/938] [D loss: 0.137028] [G loss: 0.152660] [info loss: 1.472279]\n",
            "[Epoch 29/200] [Batch 492/938] [D loss: 0.219250] [G loss: 0.586049] [info loss: 1.469759]\n",
            "[Epoch 29/200] [Batch 493/938] [D loss: 0.142448] [G loss: 0.408613] [info loss: 1.479407]\n",
            "[Epoch 29/200] [Batch 494/938] [D loss: 0.208508] [G loss: 0.265619] [info loss: 1.485328]\n",
            "[Epoch 29/200] [Batch 495/938] [D loss: 0.230651] [G loss: 0.335366] [info loss: 1.473111]\n",
            "[Epoch 29/200] [Batch 496/938] [D loss: 0.173398] [G loss: 0.308841] [info loss: 1.495601]\n",
            "[Epoch 29/200] [Batch 497/938] [D loss: 0.278249] [G loss: 0.417415] [info loss: 1.477678]\n",
            "[Epoch 29/200] [Batch 498/938] [D loss: 0.166014] [G loss: 0.419972] [info loss: 1.480030]\n",
            "[Epoch 29/200] [Batch 499/938] [D loss: 0.162373] [G loss: 0.150959] [info loss: 1.473235]\n",
            "[Epoch 29/200] [Batch 500/938] [D loss: 0.168528] [G loss: 0.159541] [info loss: 1.483842]\n",
            "[Epoch 29/200] [Batch 501/938] [D loss: 0.346834] [G loss: 0.406321] [info loss: 1.470589]\n",
            "[Epoch 29/200] [Batch 502/938] [D loss: 0.089234] [G loss: 0.399002] [info loss: 1.469850]\n",
            "[Epoch 29/200] [Batch 503/938] [D loss: 0.207338] [G loss: 0.368397] [info loss: 1.494017]\n",
            "[Epoch 29/200] [Batch 504/938] [D loss: 0.209722] [G loss: 0.328165] [info loss: 1.470322]\n",
            "[Epoch 29/200] [Batch 505/938] [D loss: 0.215562] [G loss: 0.550179] [info loss: 1.472865]\n",
            "[Epoch 29/200] [Batch 506/938] [D loss: 0.230626] [G loss: 0.319289] [info loss: 1.475060]\n",
            "[Epoch 29/200] [Batch 507/938] [D loss: 0.153847] [G loss: 0.524540] [info loss: 1.475885]\n",
            "[Epoch 29/200] [Batch 508/938] [D loss: 0.237816] [G loss: 0.219128] [info loss: 1.508741]\n",
            "[Epoch 29/200] [Batch 509/938] [D loss: 0.258825] [G loss: 0.153546] [info loss: 1.472713]\n",
            "[Epoch 29/200] [Batch 510/938] [D loss: 0.202399] [G loss: 0.408251] [info loss: 1.485140]\n",
            "[Epoch 29/200] [Batch 511/938] [D loss: 0.230030] [G loss: 0.431911] [info loss: 1.473918]\n",
            "[Epoch 29/200] [Batch 512/938] [D loss: 0.324202] [G loss: 0.347320] [info loss: 1.477390]\n",
            "[Epoch 29/200] [Batch 513/938] [D loss: 0.212008] [G loss: 0.593535] [info loss: 1.468349]\n",
            "[Epoch 29/200] [Batch 514/938] [D loss: 0.178738] [G loss: 0.380012] [info loss: 1.471110]\n",
            "[Epoch 29/200] [Batch 515/938] [D loss: 0.221356] [G loss: 0.383712] [info loss: 1.469881]\n",
            "[Epoch 29/200] [Batch 516/938] [D loss: 0.203853] [G loss: 0.134033] [info loss: 1.471717]\n",
            "[Epoch 29/200] [Batch 517/938] [D loss: 0.205664] [G loss: 0.560704] [info loss: 1.490146]\n",
            "[Epoch 29/200] [Batch 518/938] [D loss: 0.233047] [G loss: 0.565273] [info loss: 1.495424]\n",
            "[Epoch 29/200] [Batch 519/938] [D loss: 0.227610] [G loss: 0.389963] [info loss: 1.473703]\n",
            "[Epoch 29/200] [Batch 520/938] [D loss: 0.296052] [G loss: 0.384569] [info loss: 1.480692]\n",
            "[Epoch 29/200] [Batch 521/938] [D loss: 0.281078] [G loss: 0.309366] [info loss: 1.469753]\n",
            "[Epoch 29/200] [Batch 522/938] [D loss: 0.240778] [G loss: 0.411446] [info loss: 1.469805]\n",
            "[Epoch 29/200] [Batch 523/938] [D loss: 0.201440] [G loss: 0.394658] [info loss: 1.475735]\n",
            "[Epoch 29/200] [Batch 524/938] [D loss: 0.207263] [G loss: 0.322095] [info loss: 1.485458]\n",
            "[Epoch 29/200] [Batch 525/938] [D loss: 0.221652] [G loss: 0.212031] [info loss: 1.469815]\n",
            "[Epoch 29/200] [Batch 526/938] [D loss: 0.294069] [G loss: 0.495413] [info loss: 1.481003]\n",
            "[Epoch 29/200] [Batch 527/938] [D loss: 0.235982] [G loss: 0.360762] [info loss: 1.470685]\n",
            "[Epoch 29/200] [Batch 528/938] [D loss: 0.176672] [G loss: 0.176149] [info loss: 1.470419]\n",
            "[Epoch 29/200] [Batch 529/938] [D loss: 0.169105] [G loss: 0.262814] [info loss: 1.484711]\n",
            "[Epoch 29/200] [Batch 530/938] [D loss: 0.227786] [G loss: 0.545969] [info loss: 1.479614]\n",
            "[Epoch 29/200] [Batch 531/938] [D loss: 0.241863] [G loss: 0.385328] [info loss: 1.486874]\n",
            "[Epoch 29/200] [Batch 532/938] [D loss: 0.151201] [G loss: 0.478430] [info loss: 1.475167]\n",
            "[Epoch 29/200] [Batch 533/938] [D loss: 0.166804] [G loss: 0.404363] [info loss: 1.480359]\n",
            "[Epoch 29/200] [Batch 534/938] [D loss: 0.212730] [G loss: 0.275351] [info loss: 1.471266]\n",
            "[Epoch 29/200] [Batch 535/938] [D loss: 0.179604] [G loss: 0.386360] [info loss: 1.474633]\n",
            "[Epoch 29/200] [Batch 536/938] [D loss: 0.235610] [G loss: 0.428033] [info loss: 1.488153]\n",
            "[Epoch 29/200] [Batch 537/938] [D loss: 0.139141] [G loss: 0.361357] [info loss: 1.469642]\n",
            "[Epoch 29/200] [Batch 538/938] [D loss: 0.178515] [G loss: 0.201051] [info loss: 1.483294]\n",
            "[Epoch 29/200] [Batch 539/938] [D loss: 0.185569] [G loss: 0.285383] [info loss: 1.482784]\n",
            "[Epoch 29/200] [Batch 540/938] [D loss: 0.276954] [G loss: 0.226912] [info loss: 1.471994]\n",
            "[Epoch 29/200] [Batch 541/938] [D loss: 0.232961] [G loss: 0.396953] [info loss: 1.477490]\n",
            "[Epoch 29/200] [Batch 542/938] [D loss: 0.281227] [G loss: 0.495590] [info loss: 1.470632]\n",
            "[Epoch 29/200] [Batch 543/938] [D loss: 0.269431] [G loss: 0.331915] [info loss: 1.476929]\n",
            "[Epoch 29/200] [Batch 544/938] [D loss: 0.209522] [G loss: 0.186243] [info loss: 1.487886]\n",
            "[Epoch 29/200] [Batch 545/938] [D loss: 0.252181] [G loss: 0.227490] [info loss: 1.485561]\n",
            "[Epoch 29/200] [Batch 546/938] [D loss: 0.297171] [G loss: 0.242381] [info loss: 1.480916]\n",
            "[Epoch 29/200] [Batch 547/938] [D loss: 0.167251] [G loss: 0.128350] [info loss: 1.490318]\n",
            "[Epoch 29/200] [Batch 548/938] [D loss: 0.193957] [G loss: 0.289697] [info loss: 1.469474]\n",
            "[Epoch 29/200] [Batch 549/938] [D loss: 0.326043] [G loss: 0.524375] [info loss: 1.470318]\n",
            "[Epoch 29/200] [Batch 550/938] [D loss: 0.142405] [G loss: 0.402284] [info loss: 1.475403]\n",
            "[Epoch 29/200] [Batch 551/938] [D loss: 0.176028] [G loss: 0.276526] [info loss: 1.476100]\n",
            "[Epoch 29/200] [Batch 552/938] [D loss: 0.274823] [G loss: 0.295629] [info loss: 1.472101]\n",
            "[Epoch 29/200] [Batch 553/938] [D loss: 0.217770] [G loss: 0.330807] [info loss: 1.469083]\n",
            "[Epoch 29/200] [Batch 554/938] [D loss: 0.247033] [G loss: 0.398806] [info loss: 1.471045]\n",
            "[Epoch 29/200] [Batch 555/938] [D loss: 0.180747] [G loss: 0.349644] [info loss: 1.469622]\n",
            "[Epoch 29/200] [Batch 556/938] [D loss: 0.149384] [G loss: 0.267919] [info loss: 1.472429]\n",
            "[Epoch 29/200] [Batch 557/938] [D loss: 0.210583] [G loss: 0.312737] [info loss: 1.471090]\n",
            "[Epoch 29/200] [Batch 558/938] [D loss: 0.176908] [G loss: 0.431829] [info loss: 1.481560]\n",
            "[Epoch 29/200] [Batch 559/938] [D loss: 0.186628] [G loss: 0.303030] [info loss: 1.483382]\n",
            "[Epoch 29/200] [Batch 560/938] [D loss: 0.164250] [G loss: 0.442423] [info loss: 1.472795]\n",
            "[Epoch 29/200] [Batch 561/938] [D loss: 0.333604] [G loss: 0.227689] [info loss: 1.471236]\n",
            "[Epoch 29/200] [Batch 562/938] [D loss: 0.231214] [G loss: 0.223011] [info loss: 1.476127]\n",
            "[Epoch 29/200] [Batch 563/938] [D loss: 0.159263] [G loss: 0.609727] [info loss: 1.474828]\n",
            "[Epoch 29/200] [Batch 564/938] [D loss: 0.204777] [G loss: 0.355898] [info loss: 1.489544]\n",
            "[Epoch 29/200] [Batch 565/938] [D loss: 0.150090] [G loss: 0.432589] [info loss: 1.480861]\n",
            "[Epoch 29/200] [Batch 566/938] [D loss: 0.162173] [G loss: 0.411452] [info loss: 1.474839]\n",
            "[Epoch 29/200] [Batch 567/938] [D loss: 0.235467] [G loss: 0.362884] [info loss: 1.487766]\n",
            "[Epoch 29/200] [Batch 568/938] [D loss: 0.201179] [G loss: 0.707372] [info loss: 1.510435]\n",
            "[Epoch 29/200] [Batch 569/938] [D loss: 0.161961] [G loss: 0.393137] [info loss: 1.473365]\n",
            "[Epoch 29/200] [Batch 570/938] [D loss: 0.209455] [G loss: 0.221171] [info loss: 1.482858]\n",
            "[Epoch 29/200] [Batch 571/938] [D loss: 0.304844] [G loss: 0.397590] [info loss: 1.470142]\n",
            "[Epoch 29/200] [Batch 572/938] [D loss: 0.201063] [G loss: 0.419100] [info loss: 1.474442]\n",
            "[Epoch 29/200] [Batch 573/938] [D loss: 0.203788] [G loss: 0.374946] [info loss: 1.495901]\n",
            "[Epoch 29/200] [Batch 574/938] [D loss: 0.248218] [G loss: 0.297145] [info loss: 1.476612]\n",
            "[Epoch 29/200] [Batch 575/938] [D loss: 0.175296] [G loss: 0.288731] [info loss: 1.478861]\n",
            "[Epoch 29/200] [Batch 576/938] [D loss: 0.134511] [G loss: 0.218532] [info loss: 1.484575]\n",
            "[Epoch 29/200] [Batch 577/938] [D loss: 0.334910] [G loss: 0.093206] [info loss: 1.471478]\n",
            "[Epoch 29/200] [Batch 578/938] [D loss: 0.248481] [G loss: 0.256375] [info loss: 1.471829]\n",
            "[Epoch 29/200] [Batch 579/938] [D loss: 0.178564] [G loss: 0.535065] [info loss: 1.471455]\n",
            "[Epoch 29/200] [Batch 580/938] [D loss: 0.252339] [G loss: 0.523064] [info loss: 1.477508]\n",
            "[Epoch 29/200] [Batch 581/938] [D loss: 0.233587] [G loss: 0.257741] [info loss: 1.486430]\n",
            "[Epoch 29/200] [Batch 582/938] [D loss: 0.247649] [G loss: 0.243674] [info loss: 1.468984]\n",
            "[Epoch 29/200] [Batch 583/938] [D loss: 0.141067] [G loss: 0.308710] [info loss: 1.469549]\n",
            "[Epoch 29/200] [Batch 584/938] [D loss: 0.286951] [G loss: 0.233804] [info loss: 1.471840]\n",
            "[Epoch 29/200] [Batch 585/938] [D loss: 0.171127] [G loss: 0.349138] [info loss: 1.469232]\n",
            "[Epoch 29/200] [Batch 586/938] [D loss: 0.276524] [G loss: 0.343942] [info loss: 1.472547]\n",
            "[Epoch 29/200] [Batch 587/938] [D loss: 0.261213] [G loss: 0.298703] [info loss: 1.484105]\n",
            "[Epoch 29/200] [Batch 588/938] [D loss: 0.219022] [G loss: 0.363813] [info loss: 1.473773]\n",
            "[Epoch 29/200] [Batch 589/938] [D loss: 0.220611] [G loss: 0.387863] [info loss: 1.480766]\n",
            "[Epoch 29/200] [Batch 590/938] [D loss: 0.214733] [G loss: 0.363640] [info loss: 1.471593]\n",
            "[Epoch 29/200] [Batch 591/938] [D loss: 0.242513] [G loss: 0.381039] [info loss: 1.482966]\n",
            "[Epoch 29/200] [Batch 592/938] [D loss: 0.230374] [G loss: 0.373932] [info loss: 1.475221]\n",
            "[Epoch 29/200] [Batch 593/938] [D loss: 0.275077] [G loss: 0.259193] [info loss: 1.471598]\n",
            "[Epoch 29/200] [Batch 594/938] [D loss: 0.282278] [G loss: 0.236166] [info loss: 1.474377]\n",
            "[Epoch 29/200] [Batch 595/938] [D loss: 0.229620] [G loss: 0.288533] [info loss: 1.470506]\n",
            "[Epoch 29/200] [Batch 596/938] [D loss: 0.140558] [G loss: 0.622807] [info loss: 1.497882]\n",
            "[Epoch 29/200] [Batch 597/938] [D loss: 0.164011] [G loss: 0.180406] [info loss: 1.475697]\n",
            "[Epoch 29/200] [Batch 598/938] [D loss: 0.178265] [G loss: 0.363886] [info loss: 1.472503]\n",
            "[Epoch 29/200] [Batch 599/938] [D loss: 0.228856] [G loss: 0.244112] [info loss: 1.469833]\n",
            "[Epoch 29/200] [Batch 600/938] [D loss: 0.117775] [G loss: 0.430092] [info loss: 1.469317]\n",
            "[Epoch 29/200] [Batch 601/938] [D loss: 0.192887] [G loss: 0.251414] [info loss: 1.494668]\n",
            "[Epoch 29/200] [Batch 602/938] [D loss: 0.220351] [G loss: 0.246166] [info loss: 1.469490]\n",
            "[Epoch 29/200] [Batch 603/938] [D loss: 0.154684] [G loss: 0.258082] [info loss: 1.475352]\n",
            "[Epoch 29/200] [Batch 604/938] [D loss: 0.147130] [G loss: 0.406475] [info loss: 1.475214]\n",
            "[Epoch 29/200] [Batch 605/938] [D loss: 0.228599] [G loss: 0.386939] [info loss: 1.472091]\n",
            "[Epoch 29/200] [Batch 606/938] [D loss: 0.221067] [G loss: 0.416575] [info loss: 1.479574]\n",
            "[Epoch 29/200] [Batch 607/938] [D loss: 0.282360] [G loss: 0.387052] [info loss: 1.472947]\n",
            "[Epoch 29/200] [Batch 608/938] [D loss: 0.122276] [G loss: 0.482622] [info loss: 1.470475]\n",
            "[Epoch 29/200] [Batch 609/938] [D loss: 0.237016] [G loss: 0.500440] [info loss: 1.476245]\n",
            "[Epoch 29/200] [Batch 610/938] [D loss: 0.263443] [G loss: 0.165481] [info loss: 1.471165]\n",
            "[Epoch 29/200] [Batch 611/938] [D loss: 0.215498] [G loss: 0.155386] [info loss: 1.471328]\n",
            "[Epoch 29/200] [Batch 612/938] [D loss: 0.207306] [G loss: 0.148370] [info loss: 1.472876]\n",
            "[Epoch 29/200] [Batch 613/938] [D loss: 0.190640] [G loss: 0.460921] [info loss: 1.490070]\n",
            "[Epoch 29/200] [Batch 614/938] [D loss: 0.131581] [G loss: 0.486331] [info loss: 1.477718]\n",
            "[Epoch 29/200] [Batch 615/938] [D loss: 0.174422] [G loss: 0.518592] [info loss: 1.470832]\n",
            "[Epoch 29/200] [Batch 616/938] [D loss: 0.222269] [G loss: 0.148083] [info loss: 1.473225]\n",
            "[Epoch 29/200] [Batch 617/938] [D loss: 0.243747] [G loss: 0.325212] [info loss: 1.486939]\n",
            "[Epoch 29/200] [Batch 618/938] [D loss: 0.175792] [G loss: 0.322518] [info loss: 1.471432]\n",
            "[Epoch 29/200] [Batch 619/938] [D loss: 0.083121] [G loss: 0.389258] [info loss: 1.470904]\n",
            "[Epoch 29/200] [Batch 620/938] [D loss: 0.326350] [G loss: 0.425423] [info loss: 1.493801]\n",
            "[Epoch 29/200] [Batch 621/938] [D loss: 0.190601] [G loss: 0.263021] [info loss: 1.486355]\n",
            "[Epoch 29/200] [Batch 622/938] [D loss: 0.297171] [G loss: 0.399709] [info loss: 1.476969]\n",
            "[Epoch 29/200] [Batch 623/938] [D loss: 0.207250] [G loss: 0.499235] [info loss: 1.473375]\n",
            "[Epoch 29/200] [Batch 624/938] [D loss: 0.219058] [G loss: 0.315464] [info loss: 1.512424]\n",
            "[Epoch 29/200] [Batch 625/938] [D loss: 0.252563] [G loss: 0.134092] [info loss: 1.476480]\n",
            "[Epoch 29/200] [Batch 626/938] [D loss: 0.257157] [G loss: 0.234374] [info loss: 1.484743]\n",
            "[Epoch 29/200] [Batch 627/938] [D loss: 0.183673] [G loss: 0.333232] [info loss: 1.472535]\n",
            "[Epoch 29/200] [Batch 628/938] [D loss: 0.204312] [G loss: 0.440630] [info loss: 1.489932]\n",
            "[Epoch 29/200] [Batch 629/938] [D loss: 0.217126] [G loss: 0.214020] [info loss: 1.469077]\n",
            "[Epoch 29/200] [Batch 630/938] [D loss: 0.182043] [G loss: 0.282167] [info loss: 1.473932]\n",
            "[Epoch 29/200] [Batch 631/938] [D loss: 0.192836] [G loss: 0.473363] [info loss: 1.487539]\n",
            "[Epoch 29/200] [Batch 632/938] [D loss: 0.220259] [G loss: 0.356134] [info loss: 1.495418]\n",
            "[Epoch 29/200] [Batch 633/938] [D loss: 0.309641] [G loss: 0.402936] [info loss: 1.471698]\n",
            "[Epoch 29/200] [Batch 634/938] [D loss: 0.222471] [G loss: 0.362125] [info loss: 1.472238]\n",
            "[Epoch 29/200] [Batch 635/938] [D loss: 0.237915] [G loss: 0.430790] [info loss: 1.469795]\n",
            "[Epoch 29/200] [Batch 636/938] [D loss: 0.272759] [G loss: 0.286849] [info loss: 1.487005]\n",
            "[Epoch 29/200] [Batch 637/938] [D loss: 0.266549] [G loss: 0.294539] [info loss: 1.479856]\n",
            "[Epoch 29/200] [Batch 638/938] [D loss: 0.170186] [G loss: 0.331436] [info loss: 1.479113]\n",
            "[Epoch 29/200] [Batch 639/938] [D loss: 0.209549] [G loss: 0.487733] [info loss: 1.471458]\n",
            "[Epoch 29/200] [Batch 640/938] [D loss: 0.269653] [G loss: 0.247996] [info loss: 1.476909]\n",
            "[Epoch 29/200] [Batch 641/938] [D loss: 0.289589] [G loss: 0.411043] [info loss: 1.471619]\n",
            "[Epoch 29/200] [Batch 642/938] [D loss: 0.199967] [G loss: 0.563505] [info loss: 1.470141]\n",
            "[Epoch 29/200] [Batch 643/938] [D loss: 0.172813] [G loss: 0.563287] [info loss: 1.468851]\n",
            "[Epoch 29/200] [Batch 644/938] [D loss: 0.143439] [G loss: 0.283722] [info loss: 1.479881]\n",
            "[Epoch 29/200] [Batch 645/938] [D loss: 0.328399] [G loss: 0.520965] [info loss: 1.472239]\n",
            "[Epoch 29/200] [Batch 646/938] [D loss: 0.185775] [G loss: 0.423886] [info loss: 1.472173]\n",
            "[Epoch 29/200] [Batch 647/938] [D loss: 0.130683] [G loss: 0.487976] [info loss: 1.488124]\n",
            "[Epoch 29/200] [Batch 648/938] [D loss: 0.280719] [G loss: 0.453860] [info loss: 1.480259]\n",
            "[Epoch 29/200] [Batch 649/938] [D loss: 0.259663] [G loss: 0.344196] [info loss: 1.470168]\n",
            "[Epoch 29/200] [Batch 650/938] [D loss: 0.267633] [G loss: 0.254742] [info loss: 1.471635]\n",
            "[Epoch 29/200] [Batch 651/938] [D loss: 0.216156] [G loss: 0.165570] [info loss: 1.473196]\n",
            "[Epoch 29/200] [Batch 652/938] [D loss: 0.154210] [G loss: 0.309610] [info loss: 1.472016]\n",
            "[Epoch 29/200] [Batch 653/938] [D loss: 0.160024] [G loss: 0.121304] [info loss: 1.471252]\n",
            "[Epoch 29/200] [Batch 654/938] [D loss: 0.176492] [G loss: 0.299190] [info loss: 1.472650]\n",
            "[Epoch 29/200] [Batch 655/938] [D loss: 0.271196] [G loss: 0.184067] [info loss: 1.490464]\n",
            "[Epoch 29/200] [Batch 656/938] [D loss: 0.293234] [G loss: 0.283788] [info loss: 1.475868]\n",
            "[Epoch 29/200] [Batch 657/938] [D loss: 0.261444] [G loss: 0.234935] [info loss: 1.482807]\n",
            "[Epoch 29/200] [Batch 658/938] [D loss: 0.218349] [G loss: 0.493845] [info loss: 1.477395]\n",
            "[Epoch 29/200] [Batch 659/938] [D loss: 0.165644] [G loss: 0.595509] [info loss: 1.471079]\n",
            "[Epoch 29/200] [Batch 660/938] [D loss: 0.185044] [G loss: 0.585914] [info loss: 1.475260]\n",
            "[Epoch 29/200] [Batch 661/938] [D loss: 0.259137] [G loss: 0.364096] [info loss: 1.470198]\n",
            "[Epoch 29/200] [Batch 662/938] [D loss: 0.146968] [G loss: 0.442110] [info loss: 1.472451]\n",
            "[Epoch 29/200] [Batch 663/938] [D loss: 0.277705] [G loss: 0.155018] [info loss: 1.471352]\n",
            "[Epoch 29/200] [Batch 664/938] [D loss: 0.179399] [G loss: 0.103181] [info loss: 1.474088]\n",
            "[Epoch 29/200] [Batch 665/938] [D loss: 0.167390] [G loss: 0.361088] [info loss: 1.469819]\n",
            "[Epoch 29/200] [Batch 666/938] [D loss: 0.175713] [G loss: 0.185358] [info loss: 1.476739]\n",
            "[Epoch 29/200] [Batch 667/938] [D loss: 0.249451] [G loss: 0.285359] [info loss: 1.474401]\n",
            "[Epoch 29/200] [Batch 668/938] [D loss: 0.137566] [G loss: 0.377365] [info loss: 1.470459]\n",
            "[Epoch 29/200] [Batch 669/938] [D loss: 0.221984] [G loss: 0.235644] [info loss: 1.490942]\n",
            "[Epoch 29/200] [Batch 670/938] [D loss: 0.257458] [G loss: 0.411225] [info loss: 1.470656]\n",
            "[Epoch 29/200] [Batch 671/938] [D loss: 0.217972] [G loss: 0.187386] [info loss: 1.470532]\n",
            "[Epoch 29/200] [Batch 672/938] [D loss: 0.187875] [G loss: 0.298950] [info loss: 1.474695]\n",
            "[Epoch 29/200] [Batch 673/938] [D loss: 0.273449] [G loss: 0.428740] [info loss: 1.479194]\n",
            "[Epoch 29/200] [Batch 674/938] [D loss: 0.184344] [G loss: 0.375160] [info loss: 1.471439]\n",
            "[Epoch 29/200] [Batch 675/938] [D loss: 0.117674] [G loss: 0.423121] [info loss: 1.500526]\n",
            "[Epoch 29/200] [Batch 676/938] [D loss: 0.262345] [G loss: 0.283040] [info loss: 1.488098]\n",
            "[Epoch 29/200] [Batch 677/938] [D loss: 0.218808] [G loss: 0.519882] [info loss: 1.475631]\n",
            "[Epoch 29/200] [Batch 678/938] [D loss: 0.180826] [G loss: 0.334268] [info loss: 1.490610]\n",
            "[Epoch 29/200] [Batch 679/938] [D loss: 0.200412] [G loss: 0.304253] [info loss: 1.491384]\n",
            "[Epoch 29/200] [Batch 680/938] [D loss: 0.203330] [G loss: 0.417241] [info loss: 1.505879]\n",
            "[Epoch 29/200] [Batch 681/938] [D loss: 0.127486] [G loss: 0.263943] [info loss: 1.483661]\n",
            "[Epoch 29/200] [Batch 682/938] [D loss: 0.208198] [G loss: 0.202843] [info loss: 1.480330]\n",
            "[Epoch 29/200] [Batch 683/938] [D loss: 0.236489] [G loss: 0.113369] [info loss: 1.470584]\n",
            "[Epoch 29/200] [Batch 684/938] [D loss: 0.326548] [G loss: 0.228374] [info loss: 1.470019]\n",
            "[Epoch 29/200] [Batch 685/938] [D loss: 0.379520] [G loss: 0.401774] [info loss: 1.470273]\n",
            "[Epoch 29/200] [Batch 686/938] [D loss: 0.263399] [G loss: 0.452282] [info loss: 1.488598]\n",
            "[Epoch 29/200] [Batch 687/938] [D loss: 0.240085] [G loss: 0.488848] [info loss: 1.479650]\n",
            "[Epoch 29/200] [Batch 688/938] [D loss: 0.212116] [G loss: 0.224466] [info loss: 1.473112]\n",
            "[Epoch 29/200] [Batch 689/938] [D loss: 0.268262] [G loss: 0.221312] [info loss: 1.470927]\n",
            "[Epoch 29/200] [Batch 690/938] [D loss: 0.137906] [G loss: 0.376568] [info loss: 1.472359]\n",
            "[Epoch 29/200] [Batch 691/938] [D loss: 0.242501] [G loss: 0.439988] [info loss: 1.471245]\n",
            "[Epoch 29/200] [Batch 692/938] [D loss: 0.195719] [G loss: 0.248523] [info loss: 1.470744]\n",
            "[Epoch 29/200] [Batch 693/938] [D loss: 0.143424] [G loss: 0.322530] [info loss: 1.478391]\n",
            "[Epoch 29/200] [Batch 694/938] [D loss: 0.232658] [G loss: 0.195291] [info loss: 1.469093]\n",
            "[Epoch 29/200] [Batch 695/938] [D loss: 0.189805] [G loss: 0.183130] [info loss: 1.470655]\n",
            "[Epoch 29/200] [Batch 696/938] [D loss: 0.147052] [G loss: 0.312901] [info loss: 1.489981]\n",
            "[Epoch 29/200] [Batch 697/938] [D loss: 0.166430] [G loss: 0.353836] [info loss: 1.468662]\n",
            "[Epoch 29/200] [Batch 698/938] [D loss: 0.176073] [G loss: 0.552404] [info loss: 1.487264]\n",
            "[Epoch 29/200] [Batch 699/938] [D loss: 0.192077] [G loss: 0.498503] [info loss: 1.470161]\n",
            "[Epoch 29/200] [Batch 700/938] [D loss: 0.128672] [G loss: 0.340184] [info loss: 1.485394]\n",
            "[Epoch 29/200] [Batch 701/938] [D loss: 0.140597] [G loss: 0.460451] [info loss: 1.474045]\n",
            "[Epoch 29/200] [Batch 702/938] [D loss: 0.256379] [G loss: 0.385792] [info loss: 1.470170]\n",
            "[Epoch 29/200] [Batch 703/938] [D loss: 0.237618] [G loss: 0.148205] [info loss: 1.470574]\n",
            "[Epoch 29/200] [Batch 704/938] [D loss: 0.212684] [G loss: 0.228270] [info loss: 1.504952]\n",
            "[Epoch 29/200] [Batch 705/938] [D loss: 0.222282] [G loss: 0.291407] [info loss: 1.500305]\n",
            "[Epoch 29/200] [Batch 706/938] [D loss: 0.289446] [G loss: 0.439353] [info loss: 1.472348]\n",
            "[Epoch 29/200] [Batch 707/938] [D loss: 0.192627] [G loss: 0.337159] [info loss: 1.469609]\n",
            "[Epoch 29/200] [Batch 708/938] [D loss: 0.261604] [G loss: 0.574173] [info loss: 1.470480]\n",
            "[Epoch 29/200] [Batch 709/938] [D loss: 0.243928] [G loss: 0.441990] [info loss: 1.485278]\n",
            "[Epoch 29/200] [Batch 710/938] [D loss: 0.213331] [G loss: 0.301697] [info loss: 1.482978]\n",
            "[Epoch 29/200] [Batch 711/938] [D loss: 0.239907] [G loss: 0.230683] [info loss: 1.471265]\n",
            "[Epoch 29/200] [Batch 712/938] [D loss: 0.153944] [G loss: 0.273066] [info loss: 1.500720]\n",
            "[Epoch 29/200] [Batch 713/938] [D loss: 0.124552] [G loss: 0.432073] [info loss: 1.470671]\n",
            "[Epoch 29/200] [Batch 714/938] [D loss: 0.274633] [G loss: 0.256443] [info loss: 1.470028]\n",
            "[Epoch 29/200] [Batch 715/938] [D loss: 0.260928] [G loss: 0.397426] [info loss: 1.480067]\n",
            "[Epoch 29/200] [Batch 716/938] [D loss: 0.295118] [G loss: 0.297787] [info loss: 1.484475]\n",
            "[Epoch 29/200] [Batch 717/938] [D loss: 0.167710] [G loss: 0.263595] [info loss: 1.472415]\n",
            "[Epoch 29/200] [Batch 718/938] [D loss: 0.160701] [G loss: 0.389190] [info loss: 1.487205]\n",
            "[Epoch 29/200] [Batch 719/938] [D loss: 0.194489] [G loss: 0.427955] [info loss: 1.469836]\n",
            "[Epoch 29/200] [Batch 720/938] [D loss: 0.248739] [G loss: 0.328267] [info loss: 1.476231]\n",
            "[Epoch 29/200] [Batch 721/938] [D loss: 0.238225] [G loss: 0.173405] [info loss: 1.496609]\n",
            "[Epoch 29/200] [Batch 722/938] [D loss: 0.222323] [G loss: 0.586782] [info loss: 1.481275]\n",
            "[Epoch 29/200] [Batch 723/938] [D loss: 0.198687] [G loss: 0.311160] [info loss: 1.486549]\n",
            "[Epoch 29/200] [Batch 724/938] [D loss: 0.222255] [G loss: 0.299324] [info loss: 1.502438]\n",
            "[Epoch 29/200] [Batch 725/938] [D loss: 0.189100] [G loss: 0.444512] [info loss: 1.485338]\n",
            "[Epoch 29/200] [Batch 726/938] [D loss: 0.157084] [G loss: 0.157043] [info loss: 1.489598]\n",
            "[Epoch 29/200] [Batch 727/938] [D loss: 0.260741] [G loss: 0.314656] [info loss: 1.475670]\n",
            "[Epoch 29/200] [Batch 728/938] [D loss: 0.241284] [G loss: 0.449096] [info loss: 1.474246]\n",
            "[Epoch 29/200] [Batch 729/938] [D loss: 0.267687] [G loss: 0.539143] [info loss: 1.486130]\n",
            "[Epoch 29/200] [Batch 730/938] [D loss: 0.230889] [G loss: 0.249641] [info loss: 1.472548]\n",
            "[Epoch 29/200] [Batch 731/938] [D loss: 0.223498] [G loss: 0.180404] [info loss: 1.492322]\n",
            "[Epoch 29/200] [Batch 732/938] [D loss: 0.313288] [G loss: 0.329978] [info loss: 1.481944]\n",
            "[Epoch 29/200] [Batch 733/938] [D loss: 0.282340] [G loss: 0.368722] [info loss: 1.470678]\n",
            "[Epoch 29/200] [Batch 734/938] [D loss: 0.205347] [G loss: 0.422452] [info loss: 1.473785]\n",
            "[Epoch 29/200] [Batch 735/938] [D loss: 0.257929] [G loss: 0.254056] [info loss: 1.471355]\n",
            "[Epoch 29/200] [Batch 736/938] [D loss: 0.341512] [G loss: 0.424261] [info loss: 1.471903]\n",
            "[Epoch 29/200] [Batch 737/938] [D loss: 0.101609] [G loss: 0.439809] [info loss: 1.471267]\n",
            "[Epoch 29/200] [Batch 738/938] [D loss: 0.407316] [G loss: 0.368372] [info loss: 1.488758]\n",
            "[Epoch 29/200] [Batch 739/938] [D loss: 0.178210] [G loss: 0.291699] [info loss: 1.473892]\n",
            "[Epoch 29/200] [Batch 740/938] [D loss: 0.419144] [G loss: 0.581413] [info loss: 1.488350]\n",
            "[Epoch 29/200] [Batch 741/938] [D loss: 0.275457] [G loss: 0.487594] [info loss: 1.476352]\n",
            "[Epoch 29/200] [Batch 742/938] [D loss: 0.314946] [G loss: 0.149279] [info loss: 1.492114]\n",
            "[Epoch 29/200] [Batch 743/938] [D loss: 0.231837] [G loss: 0.329547] [info loss: 1.491323]\n",
            "[Epoch 29/200] [Batch 744/938] [D loss: 0.220671] [G loss: 0.599651] [info loss: 1.490443]\n",
            "[Epoch 29/200] [Batch 745/938] [D loss: 0.401230] [G loss: 0.568978] [info loss: 1.495485]\n",
            "[Epoch 29/200] [Batch 746/938] [D loss: 0.211810] [G loss: 0.424295] [info loss: 1.470901]\n",
            "[Epoch 29/200] [Batch 747/938] [D loss: 0.306045] [G loss: 0.338872] [info loss: 1.516302]\n",
            "[Epoch 29/200] [Batch 748/938] [D loss: 0.400736] [G loss: 0.120037] [info loss: 1.471134]\n",
            "[Epoch 29/200] [Batch 749/938] [D loss: 0.297041] [G loss: 0.179799] [info loss: 1.470737]\n",
            "[Epoch 29/200] [Batch 750/938] [D loss: 0.147798] [G loss: 0.200772] [info loss: 1.497982]\n",
            "[Epoch 29/200] [Batch 751/938] [D loss: 0.228295] [G loss: 0.379222] [info loss: 1.503024]\n",
            "[Epoch 29/200] [Batch 752/938] [D loss: 0.190608] [G loss: 0.163286] [info loss: 1.476669]\n",
            "[Epoch 29/200] [Batch 753/938] [D loss: 0.293952] [G loss: 0.512119] [info loss: 1.476579]\n",
            "[Epoch 29/200] [Batch 754/938] [D loss: 0.338485] [G loss: 0.472505] [info loss: 1.470199]\n",
            "[Epoch 29/200] [Batch 755/938] [D loss: 0.225420] [G loss: 0.385803] [info loss: 1.487971]\n",
            "[Epoch 29/200] [Batch 756/938] [D loss: 0.305148] [G loss: 0.243200] [info loss: 1.493340]\n",
            "[Epoch 29/200] [Batch 757/938] [D loss: 0.232445] [G loss: 0.460895] [info loss: 1.471691]\n",
            "[Epoch 29/200] [Batch 758/938] [D loss: 0.197854] [G loss: 0.238403] [info loss: 1.474360]\n",
            "[Epoch 29/200] [Batch 759/938] [D loss: 0.262524] [G loss: 0.197133] [info loss: 1.486529]\n",
            "[Epoch 29/200] [Batch 760/938] [D loss: 0.253838] [G loss: 0.288780] [info loss: 1.471849]\n",
            "[Epoch 29/200] [Batch 761/938] [D loss: 0.205796] [G loss: 0.809969] [info loss: 1.473227]\n",
            "[Epoch 29/200] [Batch 762/938] [D loss: 0.282235] [G loss: 0.565470] [info loss: 1.514130]\n",
            "[Epoch 29/200] [Batch 763/938] [D loss: 0.206543] [G loss: 0.417559] [info loss: 1.479576]\n",
            "[Epoch 29/200] [Batch 764/938] [D loss: 0.191986] [G loss: 0.388095] [info loss: 1.471271]\n",
            "[Epoch 29/200] [Batch 765/938] [D loss: 0.243103] [G loss: 0.324892] [info loss: 1.468072]\n",
            "[Epoch 29/200] [Batch 766/938] [D loss: 0.159225] [G loss: 0.379824] [info loss: 1.479396]\n",
            "[Epoch 29/200] [Batch 767/938] [D loss: 0.153465] [G loss: 0.637722] [info loss: 1.469692]\n",
            "[Epoch 29/200] [Batch 768/938] [D loss: 0.137703] [G loss: 0.177178] [info loss: 1.470855]\n",
            "[Epoch 29/200] [Batch 769/938] [D loss: 0.219995] [G loss: 0.269407] [info loss: 1.470077]\n",
            "[Epoch 29/200] [Batch 770/938] [D loss: 0.297792] [G loss: 0.306802] [info loss: 1.469626]\n",
            "[Epoch 29/200] [Batch 771/938] [D loss: 0.313407] [G loss: 0.336997] [info loss: 1.471899]\n",
            "[Epoch 29/200] [Batch 772/938] [D loss: 0.250274] [G loss: 0.253814] [info loss: 1.474724]\n",
            "[Epoch 29/200] [Batch 773/938] [D loss: 0.133093] [G loss: 0.223311] [info loss: 1.470495]\n",
            "[Epoch 29/200] [Batch 774/938] [D loss: 0.228691] [G loss: 0.344365] [info loss: 1.480155]\n",
            "[Epoch 29/200] [Batch 775/938] [D loss: 0.271744] [G loss: 0.385633] [info loss: 1.486872]\n",
            "[Epoch 29/200] [Batch 776/938] [D loss: 0.201930] [G loss: 0.311351] [info loss: 1.484459]\n",
            "[Epoch 29/200] [Batch 777/938] [D loss: 0.217512] [G loss: 0.185916] [info loss: 1.482646]\n",
            "[Epoch 29/200] [Batch 778/938] [D loss: 0.216426] [G loss: 0.396034] [info loss: 1.472316]\n",
            "[Epoch 29/200] [Batch 779/938] [D loss: 0.244014] [G loss: 0.199331] [info loss: 1.484509]\n",
            "[Epoch 29/200] [Batch 780/938] [D loss: 0.171634] [G loss: 0.296341] [info loss: 1.491477]\n",
            "[Epoch 29/200] [Batch 781/938] [D loss: 0.173984] [G loss: 0.302115] [info loss: 1.485190]\n",
            "[Epoch 29/200] [Batch 782/938] [D loss: 0.217173] [G loss: 0.267576] [info loss: 1.495841]\n",
            "[Epoch 29/200] [Batch 783/938] [D loss: 0.232050] [G loss: 0.394420] [info loss: 1.502692]\n",
            "[Epoch 29/200] [Batch 784/938] [D loss: 0.200157] [G loss: 0.228084] [info loss: 1.471661]\n",
            "[Epoch 29/200] [Batch 785/938] [D loss: 0.306599] [G loss: 0.278491] [info loss: 1.472533]\n",
            "[Epoch 29/200] [Batch 786/938] [D loss: 0.156884] [G loss: 0.195725] [info loss: 1.479804]\n",
            "[Epoch 29/200] [Batch 787/938] [D loss: 0.310385] [G loss: 0.251263] [info loss: 1.486716]\n",
            "[Epoch 29/200] [Batch 788/938] [D loss: 0.203968] [G loss: 0.423502] [info loss: 1.481244]\n",
            "[Epoch 29/200] [Batch 789/938] [D loss: 0.252946] [G loss: 0.424979] [info loss: 1.471479]\n",
            "[Epoch 29/200] [Batch 790/938] [D loss: 0.200881] [G loss: 0.301461] [info loss: 1.471916]\n",
            "[Epoch 29/200] [Batch 791/938] [D loss: 0.146340] [G loss: 0.393250] [info loss: 1.474453]\n",
            "[Epoch 29/200] [Batch 792/938] [D loss: 0.330792] [G loss: 0.386234] [info loss: 1.500643]\n",
            "[Epoch 29/200] [Batch 793/938] [D loss: 0.191967] [G loss: 0.188575] [info loss: 1.470655]\n",
            "[Epoch 29/200] [Batch 794/938] [D loss: 0.209315] [G loss: 0.235500] [info loss: 1.474990]\n",
            "[Epoch 29/200] [Batch 795/938] [D loss: 0.271903] [G loss: 0.172936] [info loss: 1.486527]\n",
            "[Epoch 29/200] [Batch 796/938] [D loss: 0.202525] [G loss: 0.341669] [info loss: 1.475032]\n",
            "[Epoch 29/200] [Batch 797/938] [D loss: 0.278932] [G loss: 0.488212] [info loss: 1.485370]\n",
            "[Epoch 29/200] [Batch 798/938] [D loss: 0.233827] [G loss: 0.291484] [info loss: 1.489490]\n",
            "[Epoch 29/200] [Batch 799/938] [D loss: 0.236697] [G loss: 0.304644] [info loss: 1.486310]\n",
            "[Epoch 29/200] [Batch 800/938] [D loss: 0.216896] [G loss: 0.231549] [info loss: 1.470144]\n",
            "[Epoch 29/200] [Batch 801/938] [D loss: 0.149236] [G loss: 0.223236] [info loss: 1.471750]\n",
            "[Epoch 29/200] [Batch 802/938] [D loss: 0.231981] [G loss: 0.337953] [info loss: 1.473424]\n",
            "[Epoch 29/200] [Batch 803/938] [D loss: 0.232688] [G loss: 0.388181] [info loss: 1.474079]\n",
            "[Epoch 29/200] [Batch 804/938] [D loss: 0.193963] [G loss: 0.452210] [info loss: 1.483121]\n",
            "[Epoch 29/200] [Batch 805/938] [D loss: 0.205648] [G loss: 0.231226] [info loss: 1.488661]\n",
            "[Epoch 29/200] [Batch 806/938] [D loss: 0.172966] [G loss: 0.159758] [info loss: 1.470567]\n",
            "[Epoch 29/200] [Batch 807/938] [D loss: 0.299557] [G loss: 0.338164] [info loss: 1.477299]\n",
            "[Epoch 29/200] [Batch 808/938] [D loss: 0.260418] [G loss: 0.255323] [info loss: 1.471916]\n",
            "[Epoch 29/200] [Batch 809/938] [D loss: 0.255709] [G loss: 0.305729] [info loss: 1.484075]\n",
            "[Epoch 29/200] [Batch 810/938] [D loss: 0.207384] [G loss: 0.414826] [info loss: 1.469764]\n",
            "[Epoch 29/200] [Batch 811/938] [D loss: 0.293037] [G loss: 0.280635] [info loss: 1.487645]\n",
            "[Epoch 29/200] [Batch 812/938] [D loss: 0.276214] [G loss: 0.427690] [info loss: 1.472664]\n",
            "[Epoch 29/200] [Batch 813/938] [D loss: 0.108863] [G loss: 0.416561] [info loss: 1.470940]\n",
            "[Epoch 29/200] [Batch 814/938] [D loss: 0.284704] [G loss: 0.216563] [info loss: 1.495167]\n",
            "[Epoch 29/200] [Batch 815/938] [D loss: 0.238344] [G loss: 0.397341] [info loss: 1.484425]\n",
            "[Epoch 29/200] [Batch 816/938] [D loss: 0.222695] [G loss: 0.369955] [info loss: 1.474999]\n",
            "[Epoch 29/200] [Batch 817/938] [D loss: 0.271483] [G loss: 0.449182] [info loss: 1.481115]\n",
            "[Epoch 29/200] [Batch 818/938] [D loss: 0.198677] [G loss: 0.447102] [info loss: 1.485205]\n",
            "[Epoch 29/200] [Batch 819/938] [D loss: 0.166198] [G loss: 0.509252] [info loss: 1.494928]\n",
            "[Epoch 29/200] [Batch 820/938] [D loss: 0.178428] [G loss: 0.388310] [info loss: 1.469422]\n",
            "[Epoch 29/200] [Batch 821/938] [D loss: 0.228052] [G loss: 0.276262] [info loss: 1.477238]\n",
            "[Epoch 29/200] [Batch 822/938] [D loss: 0.215987] [G loss: 0.313786] [info loss: 1.483439]\n",
            "[Epoch 29/200] [Batch 823/938] [D loss: 0.131671] [G loss: 0.626600] [info loss: 1.476010]\n",
            "[Epoch 29/200] [Batch 824/938] [D loss: 0.354212] [G loss: 0.550534] [info loss: 1.471148]\n",
            "[Epoch 29/200] [Batch 825/938] [D loss: 0.205587] [G loss: 0.402814] [info loss: 1.470358]\n",
            "[Epoch 29/200] [Batch 826/938] [D loss: 0.305604] [G loss: 0.395515] [info loss: 1.485364]\n",
            "[Epoch 29/200] [Batch 827/938] [D loss: 0.236318] [G loss: 0.277042] [info loss: 1.473359]\n",
            "[Epoch 29/200] [Batch 828/938] [D loss: 0.131679] [G loss: 0.428451] [info loss: 1.472974]\n",
            "[Epoch 29/200] [Batch 829/938] [D loss: 0.260372] [G loss: 0.248955] [info loss: 1.471152]\n",
            "[Epoch 29/200] [Batch 830/938] [D loss: 0.289632] [G loss: 0.292206] [info loss: 1.472364]\n",
            "[Epoch 29/200] [Batch 831/938] [D loss: 0.155571] [G loss: 0.409499] [info loss: 1.498068]\n",
            "[Epoch 29/200] [Batch 832/938] [D loss: 0.155075] [G loss: 0.582667] [info loss: 1.470928]\n",
            "[Epoch 29/200] [Batch 833/938] [D loss: 0.190355] [G loss: 0.482714] [info loss: 1.501001]\n",
            "[Epoch 29/200] [Batch 834/938] [D loss: 0.194939] [G loss: 0.124898] [info loss: 1.491596]\n",
            "[Epoch 29/200] [Batch 835/938] [D loss: 0.220177] [G loss: 0.189722] [info loss: 1.474261]\n",
            "[Epoch 29/200] [Batch 836/938] [D loss: 0.263785] [G loss: 0.268421] [info loss: 1.485907]\n",
            "[Epoch 29/200] [Batch 837/938] [D loss: 0.205862] [G loss: 0.687246] [info loss: 1.470445]\n",
            "[Epoch 29/200] [Batch 838/938] [D loss: 0.207178] [G loss: 0.393995] [info loss: 1.468359]\n",
            "[Epoch 29/200] [Batch 839/938] [D loss: 0.191157] [G loss: 0.320185] [info loss: 1.485049]\n",
            "[Epoch 29/200] [Batch 840/938] [D loss: 0.163185] [G loss: 0.193325] [info loss: 1.472032]\n",
            "[Epoch 29/200] [Batch 841/938] [D loss: 0.201150] [G loss: 0.240473] [info loss: 1.484857]\n",
            "[Epoch 29/200] [Batch 842/938] [D loss: 0.186041] [G loss: 0.085536] [info loss: 1.470287]\n",
            "[Epoch 29/200] [Batch 843/938] [D loss: 0.267351] [G loss: 0.417450] [info loss: 1.470766]\n",
            "[Epoch 29/200] [Batch 844/938] [D loss: 0.140375] [G loss: 0.611114] [info loss: 1.476683]\n",
            "[Epoch 29/200] [Batch 845/938] [D loss: 0.267612] [G loss: 0.375569] [info loss: 1.489703]\n",
            "[Epoch 29/200] [Batch 846/938] [D loss: 0.323164] [G loss: 0.487554] [info loss: 1.469044]\n",
            "[Epoch 29/200] [Batch 847/938] [D loss: 0.225875] [G loss: 0.392534] [info loss: 1.475427]\n",
            "[Epoch 29/200] [Batch 848/938] [D loss: 0.297151] [G loss: 0.285112] [info loss: 1.482332]\n",
            "[Epoch 29/200] [Batch 849/938] [D loss: 0.170751] [G loss: 0.209034] [info loss: 1.483631]\n",
            "[Epoch 29/200] [Batch 850/938] [D loss: 0.262701] [G loss: 0.307323] [info loss: 1.471629]\n",
            "[Epoch 29/200] [Batch 851/938] [D loss: 0.197379] [G loss: 0.513279] [info loss: 1.492963]\n",
            "[Epoch 29/200] [Batch 852/938] [D loss: 0.202023] [G loss: 0.395288] [info loss: 1.471899]\n",
            "[Epoch 29/200] [Batch 853/938] [D loss: 0.319690] [G loss: 0.348418] [info loss: 1.471128]\n",
            "[Epoch 29/200] [Batch 854/938] [D loss: 0.214777] [G loss: 0.219281] [info loss: 1.471043]\n",
            "[Epoch 29/200] [Batch 855/938] [D loss: 0.288497] [G loss: 0.272126] [info loss: 1.484015]\n",
            "[Epoch 29/200] [Batch 856/938] [D loss: 0.292879] [G loss: 0.293797] [info loss: 1.472114]\n",
            "[Epoch 29/200] [Batch 857/938] [D loss: 0.248750] [G loss: 0.214770] [info loss: 1.476373]\n",
            "[Epoch 29/200] [Batch 858/938] [D loss: 0.263908] [G loss: 0.548185] [info loss: 1.469599]\n",
            "[Epoch 29/200] [Batch 859/938] [D loss: 0.237178] [G loss: 0.438772] [info loss: 1.470734]\n",
            "[Epoch 29/200] [Batch 860/938] [D loss: 0.259579] [G loss: 0.378606] [info loss: 1.474604]\n",
            "[Epoch 29/200] [Batch 861/938] [D loss: 0.240380] [G loss: 0.325748] [info loss: 1.469988]\n",
            "[Epoch 29/200] [Batch 862/938] [D loss: 0.184617] [G loss: 0.360280] [info loss: 1.481982]\n",
            "[Epoch 29/200] [Batch 863/938] [D loss: 0.148437] [G loss: 0.303332] [info loss: 1.472681]\n",
            "[Epoch 29/200] [Batch 864/938] [D loss: 0.193938] [G loss: 0.520670] [info loss: 1.486392]\n",
            "[Epoch 29/200] [Batch 865/938] [D loss: 0.092057] [G loss: 0.303467] [info loss: 1.470485]\n",
            "[Epoch 29/200] [Batch 866/938] [D loss: 0.270033] [G loss: 0.237385] [info loss: 1.469935]\n",
            "[Epoch 29/200] [Batch 867/938] [D loss: 0.197444] [G loss: 0.323614] [info loss: 1.476828]\n",
            "[Epoch 29/200] [Batch 868/938] [D loss: 0.343982] [G loss: 0.348880] [info loss: 1.486839]\n",
            "[Epoch 29/200] [Batch 869/938] [D loss: 0.200316] [G loss: 0.370949] [info loss: 1.472788]\n",
            "[Epoch 29/200] [Batch 870/938] [D loss: 0.217985] [G loss: 0.143120] [info loss: 1.469054]\n",
            "[Epoch 29/200] [Batch 871/938] [D loss: 0.259108] [G loss: 0.472576] [info loss: 1.473156]\n",
            "[Epoch 29/200] [Batch 872/938] [D loss: 0.255244] [G loss: 0.393795] [info loss: 1.484429]\n",
            "[Epoch 29/200] [Batch 873/938] [D loss: 0.111613] [G loss: 0.086952] [info loss: 1.469946]\n",
            "[Epoch 29/200] [Batch 874/938] [D loss: 0.209020] [G loss: 0.339918] [info loss: 1.479255]\n",
            "[Epoch 29/200] [Batch 875/938] [D loss: 0.190873] [G loss: 0.223143] [info loss: 1.496199]\n",
            "[Epoch 29/200] [Batch 876/938] [D loss: 0.169325] [G loss: 0.295982] [info loss: 1.473354]\n",
            "[Epoch 29/200] [Batch 877/938] [D loss: 0.196361] [G loss: 0.382125] [info loss: 1.471972]\n",
            "[Epoch 29/200] [Batch 878/938] [D loss: 0.100841] [G loss: 0.533802] [info loss: 1.470997]\n",
            "[Epoch 29/200] [Batch 879/938] [D loss: 0.263261] [G loss: 0.412666] [info loss: 1.484568]\n",
            "[Epoch 29/200] [Batch 880/938] [D loss: 0.149932] [G loss: 0.349524] [info loss: 1.478628]\n",
            "[Epoch 29/200] [Batch 881/938] [D loss: 0.238086] [G loss: 0.332236] [info loss: 1.470685]\n",
            "[Epoch 29/200] [Batch 882/938] [D loss: 0.256510] [G loss: 0.406233] [info loss: 1.469111]\n",
            "[Epoch 29/200] [Batch 883/938] [D loss: 0.208109] [G loss: 0.348576] [info loss: 1.485428]\n",
            "[Epoch 29/200] [Batch 884/938] [D loss: 0.319733] [G loss: 0.474106] [info loss: 1.479209]\n",
            "[Epoch 29/200] [Batch 885/938] [D loss: 0.287622] [G loss: 0.374203] [info loss: 1.470526]\n",
            "[Epoch 29/200] [Batch 886/938] [D loss: 0.163113] [G loss: 0.309040] [info loss: 1.476824]\n",
            "[Epoch 29/200] [Batch 887/938] [D loss: 0.138465] [G loss: 0.338771] [info loss: 1.482266]\n",
            "[Epoch 29/200] [Batch 888/938] [D loss: 0.169907] [G loss: 0.281046] [info loss: 1.475117]\n",
            "[Epoch 29/200] [Batch 889/938] [D loss: 0.224837] [G loss: 0.370024] [info loss: 1.499441]\n",
            "[Epoch 29/200] [Batch 890/938] [D loss: 0.172829] [G loss: 0.406238] [info loss: 1.470400]\n",
            "[Epoch 29/200] [Batch 891/938] [D loss: 0.200875] [G loss: 0.354779] [info loss: 1.492978]\n",
            "[Epoch 29/200] [Batch 892/938] [D loss: 0.230101] [G loss: 0.515430] [info loss: 1.487119]\n",
            "[Epoch 29/200] [Batch 893/938] [D loss: 0.302874] [G loss: 0.408931] [info loss: 1.502458]\n",
            "[Epoch 29/200] [Batch 894/938] [D loss: 0.162273] [G loss: 0.443454] [info loss: 1.470937]\n",
            "[Epoch 29/200] [Batch 895/938] [D loss: 0.317204] [G loss: 0.135767] [info loss: 1.474479]\n",
            "[Epoch 29/200] [Batch 896/938] [D loss: 0.153144] [G loss: 0.587506] [info loss: 1.488060]\n",
            "[Epoch 29/200] [Batch 897/938] [D loss: 0.288830] [G loss: 0.421177] [info loss: 1.473975]\n",
            "[Epoch 29/200] [Batch 898/938] [D loss: 0.309931] [G loss: 0.663199] [info loss: 1.469770]\n",
            "[Epoch 29/200] [Batch 899/938] [D loss: 0.215119] [G loss: 0.484892] [info loss: 1.470823]\n",
            "[Epoch 29/200] [Batch 900/938] [D loss: 0.310892] [G loss: 0.270208] [info loss: 1.483595]\n",
            "[Epoch 29/200] [Batch 901/938] [D loss: 0.223826] [G loss: 0.387344] [info loss: 1.500341]\n",
            "[Epoch 29/200] [Batch 902/938] [D loss: 0.192104] [G loss: 0.400339] [info loss: 1.486372]\n",
            "[Epoch 29/200] [Batch 903/938] [D loss: 0.169298] [G loss: 0.428319] [info loss: 1.485886]\n",
            "[Epoch 29/200] [Batch 904/938] [D loss: 0.227606] [G loss: 0.358884] [info loss: 1.481123]\n",
            "[Epoch 29/200] [Batch 905/938] [D loss: 0.173405] [G loss: 0.431990] [info loss: 1.502093]\n",
            "[Epoch 29/200] [Batch 906/938] [D loss: 0.138710] [G loss: 0.316127] [info loss: 1.472580]\n",
            "[Epoch 29/200] [Batch 907/938] [D loss: 0.313353] [G loss: 0.309146] [info loss: 1.486006]\n",
            "[Epoch 29/200] [Batch 908/938] [D loss: 0.182437] [G loss: 0.225033] [info loss: 1.473039]\n",
            "[Epoch 29/200] [Batch 909/938] [D loss: 0.167367] [G loss: 0.312523] [info loss: 1.468951]\n",
            "[Epoch 29/200] [Batch 910/938] [D loss: 0.241570] [G loss: 0.415842] [info loss: 1.470140]\n",
            "[Epoch 29/200] [Batch 911/938] [D loss: 0.170876] [G loss: 0.211451] [info loss: 1.469165]\n",
            "[Epoch 29/200] [Batch 912/938] [D loss: 0.254541] [G loss: 0.460811] [info loss: 1.487104]\n",
            "[Epoch 29/200] [Batch 913/938] [D loss: 0.165545] [G loss: 0.330522] [info loss: 1.477015]\n",
            "[Epoch 29/200] [Batch 914/938] [D loss: 0.233994] [G loss: 0.366609] [info loss: 1.471777]\n",
            "[Epoch 29/200] [Batch 915/938] [D loss: 0.153485] [G loss: 0.425697] [info loss: 1.470064]\n",
            "[Epoch 29/200] [Batch 916/938] [D loss: 0.139458] [G loss: 0.269102] [info loss: 1.472075]\n",
            "[Epoch 29/200] [Batch 917/938] [D loss: 0.137445] [G loss: 0.345863] [info loss: 1.479148]\n",
            "[Epoch 29/200] [Batch 918/938] [D loss: 0.207795] [G loss: 0.303463] [info loss: 1.472701]\n",
            "[Epoch 29/200] [Batch 919/938] [D loss: 0.203490] [G loss: 0.190480] [info loss: 1.471208]\n",
            "[Epoch 29/200] [Batch 920/938] [D loss: 0.251104] [G loss: 0.185883] [info loss: 1.469310]\n",
            "[Epoch 29/200] [Batch 921/938] [D loss: 0.144237] [G loss: 0.289440] [info loss: 1.482034]\n",
            "[Epoch 29/200] [Batch 922/938] [D loss: 0.138258] [G loss: 0.634668] [info loss: 1.472974]\n",
            "[Epoch 29/200] [Batch 923/938] [D loss: 0.182685] [G loss: 0.385193] [info loss: 1.471080]\n",
            "[Epoch 29/200] [Batch 924/938] [D loss: 0.191521] [G loss: 0.408421] [info loss: 1.470757]\n",
            "[Epoch 29/200] [Batch 925/938] [D loss: 0.280634] [G loss: 0.164864] [info loss: 1.472513]\n",
            "[Epoch 29/200] [Batch 926/938] [D loss: 0.156163] [G loss: 0.244478] [info loss: 1.475509]\n",
            "[Epoch 29/200] [Batch 927/938] [D loss: 0.254717] [G loss: 0.376207] [info loss: 1.473191]\n",
            "[Epoch 29/200] [Batch 928/938] [D loss: 0.289456] [G loss: 0.213561] [info loss: 1.476824]\n",
            "[Epoch 29/200] [Batch 929/938] [D loss: 0.169568] [G loss: 0.137602] [info loss: 1.485052]\n",
            "[Epoch 29/200] [Batch 930/938] [D loss: 0.188333] [G loss: 0.166522] [info loss: 1.469413]\n",
            "[Epoch 29/200] [Batch 931/938] [D loss: 0.252263] [G loss: 0.461594] [info loss: 1.472048]\n",
            "[Epoch 29/200] [Batch 932/938] [D loss: 0.202573] [G loss: 0.296903] [info loss: 1.475520]\n",
            "[Epoch 29/200] [Batch 933/938] [D loss: 0.260068] [G loss: 0.445319] [info loss: 1.471966]\n",
            "[Epoch 29/200] [Batch 934/938] [D loss: 0.178117] [G loss: 0.288282] [info loss: 1.502108]\n",
            "[Epoch 29/200] [Batch 935/938] [D loss: 0.223231] [G loss: 0.313466] [info loss: 1.468826]\n",
            "[Epoch 29/200] [Batch 936/938] [D loss: 0.465632] [G loss: 0.683216] [info loss: 1.480389]\n",
            "[Epoch 29/200] [Batch 937/938] [D loss: 0.089399] [G loss: 0.163390] [info loss: 1.467944]\n",
            "[Epoch 30/200] [Batch 0/938] [D loss: 0.119024] [G loss: 0.107341] [info loss: 1.487145]\n",
            "[Epoch 30/200] [Batch 1/938] [D loss: 0.187265] [G loss: 0.185569] [info loss: 1.506365]\n",
            "[Epoch 30/200] [Batch 2/938] [D loss: 0.192555] [G loss: 0.242797] [info loss: 1.471092]\n",
            "[Epoch 30/200] [Batch 3/938] [D loss: 0.112101] [G loss: 0.360882] [info loss: 1.469411]\n",
            "[Epoch 30/200] [Batch 4/938] [D loss: 0.142088] [G loss: 0.338375] [info loss: 1.480488]\n",
            "[Epoch 30/200] [Batch 5/938] [D loss: 0.317949] [G loss: 0.304621] [info loss: 1.472419]\n",
            "[Epoch 30/200] [Batch 6/938] [D loss: 0.165986] [G loss: 0.374931] [info loss: 1.505872]\n",
            "[Epoch 30/200] [Batch 7/938] [D loss: 0.241421] [G loss: 0.271518] [info loss: 1.471342]\n",
            "[Epoch 30/200] [Batch 8/938] [D loss: 0.147740] [G loss: 0.300570] [info loss: 1.471556]\n",
            "[Epoch 30/200] [Batch 9/938] [D loss: 0.268631] [G loss: 0.242235] [info loss: 1.473493]\n",
            "[Epoch 30/200] [Batch 10/938] [D loss: 0.226003] [G loss: 0.354240] [info loss: 1.488456]\n",
            "[Epoch 30/200] [Batch 11/938] [D loss: 0.196454] [G loss: 0.257385] [info loss: 1.500761]\n",
            "[Epoch 30/200] [Batch 12/938] [D loss: 0.313061] [G loss: 0.305068] [info loss: 1.476706]\n",
            "[Epoch 30/200] [Batch 13/938] [D loss: 0.174388] [G loss: 0.555315] [info loss: 1.474186]\n",
            "[Epoch 30/200] [Batch 14/938] [D loss: 0.241466] [G loss: 0.236574] [info loss: 1.488300]\n",
            "[Epoch 30/200] [Batch 15/938] [D loss: 0.267794] [G loss: 0.480977] [info loss: 1.472932]\n",
            "[Epoch 30/200] [Batch 16/938] [D loss: 0.167787] [G loss: 0.551509] [info loss: 1.496248]\n",
            "[Epoch 30/200] [Batch 17/938] [D loss: 0.213486] [G loss: 0.539086] [info loss: 1.474411]\n",
            "[Epoch 30/200] [Batch 18/938] [D loss: 0.204138] [G loss: 0.579035] [info loss: 1.474153]\n",
            "[Epoch 30/200] [Batch 19/938] [D loss: 0.217697] [G loss: 0.407543] [info loss: 1.485623]\n",
            "[Epoch 30/200] [Batch 20/938] [D loss: 0.130098] [G loss: 0.236272] [info loss: 1.481788]\n",
            "[Epoch 30/200] [Batch 21/938] [D loss: 0.167711] [G loss: 0.172047] [info loss: 1.471110]\n",
            "[Epoch 30/200] [Batch 22/938] [D loss: 0.240568] [G loss: 0.234086] [info loss: 1.469737]\n",
            "[Epoch 30/200] [Batch 23/938] [D loss: 0.251351] [G loss: 0.204903] [info loss: 1.500474]\n",
            "[Epoch 30/200] [Batch 24/938] [D loss: 0.306739] [G loss: 0.355972] [info loss: 1.469409]\n",
            "[Epoch 30/200] [Batch 25/938] [D loss: 0.212679] [G loss: 0.227103] [info loss: 1.475979]\n",
            "[Epoch 30/200] [Batch 26/938] [D loss: 0.252619] [G loss: 0.492072] [info loss: 1.483811]\n",
            "[Epoch 30/200] [Batch 27/938] [D loss: 0.222632] [G loss: 0.465301] [info loss: 1.471325]\n",
            "[Epoch 30/200] [Batch 28/938] [D loss: 0.273991] [G loss: 0.269265] [info loss: 1.471485]\n",
            "[Epoch 30/200] [Batch 29/938] [D loss: 0.250180] [G loss: 0.200523] [info loss: 1.513519]\n",
            "[Epoch 30/200] [Batch 30/938] [D loss: 0.227675] [G loss: 0.194208] [info loss: 1.469543]\n",
            "[Epoch 30/200] [Batch 31/938] [D loss: 0.206785] [G loss: 0.234729] [info loss: 1.470953]\n",
            "[Epoch 30/200] [Batch 32/938] [D loss: 0.226458] [G loss: 0.337640] [info loss: 1.496151]\n",
            "[Epoch 30/200] [Batch 33/938] [D loss: 0.234884] [G loss: 0.241126] [info loss: 1.480690]\n",
            "[Epoch 30/200] [Batch 34/938] [D loss: 0.149738] [G loss: 0.356303] [info loss: 1.486099]\n",
            "[Epoch 30/200] [Batch 35/938] [D loss: 0.283924] [G loss: 0.433410] [info loss: 1.484840]\n",
            "[Epoch 30/200] [Batch 36/938] [D loss: 0.186873] [G loss: 0.304864] [info loss: 1.493881]\n",
            "[Epoch 30/200] [Batch 37/938] [D loss: 0.300929] [G loss: 0.422879] [info loss: 1.477675]\n",
            "[Epoch 30/200] [Batch 38/938] [D loss: 0.180468] [G loss: 0.277268] [info loss: 1.469965]\n",
            "[Epoch 30/200] [Batch 39/938] [D loss: 0.179752] [G loss: 0.260331] [info loss: 1.475201]\n",
            "[Epoch 30/200] [Batch 40/938] [D loss: 0.197820] [G loss: 0.663431] [info loss: 1.468194]\n",
            "[Epoch 30/200] [Batch 41/938] [D loss: 0.231080] [G loss: 0.602481] [info loss: 1.476539]\n",
            "[Epoch 30/200] [Batch 42/938] [D loss: 0.184973] [G loss: 0.490671] [info loss: 1.469097]\n",
            "[Epoch 30/200] [Batch 43/938] [D loss: 0.270388] [G loss: 0.374088] [info loss: 1.471880]\n",
            "[Epoch 30/200] [Batch 44/938] [D loss: 0.275298] [G loss: 0.229413] [info loss: 1.485797]\n",
            "[Epoch 30/200] [Batch 45/938] [D loss: 0.246853] [G loss: 0.458649] [info loss: 1.471147]\n",
            "[Epoch 30/200] [Batch 46/938] [D loss: 0.177117] [G loss: 0.471603] [info loss: 1.471266]\n",
            "[Epoch 30/200] [Batch 47/938] [D loss: 0.163964] [G loss: 0.320689] [info loss: 1.470156]\n",
            "[Epoch 30/200] [Batch 48/938] [D loss: 0.310055] [G loss: 0.297511] [info loss: 1.480784]\n",
            "[Epoch 30/200] [Batch 49/938] [D loss: 0.236785] [G loss: 0.231317] [info loss: 1.471069]\n",
            "[Epoch 30/200] [Batch 50/938] [D loss: 0.212996] [G loss: 0.108134] [info loss: 1.488700]\n",
            "[Epoch 30/200] [Batch 51/938] [D loss: 0.219500] [G loss: 0.331566] [info loss: 1.471475]\n",
            "[Epoch 30/200] [Batch 52/938] [D loss: 0.265316] [G loss: 0.316123] [info loss: 1.503664]\n",
            "[Epoch 30/200] [Batch 53/938] [D loss: 0.211254] [G loss: 0.416050] [info loss: 1.470106]\n",
            "[Epoch 30/200] [Batch 54/938] [D loss: 0.378521] [G loss: 0.396836] [info loss: 1.474649]\n",
            "[Epoch 30/200] [Batch 55/938] [D loss: 0.198437] [G loss: 0.411138] [info loss: 1.474876]\n",
            "[Epoch 30/200] [Batch 56/938] [D loss: 0.168832] [G loss: 0.114108] [info loss: 1.471239]\n",
            "[Epoch 30/200] [Batch 57/938] [D loss: 0.310054] [G loss: 0.305131] [info loss: 1.485639]\n",
            "[Epoch 30/200] [Batch 58/938] [D loss: 0.140459] [G loss: 0.295516] [info loss: 1.485788]\n",
            "[Epoch 30/200] [Batch 59/938] [D loss: 0.215707] [G loss: 0.209193] [info loss: 1.486528]\n",
            "[Epoch 30/200] [Batch 60/938] [D loss: 0.217362] [G loss: 0.261819] [info loss: 1.484710]\n",
            "[Epoch 30/200] [Batch 61/938] [D loss: 0.200546] [G loss: 0.381076] [info loss: 1.472143]\n",
            "[Epoch 30/200] [Batch 62/938] [D loss: 0.256935] [G loss: 0.448625] [info loss: 1.502075]\n",
            "[Epoch 30/200] [Batch 63/938] [D loss: 0.148611] [G loss: 0.634462] [info loss: 1.469909]\n",
            "[Epoch 30/200] [Batch 64/938] [D loss: 0.221766] [G loss: 0.474321] [info loss: 1.470133]\n",
            "[Epoch 30/200] [Batch 65/938] [D loss: 0.257752] [G loss: 0.355005] [info loss: 1.488408]\n",
            "[Epoch 30/200] [Batch 66/938] [D loss: 0.242960] [G loss: 0.275647] [info loss: 1.495153]\n",
            "[Epoch 30/200] [Batch 67/938] [D loss: 0.231602] [G loss: 0.159616] [info loss: 1.475652]\n",
            "[Epoch 30/200] [Batch 68/938] [D loss: 0.200480] [G loss: 0.066624] [info loss: 1.470195]\n",
            "[Epoch 30/200] [Batch 69/938] [D loss: 0.254632] [G loss: 0.313242] [info loss: 1.501733]\n",
            "[Epoch 30/200] [Batch 70/938] [D loss: 0.186371] [G loss: 0.615975] [info loss: 1.471882]\n",
            "[Epoch 30/200] [Batch 71/938] [D loss: 0.161921] [G loss: 0.316848] [info loss: 1.471604]\n",
            "[Epoch 30/200] [Batch 72/938] [D loss: 0.265787] [G loss: 0.114261] [info loss: 1.472326]\n",
            "[Epoch 30/200] [Batch 73/938] [D loss: 0.155160] [G loss: 0.251625] [info loss: 1.467943]\n",
            "[Epoch 30/200] [Batch 74/938] [D loss: 0.131007] [G loss: 0.402342] [info loss: 1.474254]\n",
            "[Epoch 30/200] [Batch 75/938] [D loss: 0.305318] [G loss: 0.229353] [info loss: 1.471803]\n",
            "[Epoch 30/200] [Batch 76/938] [D loss: 0.276123] [G loss: 0.779453] [info loss: 1.483177]\n",
            "[Epoch 30/200] [Batch 77/938] [D loss: 0.315539] [G loss: 0.301118] [info loss: 1.471813]\n",
            "[Epoch 30/200] [Batch 78/938] [D loss: 0.219440] [G loss: 0.415694] [info loss: 1.469952]\n",
            "[Epoch 30/200] [Batch 79/938] [D loss: 0.133338] [G loss: 0.299662] [info loss: 1.485420]\n",
            "[Epoch 30/200] [Batch 80/938] [D loss: 0.268598] [G loss: 0.146256] [info loss: 1.499118]\n",
            "[Epoch 30/200] [Batch 81/938] [D loss: 0.137397] [G loss: 0.329966] [info loss: 1.498272]\n",
            "[Epoch 30/200] [Batch 82/938] [D loss: 0.260269] [G loss: 0.385020] [info loss: 1.477702]\n",
            "[Epoch 30/200] [Batch 83/938] [D loss: 0.272332] [G loss: 0.481455] [info loss: 1.471488]\n",
            "[Epoch 30/200] [Batch 84/938] [D loss: 0.148180] [G loss: 0.525661] [info loss: 1.470861]\n",
            "[Epoch 30/200] [Batch 85/938] [D loss: 0.214229] [G loss: 0.267262] [info loss: 1.476863]\n",
            "[Epoch 30/200] [Batch 86/938] [D loss: 0.248990] [G loss: 0.102065] [info loss: 1.480658]\n",
            "[Epoch 30/200] [Batch 87/938] [D loss: 0.184237] [G loss: 0.272398] [info loss: 1.469341]\n",
            "[Epoch 30/200] [Batch 88/938] [D loss: 0.227858] [G loss: 0.249986] [info loss: 1.476046]\n",
            "[Epoch 30/200] [Batch 89/938] [D loss: 0.116027] [G loss: 0.468604] [info loss: 1.471203]\n",
            "[Epoch 30/200] [Batch 90/938] [D loss: 0.302923] [G loss: 0.422284] [info loss: 1.471199]\n",
            "[Epoch 30/200] [Batch 91/938] [D loss: 0.284232] [G loss: 0.372406] [info loss: 1.472420]\n",
            "[Epoch 30/200] [Batch 92/938] [D loss: 0.191942] [G loss: 0.150467] [info loss: 1.474407]\n",
            "[Epoch 30/200] [Batch 93/938] [D loss: 0.224042] [G loss: 0.334056] [info loss: 1.475021]\n",
            "[Epoch 30/200] [Batch 94/938] [D loss: 0.284757] [G loss: 0.201159] [info loss: 1.473962]\n",
            "[Epoch 30/200] [Batch 95/938] [D loss: 0.286070] [G loss: 0.315987] [info loss: 1.483731]\n",
            "[Epoch 30/200] [Batch 96/938] [D loss: 0.154114] [G loss: 0.626480] [info loss: 1.469399]\n",
            "[Epoch 30/200] [Batch 97/938] [D loss: 0.188250] [G loss: 0.298484] [info loss: 1.471501]\n",
            "[Epoch 30/200] [Batch 98/938] [D loss: 0.141270] [G loss: 0.331387] [info loss: 1.470094]\n",
            "[Epoch 30/200] [Batch 99/938] [D loss: 0.281629] [G loss: 0.173180] [info loss: 1.471076]\n",
            "[Epoch 30/200] [Batch 100/938] [D loss: 0.213436] [G loss: 0.268641] [info loss: 1.470712]\n",
            "[Epoch 30/200] [Batch 101/938] [D loss: 0.174496] [G loss: 0.234452] [info loss: 1.491143]\n",
            "[Epoch 30/200] [Batch 102/938] [D loss: 0.207136] [G loss: 0.362954] [info loss: 1.474934]\n",
            "[Epoch 30/200] [Batch 103/938] [D loss: 0.236687] [G loss: 0.493669] [info loss: 1.469910]\n",
            "[Epoch 30/200] [Batch 104/938] [D loss: 0.150936] [G loss: 0.408248] [info loss: 1.473241]\n",
            "[Epoch 30/200] [Batch 105/938] [D loss: 0.216029] [G loss: 0.379726] [info loss: 1.469172]\n",
            "[Epoch 30/200] [Batch 106/938] [D loss: 0.177347] [G loss: 0.294230] [info loss: 1.471410]\n",
            "[Epoch 30/200] [Batch 107/938] [D loss: 0.272839] [G loss: 0.406104] [info loss: 1.479745]\n",
            "[Epoch 30/200] [Batch 108/938] [D loss: 0.227940] [G loss: 0.201948] [info loss: 1.477538]\n",
            "[Epoch 30/200] [Batch 109/938] [D loss: 0.229280] [G loss: 0.155707] [info loss: 1.473827]\n",
            "[Epoch 30/200] [Batch 110/938] [D loss: 0.179335] [G loss: 0.301403] [info loss: 1.505624]\n",
            "[Epoch 30/200] [Batch 111/938] [D loss: 0.210227] [G loss: 0.267811] [info loss: 1.471828]\n",
            "[Epoch 30/200] [Batch 112/938] [D loss: 0.169262] [G loss: 0.429437] [info loss: 1.482303]\n",
            "[Epoch 30/200] [Batch 113/938] [D loss: 0.270212] [G loss: 0.352467] [info loss: 1.472047]\n",
            "[Epoch 30/200] [Batch 114/938] [D loss: 0.225595] [G loss: 0.287775] [info loss: 1.484269]\n",
            "[Epoch 30/200] [Batch 115/938] [D loss: 0.191488] [G loss: 0.321634] [info loss: 1.473509]\n",
            "[Epoch 30/200] [Batch 116/938] [D loss: 0.176310] [G loss: 0.586507] [info loss: 1.478088]\n",
            "[Epoch 30/200] [Batch 117/938] [D loss: 0.266681] [G loss: 0.348835] [info loss: 1.480871]\n",
            "[Epoch 30/200] [Batch 118/938] [D loss: 0.174905] [G loss: 0.668738] [info loss: 1.471373]\n",
            "[Epoch 30/200] [Batch 119/938] [D loss: 0.236025] [G loss: 0.477699] [info loss: 1.470316]\n",
            "[Epoch 30/200] [Batch 120/938] [D loss: 0.179630] [G loss: 0.320049] [info loss: 1.475771]\n",
            "[Epoch 30/200] [Batch 121/938] [D loss: 0.128260] [G loss: 0.446901] [info loss: 1.472541]\n",
            "[Epoch 30/200] [Batch 122/938] [D loss: 0.184131] [G loss: 0.201062] [info loss: 1.471541]\n",
            "[Epoch 30/200] [Batch 123/938] [D loss: 0.202894] [G loss: 0.463840] [info loss: 1.471606]\n",
            "[Epoch 30/200] [Batch 124/938] [D loss: 0.341829] [G loss: 0.300505] [info loss: 1.470618]\n",
            "[Epoch 30/200] [Batch 125/938] [D loss: 0.223984] [G loss: 0.324387] [info loss: 1.471061]\n",
            "[Epoch 30/200] [Batch 126/938] [D loss: 0.260996] [G loss: 0.288715] [info loss: 1.483002]\n",
            "[Epoch 30/200] [Batch 127/938] [D loss: 0.196934] [G loss: 0.361788] [info loss: 1.469254]\n",
            "[Epoch 30/200] [Batch 128/938] [D loss: 0.290629] [G loss: 0.120501] [info loss: 1.472947]\n",
            "[Epoch 30/200] [Batch 129/938] [D loss: 0.160953] [G loss: 0.218007] [info loss: 1.473759]\n",
            "[Epoch 30/200] [Batch 130/938] [D loss: 0.158145] [G loss: 0.307690] [info loss: 1.470456]\n",
            "[Epoch 30/200] [Batch 131/938] [D loss: 0.215855] [G loss: 0.088031] [info loss: 1.471911]\n",
            "[Epoch 30/200] [Batch 132/938] [D loss: 0.203688] [G loss: 0.219685] [info loss: 1.468575]\n",
            "[Epoch 30/200] [Batch 133/938] [D loss: 0.145713] [G loss: 0.319112] [info loss: 1.486953]\n",
            "[Epoch 30/200] [Batch 134/938] [D loss: 0.316019] [G loss: 0.190252] [info loss: 1.486818]\n",
            "[Epoch 30/200] [Batch 135/938] [D loss: 0.290520] [G loss: 0.287840] [info loss: 1.470290]\n",
            "[Epoch 30/200] [Batch 136/938] [D loss: 0.209494] [G loss: 0.201061] [info loss: 1.476749]\n",
            "[Epoch 30/200] [Batch 137/938] [D loss: 0.163151] [G loss: 0.461523] [info loss: 1.469813]\n",
            "[Epoch 30/200] [Batch 138/938] [D loss: 0.306297] [G loss: 0.302342] [info loss: 1.483736]\n",
            "[Epoch 30/200] [Batch 139/938] [D loss: 0.216010] [G loss: 0.519018] [info loss: 1.470924]\n",
            "[Epoch 30/200] [Batch 140/938] [D loss: 0.218893] [G loss: 0.295885] [info loss: 1.470357]\n",
            "[Epoch 30/200] [Batch 141/938] [D loss: 0.260224] [G loss: 0.245867] [info loss: 1.474199]\n",
            "[Epoch 30/200] [Batch 142/938] [D loss: 0.230788] [G loss: 0.492818] [info loss: 1.485187]\n",
            "[Epoch 30/200] [Batch 143/938] [D loss: 0.273760] [G loss: 0.305810] [info loss: 1.482752]\n",
            "[Epoch 30/200] [Batch 144/938] [D loss: 0.258066] [G loss: 0.387399] [info loss: 1.491300]\n",
            "[Epoch 30/200] [Batch 145/938] [D loss: 0.248426] [G loss: 0.178046] [info loss: 1.495132]\n",
            "[Epoch 30/200] [Batch 146/938] [D loss: 0.223378] [G loss: 0.135393] [info loss: 1.484560]\n",
            "[Epoch 30/200] [Batch 147/938] [D loss: 0.159301] [G loss: 0.284935] [info loss: 1.471568]\n",
            "[Epoch 30/200] [Batch 148/938] [D loss: 0.138981] [G loss: 0.351381] [info loss: 1.482708]\n",
            "[Epoch 30/200] [Batch 149/938] [D loss: 0.237557] [G loss: 0.215464] [info loss: 1.482685]\n",
            "[Epoch 30/200] [Batch 150/938] [D loss: 0.183797] [G loss: 0.346003] [info loss: 1.472721]\n",
            "[Epoch 30/200] [Batch 151/938] [D loss: 0.181264] [G loss: 0.240668] [info loss: 1.480394]\n",
            "[Epoch 30/200] [Batch 152/938] [D loss: 0.395881] [G loss: 0.168229] [info loss: 1.471824]\n",
            "[Epoch 30/200] [Batch 153/938] [D loss: 0.155255] [G loss: 0.232644] [info loss: 1.470654]\n",
            "[Epoch 30/200] [Batch 154/938] [D loss: 0.185854] [G loss: 0.362737] [info loss: 1.487117]\n",
            "[Epoch 30/200] [Batch 155/938] [D loss: 0.244000] [G loss: 0.195903] [info loss: 1.479971]\n",
            "[Epoch 30/200] [Batch 156/938] [D loss: 0.215941] [G loss: 0.393023] [info loss: 1.470849]\n",
            "[Epoch 30/200] [Batch 157/938] [D loss: 0.284175] [G loss: 0.187957] [info loss: 1.492248]\n",
            "[Epoch 30/200] [Batch 158/938] [D loss: 0.113285] [G loss: 0.374118] [info loss: 1.472935]\n",
            "[Epoch 30/200] [Batch 159/938] [D loss: 0.308725] [G loss: 0.669078] [info loss: 1.487750]\n",
            "[Epoch 30/200] [Batch 160/938] [D loss: 0.202880] [G loss: 0.462975] [info loss: 1.471947]\n",
            "[Epoch 30/200] [Batch 161/938] [D loss: 0.111250] [G loss: 0.309029] [info loss: 1.470004]\n",
            "[Epoch 30/200] [Batch 162/938] [D loss: 0.328933] [G loss: 0.179034] [info loss: 1.470996]\n",
            "[Epoch 30/200] [Batch 163/938] [D loss: 0.310388] [G loss: 0.490408] [info loss: 1.474312]\n",
            "[Epoch 30/200] [Batch 164/938] [D loss: 0.166572] [G loss: 0.344852] [info loss: 1.471235]\n",
            "[Epoch 30/200] [Batch 165/938] [D loss: 0.160232] [G loss: 0.225265] [info loss: 1.477425]\n",
            "[Epoch 30/200] [Batch 166/938] [D loss: 0.259662] [G loss: 0.291867] [info loss: 1.474291]\n",
            "[Epoch 30/200] [Batch 167/938] [D loss: 0.109397] [G loss: 0.303078] [info loss: 1.483761]\n",
            "[Epoch 30/200] [Batch 168/938] [D loss: 0.203544] [G loss: 0.269889] [info loss: 1.480437]\n",
            "[Epoch 30/200] [Batch 169/938] [D loss: 0.200641] [G loss: 0.324207] [info loss: 1.477885]\n",
            "[Epoch 30/200] [Batch 170/938] [D loss: 0.164572] [G loss: 0.299820] [info loss: 1.476119]\n",
            "[Epoch 30/200] [Batch 171/938] [D loss: 0.093600] [G loss: 0.299072] [info loss: 1.473079]\n",
            "[Epoch 30/200] [Batch 172/938] [D loss: 0.177831] [G loss: 0.342268] [info loss: 1.470635]\n",
            "[Epoch 30/200] [Batch 173/938] [D loss: 0.199634] [G loss: 0.147561] [info loss: 1.472322]\n",
            "[Epoch 30/200] [Batch 174/938] [D loss: 0.211649] [G loss: 0.387491] [info loss: 1.473546]\n",
            "[Epoch 30/200] [Batch 175/938] [D loss: 0.175283] [G loss: 0.560827] [info loss: 1.487455]\n",
            "[Epoch 30/200] [Batch 176/938] [D loss: 0.173855] [G loss: 0.485120] [info loss: 1.472275]\n",
            "[Epoch 30/200] [Batch 177/938] [D loss: 0.195947] [G loss: 0.248008] [info loss: 1.488998]\n",
            "[Epoch 30/200] [Batch 178/938] [D loss: 0.205622] [G loss: 0.239671] [info loss: 1.477896]\n",
            "[Epoch 30/200] [Batch 179/938] [D loss: 0.249044] [G loss: 0.602663] [info loss: 1.476124]\n",
            "[Epoch 30/200] [Batch 180/938] [D loss: 0.259284] [G loss: 0.541836] [info loss: 1.474939]\n",
            "[Epoch 30/200] [Batch 181/938] [D loss: 0.218049] [G loss: 0.401170] [info loss: 1.472554]\n",
            "[Epoch 30/200] [Batch 182/938] [D loss: 0.277658] [G loss: 0.239193] [info loss: 1.473226]\n",
            "[Epoch 30/200] [Batch 183/938] [D loss: 0.268626] [G loss: 0.371407] [info loss: 1.469954]\n",
            "[Epoch 30/200] [Batch 184/938] [D loss: 0.147449] [G loss: 0.284017] [info loss: 1.471724]\n",
            "[Epoch 30/200] [Batch 185/938] [D loss: 0.238404] [G loss: 0.435591] [info loss: 1.471766]\n",
            "[Epoch 30/200] [Batch 186/938] [D loss: 0.152661] [G loss: 0.455844] [info loss: 1.498601]\n",
            "[Epoch 30/200] [Batch 187/938] [D loss: 0.247739] [G loss: 0.343374] [info loss: 1.470198]\n",
            "[Epoch 30/200] [Batch 188/938] [D loss: 0.164104] [G loss: 0.303752] [info loss: 1.469635]\n",
            "[Epoch 30/200] [Batch 189/938] [D loss: 0.251358] [G loss: 0.423944] [info loss: 1.469569]\n",
            "[Epoch 30/200] [Batch 190/938] [D loss: 0.198233] [G loss: 0.322166] [info loss: 1.474549]\n",
            "[Epoch 30/200] [Batch 191/938] [D loss: 0.193400] [G loss: 0.316479] [info loss: 1.473792]\n",
            "[Epoch 30/200] [Batch 192/938] [D loss: 0.240448] [G loss: 0.383849] [info loss: 1.487053]\n",
            "[Epoch 30/200] [Batch 193/938] [D loss: 0.228113] [G loss: 0.408687] [info loss: 1.469992]\n",
            "[Epoch 30/200] [Batch 194/938] [D loss: 0.207071] [G loss: 0.304687] [info loss: 1.478547]\n",
            "[Epoch 30/200] [Batch 195/938] [D loss: 0.223174] [G loss: 0.509142] [info loss: 1.470579]\n",
            "[Epoch 30/200] [Batch 196/938] [D loss: 0.247294] [G loss: 0.109617] [info loss: 1.478510]\n",
            "[Epoch 30/200] [Batch 197/938] [D loss: 0.160140] [G loss: 0.306319] [info loss: 1.487805]\n",
            "[Epoch 30/200] [Batch 198/938] [D loss: 0.112564] [G loss: 0.455897] [info loss: 1.484925]\n",
            "[Epoch 30/200] [Batch 199/938] [D loss: 0.228331] [G loss: 0.491574] [info loss: 1.472349]\n",
            "[Epoch 30/200] [Batch 200/938] [D loss: 0.178087] [G loss: 0.426448] [info loss: 1.472837]\n",
            "[Epoch 30/200] [Batch 201/938] [D loss: 0.212146] [G loss: 0.242342] [info loss: 1.488303]\n",
            "[Epoch 30/200] [Batch 202/938] [D loss: 0.219126] [G loss: 0.346828] [info loss: 1.472064]\n",
            "[Epoch 30/200] [Batch 203/938] [D loss: 0.183743] [G loss: 0.294358] [info loss: 1.470067]\n",
            "[Epoch 30/200] [Batch 204/938] [D loss: 0.162547] [G loss: 0.300672] [info loss: 1.470970]\n",
            "[Epoch 30/200] [Batch 205/938] [D loss: 0.240342] [G loss: 0.343724] [info loss: 1.469615]\n",
            "[Epoch 30/200] [Batch 206/938] [D loss: 0.216645] [G loss: 0.464577] [info loss: 1.485835]\n",
            "[Epoch 30/200] [Batch 207/938] [D loss: 0.211747] [G loss: 0.719413] [info loss: 1.471955]\n",
            "[Epoch 30/200] [Batch 208/938] [D loss: 0.236657] [G loss: 0.258071] [info loss: 1.487021]\n",
            "[Epoch 30/200] [Batch 209/938] [D loss: 0.119433] [G loss: 0.494861] [info loss: 1.488511]\n",
            "[Epoch 30/200] [Batch 210/938] [D loss: 0.235436] [G loss: 0.386616] [info loss: 1.468961]\n",
            "[Epoch 30/200] [Batch 211/938] [D loss: 0.297768] [G loss: 0.284425] [info loss: 1.497260]\n",
            "[Epoch 30/200] [Batch 212/938] [D loss: 0.204146] [G loss: 0.180558] [info loss: 1.471947]\n",
            "[Epoch 30/200] [Batch 213/938] [D loss: 0.180663] [G loss: 0.448322] [info loss: 1.469781]\n",
            "[Epoch 30/200] [Batch 214/938] [D loss: 0.249390] [G loss: 0.401143] [info loss: 1.492324]\n",
            "[Epoch 30/200] [Batch 215/938] [D loss: 0.166507] [G loss: 0.233949] [info loss: 1.471850]\n",
            "[Epoch 30/200] [Batch 216/938] [D loss: 0.114852] [G loss: 0.201263] [info loss: 1.483006]\n",
            "[Epoch 30/200] [Batch 217/938] [D loss: 0.228073] [G loss: 0.571587] [info loss: 1.479945]\n",
            "[Epoch 30/200] [Batch 218/938] [D loss: 0.206330] [G loss: 0.295074] [info loss: 1.482254]\n",
            "[Epoch 30/200] [Batch 219/938] [D loss: 0.288874] [G loss: 0.373166] [info loss: 1.486697]\n",
            "[Epoch 30/200] [Batch 220/938] [D loss: 0.298580] [G loss: 0.280114] [info loss: 1.475974]\n",
            "[Epoch 30/200] [Batch 221/938] [D loss: 0.295058] [G loss: 0.346787] [info loss: 1.470651]\n",
            "[Epoch 30/200] [Batch 222/938] [D loss: 0.163870] [G loss: 0.550210] [info loss: 1.472150]\n",
            "[Epoch 30/200] [Batch 223/938] [D loss: 0.154563] [G loss: 0.554199] [info loss: 1.473331]\n",
            "[Epoch 30/200] [Batch 224/938] [D loss: 0.173606] [G loss: 0.536364] [info loss: 1.492809]\n",
            "[Epoch 30/200] [Batch 225/938] [D loss: 0.164062] [G loss: 0.254914] [info loss: 1.476147]\n",
            "[Epoch 30/200] [Batch 226/938] [D loss: 0.283123] [G loss: 0.186909] [info loss: 1.500638]\n",
            "[Epoch 30/200] [Batch 227/938] [D loss: 0.172252] [G loss: 0.512047] [info loss: 1.468824]\n",
            "[Epoch 30/200] [Batch 228/938] [D loss: 0.279048] [G loss: 0.401623] [info loss: 1.495738]\n",
            "[Epoch 30/200] [Batch 229/938] [D loss: 0.213074] [G loss: 0.357859] [info loss: 1.471878]\n",
            "[Epoch 30/200] [Batch 230/938] [D loss: 0.261686] [G loss: 0.265917] [info loss: 1.472251]\n",
            "[Epoch 30/200] [Batch 231/938] [D loss: 0.181823] [G loss: 0.241858] [info loss: 1.486666]\n",
            "[Epoch 30/200] [Batch 232/938] [D loss: 0.202840] [G loss: 0.213045] [info loss: 1.486542]\n",
            "[Epoch 30/200] [Batch 233/938] [D loss: 0.253735] [G loss: 0.241564] [info loss: 1.473097]\n",
            "[Epoch 30/200] [Batch 234/938] [D loss: 0.143206] [G loss: 0.332207] [info loss: 1.486749]\n",
            "[Epoch 30/200] [Batch 235/938] [D loss: 0.192598] [G loss: 0.250422] [info loss: 1.490368]\n",
            "[Epoch 30/200] [Batch 236/938] [D loss: 0.270564] [G loss: 0.312041] [info loss: 1.489165]\n",
            "[Epoch 30/200] [Batch 237/938] [D loss: 0.260795] [G loss: 0.355096] [info loss: 1.492702]\n",
            "[Epoch 30/200] [Batch 238/938] [D loss: 0.245103] [G loss: 0.180417] [info loss: 1.488272]\n",
            "[Epoch 30/200] [Batch 239/938] [D loss: 0.234107] [G loss: 0.257931] [info loss: 1.472016]\n",
            "[Epoch 30/200] [Batch 240/938] [D loss: 0.139874] [G loss: 0.334631] [info loss: 1.471570]\n",
            "[Epoch 30/200] [Batch 241/938] [D loss: 0.132256] [G loss: 0.231926] [info loss: 1.475595]\n",
            "[Epoch 30/200] [Batch 242/938] [D loss: 0.258125] [G loss: 0.268856] [info loss: 1.471722]\n",
            "[Epoch 30/200] [Batch 243/938] [D loss: 0.240409] [G loss: 0.208954] [info loss: 1.491127]\n",
            "[Epoch 30/200] [Batch 244/938] [D loss: 0.300954] [G loss: 0.289323] [info loss: 1.495962]\n",
            "[Epoch 30/200] [Batch 245/938] [D loss: 0.258384] [G loss: 0.363931] [info loss: 1.473723]\n",
            "[Epoch 30/200] [Batch 246/938] [D loss: 0.166259] [G loss: 0.559048] [info loss: 1.471323]\n",
            "[Epoch 30/200] [Batch 247/938] [D loss: 0.318729] [G loss: 0.241094] [info loss: 1.470321]\n",
            "[Epoch 30/200] [Batch 248/938] [D loss: 0.375057] [G loss: 0.328177] [info loss: 1.471875]\n",
            "[Epoch 30/200] [Batch 249/938] [D loss: 0.309496] [G loss: 0.297047] [info loss: 1.505993]\n",
            "[Epoch 30/200] [Batch 250/938] [D loss: 0.207945] [G loss: 0.376651] [info loss: 1.472259]\n",
            "[Epoch 30/200] [Batch 251/938] [D loss: 0.250823] [G loss: 0.510610] [info loss: 1.473826]\n",
            "[Epoch 30/200] [Batch 252/938] [D loss: 0.352742] [G loss: 0.235546] [info loss: 1.479069]\n",
            "[Epoch 30/200] [Batch 253/938] [D loss: 0.229882] [G loss: 0.252095] [info loss: 1.485076]\n",
            "[Epoch 30/200] [Batch 254/938] [D loss: 0.252049] [G loss: 0.409148] [info loss: 1.501512]\n",
            "[Epoch 30/200] [Batch 255/938] [D loss: 0.195458] [G loss: 0.452796] [info loss: 1.473011]\n",
            "[Epoch 30/200] [Batch 256/938] [D loss: 0.377788] [G loss: 0.408269] [info loss: 1.473622]\n",
            "[Epoch 30/200] [Batch 257/938] [D loss: 0.196172] [G loss: 0.288888] [info loss: 1.472132]\n",
            "[Epoch 30/200] [Batch 258/938] [D loss: 0.166820] [G loss: 0.115372] [info loss: 1.476055]\n",
            "[Epoch 30/200] [Batch 259/938] [D loss: 0.175232] [G loss: 0.121815] [info loss: 1.472046]\n",
            "[Epoch 30/200] [Batch 260/938] [D loss: 0.164059] [G loss: 0.444492] [info loss: 1.472620]\n",
            "[Epoch 30/200] [Batch 261/938] [D loss: 0.231686] [G loss: 0.302784] [info loss: 1.478472]\n",
            "[Epoch 30/200] [Batch 262/938] [D loss: 0.179939] [G loss: 0.266337] [info loss: 1.472244]\n",
            "[Epoch 30/200] [Batch 263/938] [D loss: 0.175903] [G loss: 0.410892] [info loss: 1.471681]\n",
            "[Epoch 30/200] [Batch 264/938] [D loss: 0.294080] [G loss: 0.464384] [info loss: 1.487459]\n",
            "[Epoch 30/200] [Batch 265/938] [D loss: 0.310021] [G loss: 0.548432] [info loss: 1.470558]\n",
            "[Epoch 30/200] [Batch 266/938] [D loss: 0.225120] [G loss: 0.436842] [info loss: 1.488237]\n",
            "[Epoch 30/200] [Batch 267/938] [D loss: 0.327651] [G loss: 0.316673] [info loss: 1.471723]\n",
            "[Epoch 30/200] [Batch 268/938] [D loss: 0.278303] [G loss: 0.198934] [info loss: 1.470156]\n",
            "[Epoch 30/200] [Batch 269/938] [D loss: 0.158699] [G loss: 0.194118] [info loss: 1.469894]\n",
            "[Epoch 30/200] [Batch 270/938] [D loss: 0.192052] [G loss: 0.104222] [info loss: 1.471489]\n",
            "[Epoch 30/200] [Batch 271/938] [D loss: 0.235105] [G loss: 0.270739] [info loss: 1.484847]\n",
            "[Epoch 30/200] [Batch 272/938] [D loss: 0.187398] [G loss: 0.327622] [info loss: 1.472513]\n",
            "[Epoch 30/200] [Batch 273/938] [D loss: 0.248583] [G loss: 0.583303] [info loss: 1.471271]\n",
            "[Epoch 30/200] [Batch 274/938] [D loss: 0.367591] [G loss: 0.514894] [info loss: 1.486334]\n",
            "[Epoch 30/200] [Batch 275/938] [D loss: 0.228503] [G loss: 0.230036] [info loss: 1.474318]\n",
            "[Epoch 30/200] [Batch 276/938] [D loss: 0.165092] [G loss: 0.195946] [info loss: 1.485335]\n",
            "[Epoch 30/200] [Batch 277/938] [D loss: 0.244859] [G loss: 0.293271] [info loss: 1.474289]\n",
            "[Epoch 30/200] [Batch 278/938] [D loss: 0.278534] [G loss: 0.219404] [info loss: 1.485813]\n",
            "[Epoch 30/200] [Batch 279/938] [D loss: 0.270685] [G loss: 0.368571] [info loss: 1.471624]\n",
            "[Epoch 30/200] [Batch 280/938] [D loss: 0.262470] [G loss: 0.237085] [info loss: 1.486381]\n",
            "[Epoch 30/200] [Batch 281/938] [D loss: 0.217430] [G loss: 0.272107] [info loss: 1.476888]\n",
            "[Epoch 30/200] [Batch 282/938] [D loss: 0.225803] [G loss: 0.256467] [info loss: 1.469390]\n",
            "[Epoch 30/200] [Batch 283/938] [D loss: 0.103480] [G loss: 0.338144] [info loss: 1.471976]\n",
            "[Epoch 30/200] [Batch 284/938] [D loss: 0.236875] [G loss: 0.383061] [info loss: 1.475424]\n",
            "[Epoch 30/200] [Batch 285/938] [D loss: 0.185672] [G loss: 0.488733] [info loss: 1.474801]\n",
            "[Epoch 30/200] [Batch 286/938] [D loss: 0.162159] [G loss: 0.330617] [info loss: 1.471162]\n",
            "[Epoch 30/200] [Batch 287/938] [D loss: 0.211876] [G loss: 0.414357] [info loss: 1.469723]\n",
            "[Epoch 30/200] [Batch 288/938] [D loss: 0.262759] [G loss: 0.223404] [info loss: 1.475198]\n",
            "[Epoch 30/200] [Batch 289/938] [D loss: 0.178485] [G loss: 0.228659] [info loss: 1.471697]\n",
            "[Epoch 30/200] [Batch 290/938] [D loss: 0.246647] [G loss: 0.159556] [info loss: 1.471949]\n",
            "[Epoch 30/200] [Batch 291/938] [D loss: 0.125973] [G loss: 0.248784] [info loss: 1.470293]\n",
            "[Epoch 30/200] [Batch 292/938] [D loss: 0.233450] [G loss: 0.293596] [info loss: 1.469090]\n",
            "[Epoch 30/200] [Batch 293/938] [D loss: 0.241945] [G loss: 0.375598] [info loss: 1.487388]\n",
            "[Epoch 30/200] [Batch 294/938] [D loss: 0.187580] [G loss: 0.267439] [info loss: 1.503400]\n",
            "[Epoch 30/200] [Batch 295/938] [D loss: 0.260463] [G loss: 0.376709] [info loss: 1.470572]\n",
            "[Epoch 30/200] [Batch 296/938] [D loss: 0.283751] [G loss: 0.305260] [info loss: 1.474209]\n",
            "[Epoch 30/200] [Batch 297/938] [D loss: 0.202401] [G loss: 0.391006] [info loss: 1.469765]\n",
            "[Epoch 30/200] [Batch 298/938] [D loss: 0.220795] [G loss: 0.353502] [info loss: 1.497665]\n",
            "[Epoch 30/200] [Batch 299/938] [D loss: 0.117180] [G loss: 0.336522] [info loss: 1.476839]\n",
            "[Epoch 30/200] [Batch 300/938] [D loss: 0.244135] [G loss: 0.309598] [info loss: 1.477688]\n",
            "[Epoch 30/200] [Batch 301/938] [D loss: 0.179168] [G loss: 0.218936] [info loss: 1.471592]\n",
            "[Epoch 30/200] [Batch 302/938] [D loss: 0.328295] [G loss: 0.116958] [info loss: 1.486576]\n",
            "[Epoch 30/200] [Batch 303/938] [D loss: 0.199198] [G loss: 0.350172] [info loss: 1.483006]\n",
            "[Epoch 30/200] [Batch 304/938] [D loss: 0.175945] [G loss: 0.301045] [info loss: 1.472602]\n",
            "[Epoch 30/200] [Batch 305/938] [D loss: 0.183687] [G loss: 0.270728] [info loss: 1.471996]\n",
            "[Epoch 30/200] [Batch 306/938] [D loss: 0.213172] [G loss: 0.237147] [info loss: 1.471891]\n",
            "[Epoch 30/200] [Batch 307/938] [D loss: 0.109443] [G loss: 0.671140] [info loss: 1.499909]\n",
            "[Epoch 30/200] [Batch 308/938] [D loss: 0.219741] [G loss: 0.295575] [info loss: 1.470358]\n",
            "[Epoch 30/200] [Batch 309/938] [D loss: 0.384340] [G loss: 0.358626] [info loss: 1.504711]\n",
            "[Epoch 30/200] [Batch 310/938] [D loss: 0.186941] [G loss: 0.297348] [info loss: 1.469022]\n",
            "[Epoch 30/200] [Batch 311/938] [D loss: 0.324029] [G loss: 0.238236] [info loss: 1.488344]\n",
            "[Epoch 30/200] [Batch 312/938] [D loss: 0.199042] [G loss: 0.244192] [info loss: 1.479352]\n",
            "[Epoch 30/200] [Batch 313/938] [D loss: 0.304358] [G loss: 0.188267] [info loss: 1.470871]\n",
            "[Epoch 30/200] [Batch 314/938] [D loss: 0.254245] [G loss: 0.444770] [info loss: 1.475554]\n",
            "[Epoch 30/200] [Batch 315/938] [D loss: 0.284544] [G loss: 0.354408] [info loss: 1.487068]\n",
            "[Epoch 30/200] [Batch 316/938] [D loss: 0.223024] [G loss: 0.366446] [info loss: 1.479215]\n",
            "[Epoch 30/200] [Batch 317/938] [D loss: 0.224306] [G loss: 0.257139] [info loss: 1.469859]\n",
            "[Epoch 30/200] [Batch 318/938] [D loss: 0.237622] [G loss: 0.235862] [info loss: 1.473960]\n",
            "[Epoch 30/200] [Batch 319/938] [D loss: 0.240556] [G loss: 0.270001] [info loss: 1.490569]\n",
            "[Epoch 30/200] [Batch 320/938] [D loss: 0.197383] [G loss: 0.138030] [info loss: 1.478641]\n",
            "[Epoch 30/200] [Batch 321/938] [D loss: 0.175007] [G loss: 0.364611] [info loss: 1.484909]\n",
            "[Epoch 30/200] [Batch 322/938] [D loss: 0.269989] [G loss: 0.345990] [info loss: 1.488209]\n",
            "[Epoch 30/200] [Batch 323/938] [D loss: 0.182408] [G loss: 0.130166] [info loss: 1.476762]\n",
            "[Epoch 30/200] [Batch 324/938] [D loss: 0.134095] [G loss: 0.230776] [info loss: 1.470833]\n",
            "[Epoch 30/200] [Batch 325/938] [D loss: 0.185335] [G loss: 0.322828] [info loss: 1.477580]\n",
            "[Epoch 30/200] [Batch 326/938] [D loss: 0.204776] [G loss: 0.249987] [info loss: 1.480252]\n",
            "[Epoch 30/200] [Batch 327/938] [D loss: 0.128186] [G loss: 0.474134] [info loss: 1.488468]\n",
            "[Epoch 30/200] [Batch 328/938] [D loss: 0.335104] [G loss: 0.376301] [info loss: 1.473572]\n",
            "[Epoch 30/200] [Batch 329/938] [D loss: 0.206437] [G loss: 0.387998] [info loss: 1.472530]\n",
            "[Epoch 30/200] [Batch 330/938] [D loss: 0.208116] [G loss: 0.542668] [info loss: 1.473754]\n",
            "[Epoch 30/200] [Batch 331/938] [D loss: 0.245508] [G loss: 0.523277] [info loss: 1.486130]\n",
            "[Epoch 30/200] [Batch 332/938] [D loss: 0.344389] [G loss: 0.355398] [info loss: 1.476276]\n",
            "[Epoch 30/200] [Batch 333/938] [D loss: 0.135653] [G loss: 0.592991] [info loss: 1.491420]\n",
            "[Epoch 30/200] [Batch 334/938] [D loss: 0.208665] [G loss: 0.238698] [info loss: 1.469721]\n",
            "[Epoch 30/200] [Batch 335/938] [D loss: 0.239123] [G loss: 0.289507] [info loss: 1.514373]\n",
            "[Epoch 30/200] [Batch 336/938] [D loss: 0.245858] [G loss: 0.198667] [info loss: 1.469025]\n",
            "[Epoch 30/200] [Batch 337/938] [D loss: 0.252980] [G loss: 0.250292] [info loss: 1.482151]\n",
            "[Epoch 30/200] [Batch 338/938] [D loss: 0.239055] [G loss: 0.176186] [info loss: 1.478939]\n",
            "[Epoch 30/200] [Batch 339/938] [D loss: 0.197735] [G loss: 0.548854] [info loss: 1.521628]\n",
            "[Epoch 30/200] [Batch 340/938] [D loss: 0.247779] [G loss: 0.384631] [info loss: 1.471584]\n",
            "[Epoch 30/200] [Batch 341/938] [D loss: 0.202841] [G loss: 0.366767] [info loss: 1.476472]\n",
            "[Epoch 30/200] [Batch 342/938] [D loss: 0.280168] [G loss: 0.606147] [info loss: 1.476701]\n",
            "[Epoch 30/200] [Batch 343/938] [D loss: 0.211946] [G loss: 0.430390] [info loss: 1.470316]\n",
            "[Epoch 30/200] [Batch 344/938] [D loss: 0.152842] [G loss: 0.399450] [info loss: 1.469647]\n",
            "[Epoch 30/200] [Batch 345/938] [D loss: 0.166045] [G loss: 0.556391] [info loss: 1.473646]\n",
            "[Epoch 30/200] [Batch 346/938] [D loss: 0.257003] [G loss: 0.135407] [info loss: 1.472999]\n",
            "[Epoch 30/200] [Batch 347/938] [D loss: 0.175397] [G loss: 0.286560] [info loss: 1.484498]\n",
            "[Epoch 30/200] [Batch 348/938] [D loss: 0.177286] [G loss: 0.108355] [info loss: 1.478566]\n",
            "[Epoch 30/200] [Batch 349/938] [D loss: 0.138612] [G loss: 0.333494] [info loss: 1.473481]\n",
            "[Epoch 30/200] [Batch 350/938] [D loss: 0.218186] [G loss: 0.488674] [info loss: 1.469852]\n",
            "[Epoch 30/200] [Batch 351/938] [D loss: 0.226357] [G loss: 0.260832] [info loss: 1.472271]\n",
            "[Epoch 30/200] [Batch 352/938] [D loss: 0.221842] [G loss: 0.400158] [info loss: 1.491148]\n",
            "[Epoch 30/200] [Batch 353/938] [D loss: 0.241591] [G loss: 0.415437] [info loss: 1.477466]\n",
            "[Epoch 30/200] [Batch 354/938] [D loss: 0.187076] [G loss: 0.233178] [info loss: 1.489410]\n",
            "[Epoch 30/200] [Batch 355/938] [D loss: 0.215466] [G loss: 0.287930] [info loss: 1.472712]\n",
            "[Epoch 30/200] [Batch 356/938] [D loss: 0.172311] [G loss: 0.413863] [info loss: 1.480991]\n",
            "[Epoch 30/200] [Batch 357/938] [D loss: 0.131878] [G loss: 0.349062] [info loss: 1.477220]\n",
            "[Epoch 30/200] [Batch 358/938] [D loss: 0.158361] [G loss: 0.475727] [info loss: 1.487545]\n",
            "[Epoch 30/200] [Batch 359/938] [D loss: 0.149611] [G loss: 0.436848] [info loss: 1.474708]\n",
            "[Epoch 30/200] [Batch 360/938] [D loss: 0.162031] [G loss: 0.336345] [info loss: 1.477397]\n",
            "[Epoch 30/200] [Batch 361/938] [D loss: 0.158753] [G loss: 0.183840] [info loss: 1.474590]\n",
            "[Epoch 30/200] [Batch 362/938] [D loss: 0.267597] [G loss: 0.609018] [info loss: 1.475491]\n",
            "[Epoch 30/200] [Batch 363/938] [D loss: 0.139392] [G loss: 0.314005] [info loss: 1.493798]\n",
            "[Epoch 30/200] [Batch 364/938] [D loss: 0.175110] [G loss: 0.471314] [info loss: 1.484762]\n",
            "[Epoch 30/200] [Batch 365/938] [D loss: 0.343423] [G loss: 0.352369] [info loss: 1.484150]\n",
            "[Epoch 30/200] [Batch 366/938] [D loss: 0.213590] [G loss: 0.387024] [info loss: 1.476507]\n",
            "[Epoch 30/200] [Batch 367/938] [D loss: 0.306648] [G loss: 0.253511] [info loss: 1.471046]\n",
            "[Epoch 30/200] [Batch 368/938] [D loss: 0.194510] [G loss: 0.064335] [info loss: 1.471898]\n",
            "[Epoch 30/200] [Batch 369/938] [D loss: 0.252398] [G loss: 0.257077] [info loss: 1.471658]\n",
            "[Epoch 30/200] [Batch 370/938] [D loss: 0.228926] [G loss: 0.453438] [info loss: 1.471346]\n",
            "[Epoch 30/200] [Batch 371/938] [D loss: 0.404012] [G loss: 0.441256] [info loss: 1.478608]\n",
            "[Epoch 30/200] [Batch 372/938] [D loss: 0.183319] [G loss: 0.408183] [info loss: 1.501511]\n",
            "[Epoch 30/200] [Batch 373/938] [D loss: 0.418539] [G loss: 0.354671] [info loss: 1.480754]\n",
            "[Epoch 30/200] [Batch 374/938] [D loss: 0.203661] [G loss: 0.227786] [info loss: 1.474054]\n",
            "[Epoch 30/200] [Batch 375/938] [D loss: 0.160762] [G loss: 0.347046] [info loss: 1.484308]\n",
            "[Epoch 30/200] [Batch 376/938] [D loss: 0.254314] [G loss: 0.560511] [info loss: 1.471755]\n",
            "[Epoch 30/200] [Batch 377/938] [D loss: 0.205186] [G loss: 0.141906] [info loss: 1.470979]\n",
            "[Epoch 30/200] [Batch 378/938] [D loss: 0.260907] [G loss: 0.427640] [info loss: 1.475548]\n",
            "[Epoch 30/200] [Batch 379/938] [D loss: 0.236641] [G loss: 0.626963] [info loss: 1.485593]\n",
            "[Epoch 30/200] [Batch 380/938] [D loss: 0.204181] [G loss: 0.520849] [info loss: 1.480708]\n",
            "[Epoch 30/200] [Batch 381/938] [D loss: 0.183335] [G loss: 0.310892] [info loss: 1.487316]\n",
            "[Epoch 30/200] [Batch 382/938] [D loss: 0.258609] [G loss: 0.211593] [info loss: 1.499379]\n",
            "[Epoch 30/200] [Batch 383/938] [D loss: 0.185157] [G loss: 0.400478] [info loss: 1.474162]\n",
            "[Epoch 30/200] [Batch 384/938] [D loss: 0.239851] [G loss: 0.255004] [info loss: 1.483204]\n",
            "[Epoch 30/200] [Batch 385/938] [D loss: 0.181281] [G loss: 0.413177] [info loss: 1.471698]\n",
            "[Epoch 30/200] [Batch 386/938] [D loss: 0.203446] [G loss: 0.266200] [info loss: 1.508966]\n",
            "[Epoch 30/200] [Batch 387/938] [D loss: 0.194414] [G loss: 0.313841] [info loss: 1.473718]\n",
            "[Epoch 30/200] [Batch 388/938] [D loss: 0.305589] [G loss: 0.185437] [info loss: 1.472592]\n",
            "[Epoch 30/200] [Batch 389/938] [D loss: 0.159833] [G loss: 0.330676] [info loss: 1.475260]\n",
            "[Epoch 30/200] [Batch 390/938] [D loss: 0.183969] [G loss: 0.393449] [info loss: 1.468873]\n",
            "[Epoch 30/200] [Batch 391/938] [D loss: 0.231214] [G loss: 0.521888] [info loss: 1.473328]\n",
            "[Epoch 30/200] [Batch 392/938] [D loss: 0.135251] [G loss: 0.228581] [info loss: 1.469646]\n",
            "[Epoch 30/200] [Batch 393/938] [D loss: 0.116565] [G loss: 0.314543] [info loss: 1.500739]\n",
            "[Epoch 30/200] [Batch 394/938] [D loss: 0.188071] [G loss: 0.168495] [info loss: 1.482927]\n",
            "[Epoch 30/200] [Batch 395/938] [D loss: 0.204676] [G loss: 0.256695] [info loss: 1.469119]\n",
            "[Epoch 30/200] [Batch 396/938] [D loss: 0.238703] [G loss: 0.451838] [info loss: 1.477266]\n",
            "[Epoch 30/200] [Batch 397/938] [D loss: 0.151091] [G loss: 0.351442] [info loss: 1.472149]\n",
            "[Epoch 30/200] [Batch 398/938] [D loss: 0.266795] [G loss: 0.341059] [info loss: 1.486779]\n",
            "[Epoch 30/200] [Batch 399/938] [D loss: 0.208424] [G loss: 0.195243] [info loss: 1.470567]\n",
            "[Epoch 30/200] [Batch 400/938] [D loss: 0.311347] [G loss: 0.039381] [info loss: 1.493154]\n",
            "[Epoch 30/200] [Batch 401/938] [D loss: 0.189085] [G loss: 0.597517] [info loss: 1.485662]\n",
            "[Epoch 30/200] [Batch 402/938] [D loss: 0.269543] [G loss: 0.562108] [info loss: 1.469679]\n",
            "[Epoch 30/200] [Batch 403/938] [D loss: 0.348793] [G loss: 0.171588] [info loss: 1.474668]\n",
            "[Epoch 30/200] [Batch 404/938] [D loss: 0.156879] [G loss: 0.218172] [info loss: 1.492454]\n",
            "[Epoch 30/200] [Batch 405/938] [D loss: 0.276146] [G loss: 0.198054] [info loss: 1.469293]\n",
            "[Epoch 30/200] [Batch 406/938] [D loss: 0.283140] [G loss: 0.337527] [info loss: 1.471143]\n",
            "[Epoch 30/200] [Batch 407/938] [D loss: 0.206087] [G loss: 0.267365] [info loss: 1.497555]\n",
            "[Epoch 30/200] [Batch 408/938] [D loss: 0.204461] [G loss: 0.241931] [info loss: 1.484073]\n",
            "[Epoch 30/200] [Batch 409/938] [D loss: 0.100723] [G loss: 0.442668] [info loss: 1.488395]\n",
            "[Epoch 30/200] [Batch 410/938] [D loss: 0.181478] [G loss: 0.513205] [info loss: 1.477657]\n",
            "[Epoch 30/200] [Batch 411/938] [D loss: 0.238702] [G loss: 0.345943] [info loss: 1.473037]\n",
            "[Epoch 30/200] [Batch 412/938] [D loss: 0.215944] [G loss: 0.243403] [info loss: 1.470948]\n",
            "[Epoch 30/200] [Batch 413/938] [D loss: 0.261932] [G loss: 0.628891] [info loss: 1.471366]\n",
            "[Epoch 30/200] [Batch 414/938] [D loss: 0.338629] [G loss: 0.415924] [info loss: 1.480972]\n",
            "[Epoch 30/200] [Batch 415/938] [D loss: 0.189344] [G loss: 0.515084] [info loss: 1.471797]\n",
            "[Epoch 30/200] [Batch 416/938] [D loss: 0.186493] [G loss: 0.333681] [info loss: 1.470603]\n",
            "[Epoch 30/200] [Batch 417/938] [D loss: 0.207875] [G loss: 0.400144] [info loss: 1.474832]\n",
            "[Epoch 30/200] [Batch 418/938] [D loss: 0.231684] [G loss: 0.253119] [info loss: 1.469494]\n",
            "[Epoch 30/200] [Batch 419/938] [D loss: 0.160205] [G loss: 0.493576] [info loss: 1.470080]\n",
            "[Epoch 30/200] [Batch 420/938] [D loss: 0.220808] [G loss: 0.261511] [info loss: 1.470469]\n",
            "[Epoch 30/200] [Batch 421/938] [D loss: 0.146829] [G loss: 0.399939] [info loss: 1.492160]\n",
            "[Epoch 30/200] [Batch 422/938] [D loss: 0.285487] [G loss: 0.253735] [info loss: 1.476245]\n",
            "[Epoch 30/200] [Batch 423/938] [D loss: 0.208248] [G loss: 0.449793] [info loss: 1.470578]\n",
            "[Epoch 30/200] [Batch 424/938] [D loss: 0.203026] [G loss: 0.314672] [info loss: 1.477511]\n",
            "[Epoch 30/200] [Batch 425/938] [D loss: 0.122070] [G loss: 0.545859] [info loss: 1.478987]\n",
            "[Epoch 30/200] [Batch 426/938] [D loss: 0.200818] [G loss: 0.382387] [info loss: 1.469931]\n",
            "[Epoch 30/200] [Batch 427/938] [D loss: 0.287774] [G loss: 0.280823] [info loss: 1.486177]\n",
            "[Epoch 30/200] [Batch 428/938] [D loss: 0.239895] [G loss: 0.128437] [info loss: 1.469418]\n",
            "[Epoch 30/200] [Batch 429/938] [D loss: 0.246787] [G loss: 0.376910] [info loss: 1.472918]\n",
            "[Epoch 30/200] [Batch 430/938] [D loss: 0.154508] [G loss: 0.301033] [info loss: 1.470356]\n",
            "[Epoch 30/200] [Batch 431/938] [D loss: 0.320508] [G loss: 0.350702] [info loss: 1.485159]\n",
            "[Epoch 30/200] [Batch 432/938] [D loss: 0.265085] [G loss: 0.370968] [info loss: 1.471705]\n",
            "[Epoch 30/200] [Batch 433/938] [D loss: 0.297028] [G loss: 0.329617] [info loss: 1.487117]\n",
            "[Epoch 30/200] [Batch 434/938] [D loss: 0.234256] [G loss: 0.277525] [info loss: 1.475233]\n",
            "[Epoch 30/200] [Batch 435/938] [D loss: 0.222816] [G loss: 0.154049] [info loss: 1.472952]\n",
            "[Epoch 30/200] [Batch 436/938] [D loss: 0.213364] [G loss: 0.362144] [info loss: 1.487014]\n",
            "[Epoch 30/200] [Batch 437/938] [D loss: 0.185003] [G loss: 0.419959] [info loss: 1.484825]\n",
            "[Epoch 30/200] [Batch 438/938] [D loss: 0.148750] [G loss: 0.329372] [info loss: 1.492527]\n",
            "[Epoch 30/200] [Batch 439/938] [D loss: 0.279145] [G loss: 0.389229] [info loss: 1.480450]\n",
            "[Epoch 30/200] [Batch 440/938] [D loss: 0.142861] [G loss: 0.425220] [info loss: 1.471933]\n",
            "[Epoch 30/200] [Batch 441/938] [D loss: 0.270188] [G loss: 0.207388] [info loss: 1.469575]\n",
            "[Epoch 30/200] [Batch 442/938] [D loss: 0.188293] [G loss: 0.258748] [info loss: 1.475737]\n",
            "[Epoch 30/200] [Batch 443/938] [D loss: 0.168625] [G loss: 0.790741] [info loss: 1.475336]\n",
            "[Epoch 30/200] [Batch 444/938] [D loss: 0.219396] [G loss: 0.310862] [info loss: 1.476987]\n",
            "[Epoch 30/200] [Batch 445/938] [D loss: 0.235422] [G loss: 0.267665] [info loss: 1.471001]\n",
            "[Epoch 30/200] [Batch 446/938] [D loss: 0.254644] [G loss: 0.449761] [info loss: 1.472897]\n",
            "[Epoch 30/200] [Batch 447/938] [D loss: 0.192623] [G loss: 0.206609] [info loss: 1.510380]\n",
            "[Epoch 30/200] [Batch 448/938] [D loss: 0.188138] [G loss: 0.208937] [info loss: 1.467496]\n",
            "[Epoch 30/200] [Batch 449/938] [D loss: 0.246746] [G loss: 0.134026] [info loss: 1.483629]\n",
            "[Epoch 30/200] [Batch 450/938] [D loss: 0.190661] [G loss: 0.409862] [info loss: 1.483052]\n",
            "[Epoch 30/200] [Batch 451/938] [D loss: 0.187475] [G loss: 0.309917] [info loss: 1.471243]\n",
            "[Epoch 30/200] [Batch 452/938] [D loss: 0.149700] [G loss: 0.314930] [info loss: 1.486001]\n",
            "[Epoch 30/200] [Batch 453/938] [D loss: 0.284725] [G loss: 0.207333] [info loss: 1.470689]\n",
            "[Epoch 30/200] [Batch 454/938] [D loss: 0.183804] [G loss: 0.381869] [info loss: 1.468557]\n",
            "[Epoch 30/200] [Batch 455/938] [D loss: 0.271374] [G loss: 0.356589] [info loss: 1.470628]\n",
            "[Epoch 30/200] [Batch 456/938] [D loss: 0.153623] [G loss: 0.492284] [info loss: 1.474875]\n",
            "[Epoch 30/200] [Batch 457/938] [D loss: 0.228099] [G loss: 0.349580] [info loss: 1.471814]\n",
            "[Epoch 30/200] [Batch 458/938] [D loss: 0.260789] [G loss: 0.190892] [info loss: 1.470698]\n",
            "[Epoch 30/200] [Batch 459/938] [D loss: 0.273763] [G loss: 0.180738] [info loss: 1.469848]\n",
            "[Epoch 30/200] [Batch 460/938] [D loss: 0.261713] [G loss: 0.306635] [info loss: 1.472034]\n",
            "[Epoch 30/200] [Batch 461/938] [D loss: 0.263764] [G loss: 0.234753] [info loss: 1.484710]\n",
            "[Epoch 30/200] [Batch 462/938] [D loss: 0.335742] [G loss: 0.240496] [info loss: 1.488381]\n",
            "[Epoch 30/200] [Batch 463/938] [D loss: 0.277786] [G loss: 0.210607] [info loss: 1.477072]\n",
            "[Epoch 30/200] [Batch 464/938] [D loss: 0.215307] [G loss: 0.499570] [info loss: 1.469145]\n",
            "[Epoch 30/200] [Batch 465/938] [D loss: 0.248654] [G loss: 0.266993] [info loss: 1.472392]\n",
            "[Epoch 30/200] [Batch 466/938] [D loss: 0.261359] [G loss: 0.239920] [info loss: 1.472524]\n",
            "[Epoch 30/200] [Batch 467/938] [D loss: 0.197656] [G loss: 0.223272] [info loss: 1.474540]\n",
            "[Epoch 30/200] [Batch 468/938] [D loss: 0.189841] [G loss: 0.344043] [info loss: 1.467928]\n",
            "[Epoch 30/200] [Batch 469/938] [D loss: 0.202065] [G loss: 0.389105] [info loss: 1.473704]\n",
            "[Epoch 30/200] [Batch 470/938] [D loss: 0.252151] [G loss: 0.368611] [info loss: 1.483189]\n",
            "[Epoch 30/200] [Batch 471/938] [D loss: 0.103898] [G loss: 0.287197] [info loss: 1.476187]\n",
            "[Epoch 30/200] [Batch 472/938] [D loss: 0.175826] [G loss: 0.563321] [info loss: 1.479295]\n",
            "[Epoch 30/200] [Batch 473/938] [D loss: 0.244406] [G loss: 0.337155] [info loss: 1.471207]\n",
            "[Epoch 30/200] [Batch 474/938] [D loss: 0.124231] [G loss: 0.378038] [info loss: 1.485982]\n",
            "[Epoch 30/200] [Batch 475/938] [D loss: 0.158063] [G loss: 0.314446] [info loss: 1.480371]\n",
            "[Epoch 30/200] [Batch 476/938] [D loss: 0.309166] [G loss: 0.368769] [info loss: 1.469728]\n",
            "[Epoch 30/200] [Batch 477/938] [D loss: 0.180702] [G loss: 0.325008] [info loss: 1.470855]\n",
            "[Epoch 30/200] [Batch 478/938] [D loss: 0.295081] [G loss: 0.214032] [info loss: 1.471036]\n",
            "[Epoch 30/200] [Batch 479/938] [D loss: 0.196725] [G loss: 0.376315] [info loss: 1.502930]\n",
            "[Epoch 30/200] [Batch 480/938] [D loss: 0.202664] [G loss: 0.785254] [info loss: 1.487389]\n",
            "[Epoch 30/200] [Batch 481/938] [D loss: 0.148036] [G loss: 0.331788] [info loss: 1.478457]\n",
            "[Epoch 30/200] [Batch 482/938] [D loss: 0.336532] [G loss: 0.221537] [info loss: 1.473257]\n",
            "[Epoch 30/200] [Batch 483/938] [D loss: 0.149225] [G loss: 0.578609] [info loss: 1.470467]\n",
            "[Epoch 30/200] [Batch 484/938] [D loss: 0.165154] [G loss: 0.600426] [info loss: 1.478174]\n",
            "[Epoch 30/200] [Batch 485/938] [D loss: 0.251142] [G loss: 0.478324] [info loss: 1.478612]\n",
            "[Epoch 30/200] [Batch 486/938] [D loss: 0.137676] [G loss: 0.432612] [info loss: 1.475874]\n",
            "[Epoch 30/200] [Batch 487/938] [D loss: 0.240137] [G loss: 0.273325] [info loss: 1.470391]\n",
            "[Epoch 30/200] [Batch 488/938] [D loss: 0.254056] [G loss: 0.200113] [info loss: 1.499341]\n",
            "[Epoch 30/200] [Batch 489/938] [D loss: 0.193183] [G loss: 0.180955] [info loss: 1.467166]\n",
            "[Epoch 30/200] [Batch 490/938] [D loss: 0.218685] [G loss: 0.230678] [info loss: 1.484843]\n",
            "[Epoch 30/200] [Batch 491/938] [D loss: 0.288973] [G loss: 0.122100] [info loss: 1.471757]\n",
            "[Epoch 30/200] [Batch 492/938] [D loss: 0.307985] [G loss: 0.389524] [info loss: 1.470539]\n",
            "[Epoch 30/200] [Batch 493/938] [D loss: 0.241295] [G loss: 0.275061] [info loss: 1.471223]\n",
            "[Epoch 30/200] [Batch 494/938] [D loss: 0.217243] [G loss: 0.220342] [info loss: 1.483608]\n",
            "[Epoch 30/200] [Batch 495/938] [D loss: 0.204524] [G loss: 0.499778] [info loss: 1.469689]\n",
            "[Epoch 30/200] [Batch 496/938] [D loss: 0.328779] [G loss: 0.337833] [info loss: 1.487369]\n",
            "[Epoch 30/200] [Batch 497/938] [D loss: 0.195239] [G loss: 0.168087] [info loss: 1.471670]\n",
            "[Epoch 30/200] [Batch 498/938] [D loss: 0.230270] [G loss: 0.106338] [info loss: 1.472225]\n",
            "[Epoch 30/200] [Batch 499/938] [D loss: 0.302814] [G loss: 0.208762] [info loss: 1.469767]\n",
            "[Epoch 30/200] [Batch 500/938] [D loss: 0.277738] [G loss: 0.506424] [info loss: 1.481621]\n",
            "[Epoch 30/200] [Batch 501/938] [D loss: 0.286723] [G loss: 0.343613] [info loss: 1.489941]\n",
            "[Epoch 30/200] [Batch 502/938] [D loss: 0.272450] [G loss: 0.361518] [info loss: 1.467754]\n",
            "[Epoch 30/200] [Batch 503/938] [D loss: 0.203362] [G loss: 0.364133] [info loss: 1.469193]\n",
            "[Epoch 30/200] [Batch 504/938] [D loss: 0.198483] [G loss: 0.347344] [info loss: 1.485175]\n",
            "[Epoch 30/200] [Batch 505/938] [D loss: 0.128309] [G loss: 0.266406] [info loss: 1.500528]\n",
            "[Epoch 30/200] [Batch 506/938] [D loss: 0.168767] [G loss: 0.358578] [info loss: 1.484465]\n",
            "[Epoch 30/200] [Batch 507/938] [D loss: 0.209755] [G loss: 0.326293] [info loss: 1.481753]\n",
            "[Epoch 30/200] [Batch 508/938] [D loss: 0.145432] [G loss: 0.357067] [info loss: 1.481022]\n",
            "[Epoch 30/200] [Batch 509/938] [D loss: 0.273572] [G loss: 0.143186] [info loss: 1.471722]\n",
            "[Epoch 30/200] [Batch 510/938] [D loss: 0.114386] [G loss: 0.208102] [info loss: 1.469827]\n",
            "[Epoch 30/200] [Batch 511/938] [D loss: 0.189836] [G loss: 0.672303] [info loss: 1.485657]\n",
            "[Epoch 30/200] [Batch 512/938] [D loss: 0.161154] [G loss: 0.106219] [info loss: 1.507052]\n",
            "[Epoch 30/200] [Batch 513/938] [D loss: 0.213408] [G loss: 0.172279] [info loss: 1.470483]\n",
            "[Epoch 30/200] [Batch 514/938] [D loss: 0.234051] [G loss: 0.196064] [info loss: 1.472788]\n",
            "[Epoch 30/200] [Batch 515/938] [D loss: 0.162559] [G loss: 0.515501] [info loss: 1.494131]\n",
            "[Epoch 30/200] [Batch 516/938] [D loss: 0.192340] [G loss: 0.263391] [info loss: 1.470554]\n",
            "[Epoch 30/200] [Batch 517/938] [D loss: 0.215485] [G loss: 0.222427] [info loss: 1.474518]\n",
            "[Epoch 30/200] [Batch 518/938] [D loss: 0.210176] [G loss: 0.211702] [info loss: 1.508571]\n",
            "[Epoch 30/200] [Batch 519/938] [D loss: 0.290102] [G loss: 0.198920] [info loss: 1.508929]\n",
            "[Epoch 30/200] [Batch 520/938] [D loss: 0.279767] [G loss: 0.333059] [info loss: 1.468969]\n",
            "[Epoch 30/200] [Batch 521/938] [D loss: 0.325110] [G loss: 0.270653] [info loss: 1.470579]\n",
            "[Epoch 30/200] [Batch 522/938] [D loss: 0.253443] [G loss: 0.385252] [info loss: 1.480291]\n",
            "[Epoch 30/200] [Batch 523/938] [D loss: 0.223584] [G loss: 0.365324] [info loss: 1.470934]\n",
            "[Epoch 30/200] [Batch 524/938] [D loss: 0.165695] [G loss: 0.363520] [info loss: 1.470029]\n",
            "[Epoch 30/200] [Batch 525/938] [D loss: 0.089151] [G loss: 0.312651] [info loss: 1.473531]\n",
            "[Epoch 30/200] [Batch 526/938] [D loss: 0.248182] [G loss: 0.263756] [info loss: 1.480223]\n",
            "[Epoch 30/200] [Batch 527/938] [D loss: 0.163261] [G loss: 0.444367] [info loss: 1.504964]\n",
            "[Epoch 30/200] [Batch 528/938] [D loss: 0.200157] [G loss: 0.312883] [info loss: 1.470429]\n",
            "[Epoch 30/200] [Batch 529/938] [D loss: 0.274595] [G loss: 0.329148] [info loss: 1.490290]\n",
            "[Epoch 30/200] [Batch 530/938] [D loss: 0.227268] [G loss: 0.379036] [info loss: 1.469305]\n",
            "[Epoch 30/200] [Batch 531/938] [D loss: 0.169356] [G loss: 0.192487] [info loss: 1.470973]\n",
            "[Epoch 30/200] [Batch 532/938] [D loss: 0.177575] [G loss: 0.180931] [info loss: 1.470251]\n",
            "[Epoch 30/200] [Batch 533/938] [D loss: 0.169912] [G loss: 0.412276] [info loss: 1.469348]\n",
            "[Epoch 30/200] [Batch 534/938] [D loss: 0.294110] [G loss: 0.269528] [info loss: 1.473108]\n",
            "[Epoch 30/200] [Batch 535/938] [D loss: 0.185723] [G loss: 0.437837] [info loss: 1.475117]\n",
            "[Epoch 30/200] [Batch 536/938] [D loss: 0.266970] [G loss: 0.264656] [info loss: 1.491480]\n",
            "[Epoch 30/200] [Batch 537/938] [D loss: 0.196254] [G loss: 0.308974] [info loss: 1.474272]\n",
            "[Epoch 30/200] [Batch 538/938] [D loss: 0.237870] [G loss: 0.267825] [info loss: 1.469259]\n",
            "[Epoch 30/200] [Batch 539/938] [D loss: 0.203071] [G loss: 0.261846] [info loss: 1.469574]\n",
            "[Epoch 30/200] [Batch 540/938] [D loss: 0.181910] [G loss: 0.458001] [info loss: 1.506890]\n",
            "[Epoch 30/200] [Batch 541/938] [D loss: 0.266533] [G loss: 0.257750] [info loss: 1.487037]\n",
            "[Epoch 30/200] [Batch 542/938] [D loss: 0.304525] [G loss: 0.411616] [info loss: 1.469443]\n",
            "[Epoch 30/200] [Batch 543/938] [D loss: 0.179359] [G loss: 0.279942] [info loss: 1.496504]\n",
            "[Epoch 30/200] [Batch 544/938] [D loss: 0.144250] [G loss: 0.319586] [info loss: 1.494667]\n",
            "[Epoch 30/200] [Batch 545/938] [D loss: 0.227684] [G loss: 0.348385] [info loss: 1.475556]\n",
            "[Epoch 30/200] [Batch 546/938] [D loss: 0.303773] [G loss: 0.291522] [info loss: 1.479617]\n",
            "[Epoch 30/200] [Batch 547/938] [D loss: 0.185731] [G loss: 0.278257] [info loss: 1.468604]\n",
            "[Epoch 30/200] [Batch 548/938] [D loss: 0.167368] [G loss: 0.405222] [info loss: 1.489949]\n",
            "[Epoch 30/200] [Batch 549/938] [D loss: 0.263197] [G loss: 0.355207] [info loss: 1.467962]\n",
            "[Epoch 30/200] [Batch 550/938] [D loss: 0.218795] [G loss: 0.293931] [info loss: 1.471354]\n",
            "[Epoch 30/200] [Batch 551/938] [D loss: 0.228447] [G loss: 0.364504] [info loss: 1.471210]\n",
            "[Epoch 30/200] [Batch 552/938] [D loss: 0.150964] [G loss: 0.372009] [info loss: 1.473538]\n",
            "[Epoch 30/200] [Batch 553/938] [D loss: 0.278122] [G loss: 0.302372] [info loss: 1.495529]\n",
            "[Epoch 30/200] [Batch 554/938] [D loss: 0.235008] [G loss: 0.240860] [info loss: 1.476771]\n",
            "[Epoch 30/200] [Batch 555/938] [D loss: 0.310742] [G loss: 0.306931] [info loss: 1.484609]\n",
            "[Epoch 30/200] [Batch 556/938] [D loss: 0.248674] [G loss: 0.340502] [info loss: 1.469684]\n",
            "[Epoch 30/200] [Batch 557/938] [D loss: 0.278132] [G loss: 0.370198] [info loss: 1.486583]\n",
            "[Epoch 30/200] [Batch 558/938] [D loss: 0.168104] [G loss: 0.242196] [info loss: 1.476682]\n",
            "[Epoch 30/200] [Batch 559/938] [D loss: 0.165697] [G loss: 0.248735] [info loss: 1.486766]\n",
            "[Epoch 30/200] [Batch 560/938] [D loss: 0.277451] [G loss: 0.221160] [info loss: 1.488638]\n",
            "[Epoch 30/200] [Batch 561/938] [D loss: 0.190907] [G loss: 0.538025] [info loss: 1.468963]\n",
            "[Epoch 30/200] [Batch 562/938] [D loss: 0.299967] [G loss: 0.498072] [info loss: 1.490536]\n",
            "[Epoch 30/200] [Batch 563/938] [D loss: 0.162611] [G loss: 0.236112] [info loss: 1.475523]\n",
            "[Epoch 30/200] [Batch 564/938] [D loss: 0.210219] [G loss: 0.216673] [info loss: 1.470100]\n",
            "[Epoch 30/200] [Batch 565/938] [D loss: 0.244857] [G loss: 0.352855] [info loss: 1.477769]\n",
            "[Epoch 30/200] [Batch 566/938] [D loss: 0.267028] [G loss: 0.347956] [info loss: 1.470373]\n",
            "[Epoch 30/200] [Batch 567/938] [D loss: 0.183342] [G loss: 0.258166] [info loss: 1.494011]\n",
            "[Epoch 30/200] [Batch 568/938] [D loss: 0.184659] [G loss: 0.290429] [info loss: 1.484075]\n",
            "[Epoch 30/200] [Batch 569/938] [D loss: 0.263397] [G loss: 0.405181] [info loss: 1.471367]\n",
            "[Epoch 30/200] [Batch 570/938] [D loss: 0.190492] [G loss: 0.229392] [info loss: 1.495873]\n",
            "[Epoch 30/200] [Batch 571/938] [D loss: 0.265357] [G loss: 0.445693] [info loss: 1.471390]\n",
            "[Epoch 30/200] [Batch 572/938] [D loss: 0.198583] [G loss: 0.458435] [info loss: 1.477594]\n",
            "[Epoch 30/200] [Batch 573/938] [D loss: 0.132339] [G loss: 0.319671] [info loss: 1.501211]\n",
            "[Epoch 30/200] [Batch 574/938] [D loss: 0.421248] [G loss: 0.273685] [info loss: 1.490783]\n",
            "[Epoch 30/200] [Batch 575/938] [D loss: 0.222829] [G loss: 0.357602] [info loss: 1.468521]\n",
            "[Epoch 30/200] [Batch 576/938] [D loss: 0.152762] [G loss: 0.255468] [info loss: 1.486598]\n",
            "[Epoch 30/200] [Batch 577/938] [D loss: 0.207830] [G loss: 0.352936] [info loss: 1.499026]\n",
            "[Epoch 30/200] [Batch 578/938] [D loss: 0.220920] [G loss: 0.247680] [info loss: 1.492236]\n",
            "[Epoch 30/200] [Batch 579/938] [D loss: 0.259388] [G loss: 0.575140] [info loss: 1.469878]\n",
            "[Epoch 30/200] [Batch 580/938] [D loss: 0.228975] [G loss: 0.170145] [info loss: 1.476610]\n",
            "[Epoch 30/200] [Batch 581/938] [D loss: 0.288426] [G loss: 0.451002] [info loss: 1.487719]\n",
            "[Epoch 30/200] [Batch 582/938] [D loss: 0.141496] [G loss: 0.441768] [info loss: 1.485007]\n",
            "[Epoch 30/200] [Batch 583/938] [D loss: 0.242621] [G loss: 0.265441] [info loss: 1.488180]\n",
            "[Epoch 30/200] [Batch 584/938] [D loss: 0.273267] [G loss: 0.203604] [info loss: 1.470891]\n",
            "[Epoch 30/200] [Batch 585/938] [D loss: 0.261836] [G loss: 0.194134] [info loss: 1.472023]\n",
            "[Epoch 30/200] [Batch 586/938] [D loss: 0.167951] [G loss: 0.287341] [info loss: 1.488693]\n",
            "[Epoch 30/200] [Batch 587/938] [D loss: 0.141747] [G loss: 0.371317] [info loss: 1.473022]\n",
            "[Epoch 30/200] [Batch 588/938] [D loss: 0.184304] [G loss: 0.575899] [info loss: 1.482783]\n",
            "[Epoch 30/200] [Batch 589/938] [D loss: 0.207642] [G loss: 0.655774] [info loss: 1.468777]\n",
            "[Epoch 30/200] [Batch 590/938] [D loss: 0.315443] [G loss: 0.396131] [info loss: 1.470164]\n",
            "[Epoch 30/200] [Batch 591/938] [D loss: 0.246788] [G loss: 0.247476] [info loss: 1.468072]\n",
            "[Epoch 30/200] [Batch 592/938] [D loss: 0.205253] [G loss: 0.469584] [info loss: 1.467335]\n",
            "[Epoch 30/200] [Batch 593/938] [D loss: 0.231456] [G loss: 0.519952] [info loss: 1.479881]\n",
            "[Epoch 30/200] [Batch 594/938] [D loss: 0.132542] [G loss: 0.319844] [info loss: 1.484274]\n",
            "[Epoch 30/200] [Batch 595/938] [D loss: 0.201040] [G loss: 0.212394] [info loss: 1.469546]\n",
            "[Epoch 30/200] [Batch 596/938] [D loss: 0.370462] [G loss: 0.241619] [info loss: 1.469718]\n",
            "[Epoch 30/200] [Batch 597/938] [D loss: 0.179191] [G loss: 0.339196] [info loss: 1.469445]\n",
            "[Epoch 30/200] [Batch 598/938] [D loss: 0.165483] [G loss: 0.541843] [info loss: 1.489554]\n",
            "[Epoch 30/200] [Batch 599/938] [D loss: 0.212220] [G loss: 0.527095] [info loss: 1.487618]\n",
            "[Epoch 30/200] [Batch 600/938] [D loss: 0.235277] [G loss: 0.274165] [info loss: 1.478985]\n",
            "[Epoch 30/200] [Batch 601/938] [D loss: 0.180777] [G loss: 0.304094] [info loss: 1.471755]\n",
            "[Epoch 30/200] [Batch 602/938] [D loss: 0.265474] [G loss: 0.213075] [info loss: 1.478146]\n",
            "[Epoch 30/200] [Batch 603/938] [D loss: 0.192589] [G loss: 0.259575] [info loss: 1.468801]\n",
            "[Epoch 30/200] [Batch 604/938] [D loss: 0.290092] [G loss: 0.219049] [info loss: 1.476531]\n",
            "[Epoch 30/200] [Batch 605/938] [D loss: 0.337689] [G loss: 0.382326] [info loss: 1.475790]\n",
            "[Epoch 30/200] [Batch 606/938] [D loss: 0.068463] [G loss: 0.365599] [info loss: 1.485985]\n",
            "[Epoch 30/200] [Batch 607/938] [D loss: 0.204824] [G loss: 0.244001] [info loss: 1.472191]\n",
            "[Epoch 30/200] [Batch 608/938] [D loss: 0.174008] [G loss: 0.205274] [info loss: 1.483570]\n",
            "[Epoch 30/200] [Batch 609/938] [D loss: 0.115338] [G loss: 0.281600] [info loss: 1.500784]\n",
            "[Epoch 30/200] [Batch 610/938] [D loss: 0.246221] [G loss: 0.375099] [info loss: 1.486521]\n",
            "[Epoch 30/200] [Batch 611/938] [D loss: 0.176392] [G loss: 0.261092] [info loss: 1.471884]\n",
            "[Epoch 30/200] [Batch 612/938] [D loss: 0.143439] [G loss: 0.292635] [info loss: 1.513275]\n",
            "[Epoch 30/200] [Batch 613/938] [D loss: 0.192464] [G loss: 0.369702] [info loss: 1.469653]\n",
            "[Epoch 30/200] [Batch 614/938] [D loss: 0.183051] [G loss: 0.619568] [info loss: 1.475883]\n",
            "[Epoch 30/200] [Batch 615/938] [D loss: 0.217585] [G loss: 0.419834] [info loss: 1.470191]\n",
            "[Epoch 30/200] [Batch 616/938] [D loss: 0.196682] [G loss: 0.184418] [info loss: 1.467934]\n",
            "[Epoch 30/200] [Batch 617/938] [D loss: 0.174901] [G loss: 0.354192] [info loss: 1.471890]\n",
            "[Epoch 30/200] [Batch 618/938] [D loss: 0.208881] [G loss: 0.512226] [info loss: 1.469737]\n",
            "[Epoch 30/200] [Batch 619/938] [D loss: 0.151686] [G loss: 0.336783] [info loss: 1.477303]\n",
            "[Epoch 30/200] [Batch 620/938] [D loss: 0.209204] [G loss: 0.377102] [info loss: 1.473025]\n",
            "[Epoch 30/200] [Batch 621/938] [D loss: 0.206466] [G loss: 0.326292] [info loss: 1.470765]\n",
            "[Epoch 30/200] [Batch 622/938] [D loss: 0.257063] [G loss: 0.237687] [info loss: 1.471773]\n",
            "[Epoch 30/200] [Batch 623/938] [D loss: 0.168974] [G loss: 0.277489] [info loss: 1.479177]\n",
            "[Epoch 30/200] [Batch 624/938] [D loss: 0.237865] [G loss: 0.342909] [info loss: 1.486005]\n",
            "[Epoch 30/200] [Batch 625/938] [D loss: 0.225850] [G loss: 0.539752] [info loss: 1.471068]\n",
            "[Epoch 30/200] [Batch 626/938] [D loss: 0.242481] [G loss: 0.532575] [info loss: 1.480929]\n",
            "[Epoch 30/200] [Batch 627/938] [D loss: 0.197522] [G loss: 0.349576] [info loss: 1.480030]\n",
            "[Epoch 30/200] [Batch 628/938] [D loss: 0.233700] [G loss: 0.496778] [info loss: 1.472655]\n",
            "[Epoch 30/200] [Batch 629/938] [D loss: 0.167940] [G loss: 0.394058] [info loss: 1.470833]\n",
            "[Epoch 30/200] [Batch 630/938] [D loss: 0.143678] [G loss: 0.333481] [info loss: 1.474458]\n",
            "[Epoch 30/200] [Batch 631/938] [D loss: 0.152142] [G loss: 0.250802] [info loss: 1.470995]\n",
            "[Epoch 30/200] [Batch 632/938] [D loss: 0.291903] [G loss: 0.153788] [info loss: 1.479867]\n",
            "[Epoch 30/200] [Batch 633/938] [D loss: 0.259101] [G loss: 0.558903] [info loss: 1.478061]\n",
            "[Epoch 30/200] [Batch 634/938] [D loss: 0.162726] [G loss: 0.335863] [info loss: 1.479547]\n",
            "[Epoch 30/200] [Batch 635/938] [D loss: 0.210266] [G loss: 0.300979] [info loss: 1.500953]\n",
            "[Epoch 30/200] [Batch 636/938] [D loss: 0.235811] [G loss: 0.150066] [info loss: 1.486751]\n",
            "[Epoch 30/200] [Batch 637/938] [D loss: 0.168185] [G loss: 0.304209] [info loss: 1.469118]\n",
            "[Epoch 30/200] [Batch 638/938] [D loss: 0.264654] [G loss: 0.703868] [info loss: 1.472896]\n",
            "[Epoch 30/200] [Batch 639/938] [D loss: 0.181103] [G loss: 0.364971] [info loss: 1.480466]\n",
            "[Epoch 30/200] [Batch 640/938] [D loss: 0.219599] [G loss: 0.364157] [info loss: 1.472936]\n",
            "[Epoch 30/200] [Batch 641/938] [D loss: 0.146884] [G loss: 0.209891] [info loss: 1.481928]\n",
            "[Epoch 30/200] [Batch 642/938] [D loss: 0.194291] [G loss: 0.055545] [info loss: 1.470876]\n",
            "[Epoch 30/200] [Batch 643/938] [D loss: 0.182712] [G loss: 0.304883] [info loss: 1.483080]\n",
            "[Epoch 30/200] [Batch 644/938] [D loss: 0.209280] [G loss: 0.490081] [info loss: 1.485002]\n",
            "[Epoch 30/200] [Batch 645/938] [D loss: 0.324977] [G loss: 0.278293] [info loss: 1.485200]\n",
            "[Epoch 30/200] [Batch 646/938] [D loss: 0.313850] [G loss: 0.363708] [info loss: 1.477065]\n",
            "[Epoch 30/200] [Batch 647/938] [D loss: 0.145862] [G loss: 0.353290] [info loss: 1.469259]\n",
            "[Epoch 30/200] [Batch 648/938] [D loss: 0.184314] [G loss: 0.264648] [info loss: 1.472174]\n",
            "[Epoch 30/200] [Batch 649/938] [D loss: 0.237100] [G loss: 0.198979] [info loss: 1.472456]\n",
            "[Epoch 30/200] [Batch 650/938] [D loss: 0.174279] [G loss: 0.522917] [info loss: 1.529832]\n",
            "[Epoch 30/200] [Batch 651/938] [D loss: 0.227788] [G loss: 0.279896] [info loss: 1.469498]\n",
            "[Epoch 30/200] [Batch 652/938] [D loss: 0.331008] [G loss: 0.626657] [info loss: 1.469775]\n",
            "[Epoch 30/200] [Batch 653/938] [D loss: 0.272662] [G loss: 0.335322] [info loss: 1.470789]\n",
            "[Epoch 30/200] [Batch 654/938] [D loss: 0.155503] [G loss: 0.273907] [info loss: 1.471652]\n",
            "[Epoch 30/200] [Batch 655/938] [D loss: 0.188855] [G loss: 0.279018] [info loss: 1.468976]\n",
            "[Epoch 30/200] [Batch 656/938] [D loss: 0.243408] [G loss: 0.231509] [info loss: 1.484168]\n",
            "[Epoch 30/200] [Batch 657/938] [D loss: 0.158241] [G loss: 0.162453] [info loss: 1.479567]\n",
            "[Epoch 30/200] [Batch 658/938] [D loss: 0.209383] [G loss: 0.453875] [info loss: 1.485787]\n",
            "[Epoch 30/200] [Batch 659/938] [D loss: 0.266714] [G loss: 0.468978] [info loss: 1.478196]\n",
            "[Epoch 30/200] [Batch 660/938] [D loss: 0.320903] [G loss: 0.240028] [info loss: 1.470796]\n",
            "[Epoch 30/200] [Batch 661/938] [D loss: 0.213169] [G loss: 0.497063] [info loss: 1.470849]\n",
            "[Epoch 30/200] [Batch 662/938] [D loss: 0.107978] [G loss: 0.510202] [info loss: 1.473416]\n",
            "[Epoch 30/200] [Batch 663/938] [D loss: 0.230161] [G loss: 0.279777] [info loss: 1.480479]\n",
            "[Epoch 30/200] [Batch 664/938] [D loss: 0.169374] [G loss: 0.557202] [info loss: 1.471494]\n",
            "[Epoch 30/200] [Batch 665/938] [D loss: 0.300872] [G loss: 0.181765] [info loss: 1.469382]\n",
            "[Epoch 30/200] [Batch 666/938] [D loss: 0.221585] [G loss: 0.332902] [info loss: 1.518946]\n",
            "[Epoch 30/200] [Batch 667/938] [D loss: 0.236170] [G loss: 0.283605] [info loss: 1.495724]\n",
            "[Epoch 30/200] [Batch 668/938] [D loss: 0.224972] [G loss: 0.456207] [info loss: 1.481671]\n",
            "[Epoch 30/200] [Batch 669/938] [D loss: 0.229746] [G loss: 0.358242] [info loss: 1.471016]\n",
            "[Epoch 30/200] [Batch 670/938] [D loss: 0.214858] [G loss: 0.241623] [info loss: 1.485472]\n",
            "[Epoch 30/200] [Batch 671/938] [D loss: 0.278310] [G loss: 0.252876] [info loss: 1.468387]\n",
            "[Epoch 30/200] [Batch 672/938] [D loss: 0.277418] [G loss: 0.137920] [info loss: 1.469098]\n",
            "[Epoch 30/200] [Batch 673/938] [D loss: 0.290690] [G loss: 0.269123] [info loss: 1.488093]\n",
            "[Epoch 30/200] [Batch 674/938] [D loss: 0.136007] [G loss: 0.277699] [info loss: 1.528266]\n",
            "[Epoch 30/200] [Batch 675/938] [D loss: 0.267235] [G loss: 0.269473] [info loss: 1.473016]\n",
            "[Epoch 30/200] [Batch 676/938] [D loss: 0.224135] [G loss: 0.218721] [info loss: 1.485826]\n",
            "[Epoch 30/200] [Batch 677/938] [D loss: 0.247798] [G loss: 0.377186] [info loss: 1.471623]\n",
            "[Epoch 30/200] [Batch 678/938] [D loss: 0.215948] [G loss: 0.263514] [info loss: 1.470356]\n",
            "[Epoch 30/200] [Batch 679/938] [D loss: 0.137372] [G loss: 0.366749] [info loss: 1.480804]\n",
            "[Epoch 30/200] [Batch 680/938] [D loss: 0.283350] [G loss: 0.346989] [info loss: 1.476930]\n",
            "[Epoch 30/200] [Batch 681/938] [D loss: 0.270861] [G loss: 0.350457] [info loss: 1.474201]\n",
            "[Epoch 30/200] [Batch 682/938] [D loss: 0.199299] [G loss: 0.241832] [info loss: 1.490593]\n",
            "[Epoch 30/200] [Batch 683/938] [D loss: 0.294920] [G loss: 0.183498] [info loss: 1.470716]\n",
            "[Epoch 30/200] [Batch 684/938] [D loss: 0.320725] [G loss: 0.368964] [info loss: 1.484409]\n",
            "[Epoch 30/200] [Batch 685/938] [D loss: 0.247824] [G loss: 0.315986] [info loss: 1.476585]\n",
            "[Epoch 30/200] [Batch 686/938] [D loss: 0.153564] [G loss: 0.492413] [info loss: 1.498953]\n",
            "[Epoch 30/200] [Batch 687/938] [D loss: 0.130368] [G loss: 0.347767] [info loss: 1.471132]\n",
            "[Epoch 30/200] [Batch 688/938] [D loss: 0.156628] [G loss: 0.375613] [info loss: 1.470078]\n",
            "[Epoch 30/200] [Batch 689/938] [D loss: 0.227091] [G loss: 0.549088] [info loss: 1.472578]\n",
            "[Epoch 30/200] [Batch 690/938] [D loss: 0.211879] [G loss: 0.194530] [info loss: 1.472452]\n",
            "[Epoch 30/200] [Batch 691/938] [D loss: 0.172530] [G loss: 0.406206] [info loss: 1.468830]\n",
            "[Epoch 30/200] [Batch 692/938] [D loss: 0.248263] [G loss: 0.381629] [info loss: 1.485084]\n",
            "[Epoch 30/200] [Batch 693/938] [D loss: 0.286851] [G loss: 0.279701] [info loss: 1.470603]\n",
            "[Epoch 30/200] [Batch 694/938] [D loss: 0.190639] [G loss: 0.395982] [info loss: 1.478809]\n",
            "[Epoch 30/200] [Batch 695/938] [D loss: 0.131331] [G loss: 0.443499] [info loss: 1.495004]\n",
            "[Epoch 30/200] [Batch 696/938] [D loss: 0.279955] [G loss: 0.387744] [info loss: 1.481527]\n",
            "[Epoch 30/200] [Batch 697/938] [D loss: 0.199069] [G loss: 0.234625] [info loss: 1.488058]\n",
            "[Epoch 30/200] [Batch 698/938] [D loss: 0.229169] [G loss: 0.542834] [info loss: 1.478829]\n",
            "[Epoch 30/200] [Batch 699/938] [D loss: 0.316119] [G loss: 0.524829] [info loss: 1.473579]\n",
            "[Epoch 30/200] [Batch 700/938] [D loss: 0.126347] [G loss: 0.409467] [info loss: 1.491718]\n",
            "[Epoch 30/200] [Batch 701/938] [D loss: 0.317477] [G loss: 0.162822] [info loss: 1.493601]\n",
            "[Epoch 30/200] [Batch 702/938] [D loss: 0.181697] [G loss: 0.319637] [info loss: 1.484174]\n",
            "[Epoch 30/200] [Batch 703/938] [D loss: 0.297713] [G loss: 0.246106] [info loss: 1.473221]\n",
            "[Epoch 30/200] [Batch 704/938] [D loss: 0.161068] [G loss: 0.208408] [info loss: 1.468622]\n",
            "[Epoch 30/200] [Batch 705/938] [D loss: 0.264008] [G loss: 0.350730] [info loss: 1.471889]\n",
            "[Epoch 30/200] [Batch 706/938] [D loss: 0.279361] [G loss: 0.290008] [info loss: 1.471171]\n",
            "[Epoch 30/200] [Batch 707/938] [D loss: 0.343149] [G loss: 0.189554] [info loss: 1.472751]\n",
            "[Epoch 30/200] [Batch 708/938] [D loss: 0.216938] [G loss: 0.448590] [info loss: 1.470563]\n",
            "[Epoch 30/200] [Batch 709/938] [D loss: 0.190664] [G loss: 0.322912] [info loss: 1.474112]\n",
            "[Epoch 30/200] [Batch 710/938] [D loss: 0.185147] [G loss: 0.295676] [info loss: 1.472064]\n",
            "[Epoch 30/200] [Batch 711/938] [D loss: 0.274532] [G loss: 0.347170] [info loss: 1.491431]\n",
            "[Epoch 30/200] [Batch 712/938] [D loss: 0.156108] [G loss: 0.355371] [info loss: 1.484546]\n",
            "[Epoch 30/200] [Batch 713/938] [D loss: 0.201093] [G loss: 0.203306] [info loss: 1.498952]\n",
            "[Epoch 30/200] [Batch 714/938] [D loss: 0.252409] [G loss: 0.469196] [info loss: 1.469847]\n",
            "[Epoch 30/200] [Batch 715/938] [D loss: 0.197049] [G loss: 0.362881] [info loss: 1.475587]\n",
            "[Epoch 30/200] [Batch 716/938] [D loss: 0.328473] [G loss: 0.550866] [info loss: 1.487606]\n",
            "[Epoch 30/200] [Batch 717/938] [D loss: 0.160726] [G loss: 0.355419] [info loss: 1.490160]\n",
            "[Epoch 30/200] [Batch 718/938] [D loss: 0.169349] [G loss: 0.507108] [info loss: 1.471426]\n",
            "[Epoch 30/200] [Batch 719/938] [D loss: 0.222195] [G loss: 0.255359] [info loss: 1.470183]\n",
            "[Epoch 30/200] [Batch 720/938] [D loss: 0.196336] [G loss: 0.190771] [info loss: 1.478732]\n",
            "[Epoch 30/200] [Batch 721/938] [D loss: 0.144507] [G loss: 0.309927] [info loss: 1.489852]\n",
            "[Epoch 30/200] [Batch 722/938] [D loss: 0.110599] [G loss: 0.439837] [info loss: 1.481756]\n",
            "[Epoch 30/200] [Batch 723/938] [D loss: 0.175387] [G loss: 0.488853] [info loss: 1.480140]\n",
            "[Epoch 30/200] [Batch 724/938] [D loss: 0.181213] [G loss: 0.758428] [info loss: 1.500071]\n",
            "[Epoch 30/200] [Batch 725/938] [D loss: 0.197885] [G loss: 0.326529] [info loss: 1.471434]\n",
            "[Epoch 30/200] [Batch 726/938] [D loss: 0.232324] [G loss: 0.379520] [info loss: 1.472860]\n",
            "[Epoch 30/200] [Batch 727/938] [D loss: 0.302758] [G loss: 0.273650] [info loss: 1.470853]\n",
            "[Epoch 30/200] [Batch 728/938] [D loss: 0.119860] [G loss: 0.392519] [info loss: 1.468897]\n",
            "[Epoch 30/200] [Batch 729/938] [D loss: 0.243198] [G loss: 0.293401] [info loss: 1.476378]\n",
            "[Epoch 30/200] [Batch 730/938] [D loss: 0.403195] [G loss: 0.411813] [info loss: 1.475150]\n",
            "[Epoch 30/200] [Batch 731/938] [D loss: 0.191837] [G loss: 0.285437] [info loss: 1.472281]\n",
            "[Epoch 30/200] [Batch 732/938] [D loss: 0.211554] [G loss: 0.309140] [info loss: 1.470866]\n",
            "[Epoch 30/200] [Batch 733/938] [D loss: 0.196881] [G loss: 0.188049] [info loss: 1.483711]\n",
            "[Epoch 30/200] [Batch 734/938] [D loss: 0.289997] [G loss: 0.103892] [info loss: 1.500637]\n",
            "[Epoch 30/200] [Batch 735/938] [D loss: 0.297339] [G loss: 0.327387] [info loss: 1.471723]\n",
            "[Epoch 30/200] [Batch 736/938] [D loss: 0.174124] [G loss: 0.351116] [info loss: 1.481387]\n",
            "[Epoch 30/200] [Batch 737/938] [D loss: 0.181557] [G loss: 0.458800] [info loss: 1.470229]\n",
            "[Epoch 30/200] [Batch 738/938] [D loss: 0.235955] [G loss: 0.404060] [info loss: 1.472012]\n",
            "[Epoch 30/200] [Batch 739/938] [D loss: 0.284835] [G loss: 0.351369] [info loss: 1.502234]\n",
            "[Epoch 30/200] [Batch 740/938] [D loss: 0.179968] [G loss: 0.490721] [info loss: 1.471689]\n",
            "[Epoch 30/200] [Batch 741/938] [D loss: 0.166615] [G loss: 0.297980] [info loss: 1.502258]\n",
            "[Epoch 30/200] [Batch 742/938] [D loss: 0.154883] [G loss: 0.260458] [info loss: 1.471157]\n",
            "[Epoch 30/200] [Batch 743/938] [D loss: 0.156373] [G loss: 0.383159] [info loss: 1.485040]\n",
            "[Epoch 30/200] [Batch 744/938] [D loss: 0.290550] [G loss: 0.358387] [info loss: 1.479877]\n",
            "[Epoch 30/200] [Batch 745/938] [D loss: 0.221742] [G loss: 0.164334] [info loss: 1.472417]\n",
            "[Epoch 30/200] [Batch 746/938] [D loss: 0.132472] [G loss: 0.275147] [info loss: 1.469384]\n",
            "[Epoch 30/200] [Batch 747/938] [D loss: 0.134328] [G loss: 0.203414] [info loss: 1.511558]\n",
            "[Epoch 30/200] [Batch 748/938] [D loss: 0.275642] [G loss: 0.058635] [info loss: 1.468930]\n",
            "[Epoch 30/200] [Batch 749/938] [D loss: 0.219622] [G loss: 0.105056] [info loss: 1.468323]\n",
            "[Epoch 30/200] [Batch 750/938] [D loss: 0.261364] [G loss: 0.400996] [info loss: 1.474247]\n",
            "[Epoch 30/200] [Batch 751/938] [D loss: 0.347806] [G loss: 0.400524] [info loss: 1.469757]\n",
            "[Epoch 30/200] [Batch 752/938] [D loss: 0.206187] [G loss: 0.207530] [info loss: 1.470592]\n",
            "[Epoch 30/200] [Batch 753/938] [D loss: 0.240464] [G loss: 0.263588] [info loss: 1.493565]\n",
            "[Epoch 30/200] [Batch 754/938] [D loss: 0.241077] [G loss: 0.064652] [info loss: 1.469471]\n",
            "[Epoch 30/200] [Batch 755/938] [D loss: 0.277024] [G loss: 0.147786] [info loss: 1.488553]\n",
            "[Epoch 30/200] [Batch 756/938] [D loss: 0.159859] [G loss: 0.520131] [info loss: 1.470894]\n",
            "[Epoch 30/200] [Batch 757/938] [D loss: 0.270696] [G loss: 0.399144] [info loss: 1.469538]\n",
            "[Epoch 30/200] [Batch 758/938] [D loss: 0.283031] [G loss: 0.294121] [info loss: 1.484320]\n",
            "[Epoch 30/200] [Batch 759/938] [D loss: 0.212666] [G loss: 0.289457] [info loss: 1.502966]\n",
            "[Epoch 30/200] [Batch 760/938] [D loss: 0.155925] [G loss: 0.247034] [info loss: 1.470387]\n",
            "[Epoch 30/200] [Batch 761/938] [D loss: 0.220948] [G loss: 0.144269] [info loss: 1.474521]\n",
            "[Epoch 30/200] [Batch 762/938] [D loss: 0.147744] [G loss: 0.434741] [info loss: 1.473492]\n",
            "[Epoch 30/200] [Batch 763/938] [D loss: 0.221729] [G loss: 0.344003] [info loss: 1.472032]\n",
            "[Epoch 30/200] [Batch 764/938] [D loss: 0.254025] [G loss: 0.331138] [info loss: 1.472077]\n",
            "[Epoch 30/200] [Batch 765/938] [D loss: 0.267562] [G loss: 0.160579] [info loss: 1.488601]\n",
            "[Epoch 30/200] [Batch 766/938] [D loss: 0.300372] [G loss: 0.277956] [info loss: 1.485533]\n",
            "[Epoch 30/200] [Batch 767/938] [D loss: 0.181017] [G loss: 0.517227] [info loss: 1.472157]\n",
            "[Epoch 30/200] [Batch 768/938] [D loss: 0.256180] [G loss: 0.342320] [info loss: 1.473323]\n",
            "[Epoch 30/200] [Batch 769/938] [D loss: 0.259838] [G loss: 0.224705] [info loss: 1.481045]\n",
            "[Epoch 30/200] [Batch 770/938] [D loss: 0.208275] [G loss: 0.178479] [info loss: 1.470808]\n",
            "[Epoch 30/200] [Batch 771/938] [D loss: 0.231572] [G loss: 0.197838] [info loss: 1.471739]\n",
            "[Epoch 30/200] [Batch 772/938] [D loss: 0.130680] [G loss: 0.200731] [info loss: 1.470766]\n",
            "[Epoch 30/200] [Batch 773/938] [D loss: 0.171482] [G loss: 0.458227] [info loss: 1.470659]\n",
            "[Epoch 30/200] [Batch 774/938] [D loss: 0.152203] [G loss: 0.594797] [info loss: 1.485215]\n",
            "[Epoch 30/200] [Batch 775/938] [D loss: 0.264761] [G loss: 0.534414] [info loss: 1.483800]\n",
            "[Epoch 30/200] [Batch 776/938] [D loss: 0.144727] [G loss: 0.459469] [info loss: 1.472738]\n",
            "[Epoch 30/200] [Batch 777/938] [D loss: 0.255426] [G loss: 0.325835] [info loss: 1.489136]\n",
            "[Epoch 30/200] [Batch 778/938] [D loss: 0.230320] [G loss: 0.194370] [info loss: 1.468536]\n",
            "[Epoch 30/200] [Batch 779/938] [D loss: 0.167696] [G loss: 0.124541] [info loss: 1.478941]\n",
            "[Epoch 30/200] [Batch 780/938] [D loss: 0.163178] [G loss: 0.104502] [info loss: 1.468146]\n",
            "[Epoch 30/200] [Batch 781/938] [D loss: 0.233572] [G loss: 0.210170] [info loss: 1.473245]\n",
            "[Epoch 30/200] [Batch 782/938] [D loss: 0.244598] [G loss: 0.194867] [info loss: 1.476242]\n",
            "[Epoch 30/200] [Batch 783/938] [D loss: 0.236446] [G loss: 0.230664] [info loss: 1.474132]\n",
            "[Epoch 30/200] [Batch 784/938] [D loss: 0.236112] [G loss: 0.242182] [info loss: 1.488198]\n",
            "[Epoch 30/200] [Batch 785/938] [D loss: 0.140090] [G loss: 0.206098] [info loss: 1.482173]\n",
            "[Epoch 30/200] [Batch 786/938] [D loss: 0.207802] [G loss: 0.331528] [info loss: 1.471753]\n",
            "[Epoch 30/200] [Batch 787/938] [D loss: 0.306280] [G loss: 0.348374] [info loss: 1.471457]\n",
            "[Epoch 30/200] [Batch 788/938] [D loss: 0.225486] [G loss: 0.511287] [info loss: 1.484777]\n",
            "[Epoch 30/200] [Batch 789/938] [D loss: 0.201196] [G loss: 0.489792] [info loss: 1.486823]\n",
            "[Epoch 30/200] [Batch 790/938] [D loss: 0.239473] [G loss: 0.236328] [info loss: 1.488611]\n",
            "[Epoch 30/200] [Batch 791/938] [D loss: 0.225954] [G loss: 0.255288] [info loss: 1.497779]\n",
            "[Epoch 30/200] [Batch 792/938] [D loss: 0.349452] [G loss: 0.402535] [info loss: 1.482210]\n",
            "[Epoch 30/200] [Batch 793/938] [D loss: 0.294914] [G loss: 0.524068] [info loss: 1.493096]\n",
            "[Epoch 30/200] [Batch 794/938] [D loss: 0.349658] [G loss: 0.253606] [info loss: 1.470484]\n",
            "[Epoch 30/200] [Batch 795/938] [D loss: 0.297172] [G loss: 0.207970] [info loss: 1.470836]\n",
            "[Epoch 30/200] [Batch 796/938] [D loss: 0.145536] [G loss: 0.242219] [info loss: 1.474995]\n",
            "[Epoch 30/200] [Batch 797/938] [D loss: 0.246144] [G loss: 0.291736] [info loss: 1.497510]\n",
            "[Epoch 30/200] [Batch 798/938] [D loss: 0.211472] [G loss: 0.359783] [info loss: 1.484322]\n",
            "[Epoch 30/200] [Batch 799/938] [D loss: 0.155429] [G loss: 0.302525] [info loss: 1.491710]\n",
            "[Epoch 30/200] [Batch 800/938] [D loss: 0.227669] [G loss: 0.252767] [info loss: 1.475070]\n",
            "[Epoch 30/200] [Batch 801/938] [D loss: 0.286594] [G loss: 0.236318] [info loss: 1.497171]\n",
            "[Epoch 30/200] [Batch 802/938] [D loss: 0.296081] [G loss: 0.389925] [info loss: 1.473826]\n",
            "[Epoch 30/200] [Batch 803/938] [D loss: 0.155637] [G loss: 0.291037] [info loss: 1.488692]\n",
            "[Epoch 30/200] [Batch 804/938] [D loss: 0.180054] [G loss: 0.347773] [info loss: 1.487101]\n",
            "[Epoch 30/200] [Batch 805/938] [D loss: 0.182461] [G loss: 0.229132] [info loss: 1.486962]\n",
            "[Epoch 30/200] [Batch 806/938] [D loss: 0.262297] [G loss: 0.455504] [info loss: 1.482778]\n",
            "[Epoch 30/200] [Batch 807/938] [D loss: 0.205834] [G loss: 0.367231] [info loss: 1.470827]\n",
            "[Epoch 30/200] [Batch 808/938] [D loss: 0.153894] [G loss: 0.292781] [info loss: 1.468731]\n",
            "[Epoch 30/200] [Batch 809/938] [D loss: 0.170110] [G loss: 0.220944] [info loss: 1.468650]\n",
            "[Epoch 30/200] [Batch 810/938] [D loss: 0.137210] [G loss: 0.518504] [info loss: 1.469149]\n",
            "[Epoch 30/200] [Batch 811/938] [D loss: 0.227192] [G loss: 0.238716] [info loss: 1.472661]\n",
            "[Epoch 30/200] [Batch 812/938] [D loss: 0.350618] [G loss: 0.498047] [info loss: 1.480424]\n",
            "[Epoch 30/200] [Batch 813/938] [D loss: 0.201622] [G loss: 0.156456] [info loss: 1.472176]\n",
            "[Epoch 30/200] [Batch 814/938] [D loss: 0.236619] [G loss: 0.328150] [info loss: 1.470743]\n",
            "[Epoch 30/200] [Batch 815/938] [D loss: 0.071294] [G loss: 0.443487] [info loss: 1.468075]\n",
            "[Epoch 30/200] [Batch 816/938] [D loss: 0.254118] [G loss: 0.316215] [info loss: 1.487146]\n",
            "[Epoch 30/200] [Batch 817/938] [D loss: 0.219917] [G loss: 0.362365] [info loss: 1.471687]\n",
            "[Epoch 30/200] [Batch 818/938] [D loss: 0.267619] [G loss: 0.229325] [info loss: 1.472921]\n",
            "[Epoch 30/200] [Batch 819/938] [D loss: 0.174956] [G loss: 0.233233] [info loss: 1.485880]\n",
            "[Epoch 30/200] [Batch 820/938] [D loss: 0.295745] [G loss: 0.419114] [info loss: 1.469407]\n",
            "[Epoch 30/200] [Batch 821/938] [D loss: 0.110428] [G loss: 0.406253] [info loss: 1.483614]\n",
            "[Epoch 30/200] [Batch 822/938] [D loss: 0.181170] [G loss: 0.293119] [info loss: 1.474630]\n",
            "[Epoch 30/200] [Batch 823/938] [D loss: 0.354078] [G loss: 0.517028] [info loss: 1.499217]\n",
            "[Epoch 30/200] [Batch 824/938] [D loss: 0.253338] [G loss: 0.400243] [info loss: 1.516165]\n",
            "[Epoch 30/200] [Batch 825/938] [D loss: 0.241332] [G loss: 0.311074] [info loss: 1.484406]\n",
            "[Epoch 30/200] [Batch 826/938] [D loss: 0.145582] [G loss: 0.233166] [info loss: 1.476291]\n",
            "[Epoch 30/200] [Batch 827/938] [D loss: 0.290394] [G loss: 0.242034] [info loss: 1.485873]\n",
            "[Epoch 30/200] [Batch 828/938] [D loss: 0.121085] [G loss: 0.403540] [info loss: 1.499168]\n",
            "[Epoch 30/200] [Batch 829/938] [D loss: 0.219088] [G loss: 0.143384] [info loss: 1.473332]\n",
            "[Epoch 30/200] [Batch 830/938] [D loss: 0.208881] [G loss: 0.340307] [info loss: 1.488430]\n",
            "[Epoch 30/200] [Batch 831/938] [D loss: 0.238520] [G loss: 0.278559] [info loss: 1.479947]\n",
            "[Epoch 30/200] [Batch 832/938] [D loss: 0.242438] [G loss: 0.566736] [info loss: 1.476829]\n",
            "[Epoch 30/200] [Batch 833/938] [D loss: 0.186910] [G loss: 0.335196] [info loss: 1.471956]\n",
            "[Epoch 30/200] [Batch 834/938] [D loss: 0.220655] [G loss: 0.370796] [info loss: 1.473208]\n",
            "[Epoch 30/200] [Batch 835/938] [D loss: 0.155107] [G loss: 0.225956] [info loss: 1.470639]\n",
            "[Epoch 30/200] [Batch 836/938] [D loss: 0.119247] [G loss: 0.215293] [info loss: 1.482117]\n",
            "[Epoch 30/200] [Batch 837/938] [D loss: 0.154427] [G loss: 0.331407] [info loss: 1.486851]\n",
            "[Epoch 30/200] [Batch 838/938] [D loss: 0.154425] [G loss: 0.384719] [info loss: 1.472756]\n",
            "[Epoch 30/200] [Batch 839/938] [D loss: 0.234409] [G loss: 0.334711] [info loss: 1.485226]\n",
            "[Epoch 30/200] [Batch 840/938] [D loss: 0.237793] [G loss: 0.412908] [info loss: 1.471780]\n",
            "[Epoch 30/200] [Batch 841/938] [D loss: 0.200848] [G loss: 0.294749] [info loss: 1.471333]\n",
            "[Epoch 30/200] [Batch 842/938] [D loss: 0.184131] [G loss: 0.239482] [info loss: 1.485364]\n",
            "[Epoch 30/200] [Batch 843/938] [D loss: 0.229741] [G loss: 0.491408] [info loss: 1.474646]\n",
            "[Epoch 30/200] [Batch 844/938] [D loss: 0.235365] [G loss: 0.274324] [info loss: 1.483183]\n",
            "[Epoch 30/200] [Batch 845/938] [D loss: 0.231338] [G loss: 0.521210] [info loss: 1.470292]\n",
            "[Epoch 30/200] [Batch 846/938] [D loss: 0.235142] [G loss: 0.269518] [info loss: 1.491559]\n",
            "[Epoch 30/200] [Batch 847/938] [D loss: 0.179327] [G loss: 0.399843] [info loss: 1.479869]\n",
            "[Epoch 30/200] [Batch 848/938] [D loss: 0.245879] [G loss: 0.333961] [info loss: 1.472580]\n",
            "[Epoch 30/200] [Batch 849/938] [D loss: 0.244346] [G loss: 0.475113] [info loss: 1.469618]\n",
            "[Epoch 30/200] [Batch 850/938] [D loss: 0.187429] [G loss: 0.259118] [info loss: 1.469706]\n",
            "[Epoch 30/200] [Batch 851/938] [D loss: 0.181639] [G loss: 0.314167] [info loss: 1.520321]\n",
            "[Epoch 30/200] [Batch 852/938] [D loss: 0.176069] [G loss: 0.366324] [info loss: 1.469230]\n",
            "[Epoch 30/200] [Batch 853/938] [D loss: 0.218563] [G loss: 0.356948] [info loss: 1.486859]\n",
            "[Epoch 30/200] [Batch 854/938] [D loss: 0.262416] [G loss: 0.557005] [info loss: 1.484691]\n",
            "[Epoch 30/200] [Batch 855/938] [D loss: 0.196215] [G loss: 0.178051] [info loss: 1.485685]\n",
            "[Epoch 30/200] [Batch 856/938] [D loss: 0.161765] [G loss: 0.234256] [info loss: 1.490587]\n",
            "[Epoch 30/200] [Batch 857/938] [D loss: 0.236903] [G loss: 0.178001] [info loss: 1.472132]\n",
            "[Epoch 30/200] [Batch 858/938] [D loss: 0.226369] [G loss: 0.532776] [info loss: 1.472293]\n",
            "[Epoch 30/200] [Batch 859/938] [D loss: 0.266115] [G loss: 0.230336] [info loss: 1.505339]\n",
            "[Epoch 30/200] [Batch 860/938] [D loss: 0.316217] [G loss: 0.518374] [info loss: 1.470590]\n",
            "[Epoch 30/200] [Batch 861/938] [D loss: 0.224944] [G loss: 0.267214] [info loss: 1.484654]\n",
            "[Epoch 30/200] [Batch 862/938] [D loss: 0.220709] [G loss: 0.158636] [info loss: 1.471423]\n",
            "[Epoch 30/200] [Batch 863/938] [D loss: 0.170670] [G loss: 0.292984] [info loss: 1.470490]\n",
            "[Epoch 30/200] [Batch 864/938] [D loss: 0.260943] [G loss: 0.179615] [info loss: 1.474687]\n",
            "[Epoch 30/200] [Batch 865/938] [D loss: 0.215292] [G loss: 0.394322] [info loss: 1.468962]\n",
            "[Epoch 30/200] [Batch 866/938] [D loss: 0.260911] [G loss: 0.518073] [info loss: 1.471853]\n",
            "[Epoch 30/200] [Batch 867/938] [D loss: 0.235000] [G loss: 0.480919] [info loss: 1.482054]\n",
            "[Epoch 30/200] [Batch 868/938] [D loss: 0.245594] [G loss: 0.291429] [info loss: 1.468784]\n",
            "[Epoch 30/200] [Batch 869/938] [D loss: 0.330726] [G loss: 0.169970] [info loss: 1.469855]\n",
            "[Epoch 30/200] [Batch 870/938] [D loss: 0.156854] [G loss: 0.367019] [info loss: 1.492849]\n",
            "[Epoch 30/200] [Batch 871/938] [D loss: 0.178675] [G loss: 0.237637] [info loss: 1.469163]\n",
            "[Epoch 30/200] [Batch 872/938] [D loss: 0.199152] [G loss: 0.340194] [info loss: 1.485175]\n",
            "[Epoch 30/200] [Batch 873/938] [D loss: 0.367751] [G loss: 0.154634] [info loss: 1.486150]\n",
            "[Epoch 30/200] [Batch 874/938] [D loss: 0.233783] [G loss: 0.271282] [info loss: 1.472450]\n",
            "[Epoch 30/200] [Batch 875/938] [D loss: 0.232211] [G loss: 0.430382] [info loss: 1.492060]\n",
            "[Epoch 30/200] [Batch 876/938] [D loss: 0.265889] [G loss: 0.331814] [info loss: 1.477443]\n",
            "[Epoch 30/200] [Batch 877/938] [D loss: 0.299603] [G loss: 0.243782] [info loss: 1.473616]\n",
            "[Epoch 30/200] [Batch 878/938] [D loss: 0.195816] [G loss: 0.127345] [info loss: 1.478917]\n",
            "[Epoch 30/200] [Batch 879/938] [D loss: 0.160372] [G loss: 0.300470] [info loss: 1.469563]\n",
            "[Epoch 30/200] [Batch 880/938] [D loss: 0.313509] [G loss: 0.253013] [info loss: 1.471566]\n",
            "[Epoch 30/200] [Batch 881/938] [D loss: 0.100998] [G loss: 0.356292] [info loss: 1.470334]\n",
            "[Epoch 30/200] [Batch 882/938] [D loss: 0.271953] [G loss: 0.154591] [info loss: 1.472644]\n",
            "[Epoch 30/200] [Batch 883/938] [D loss: 0.272189] [G loss: 0.215478] [info loss: 1.468788]\n",
            "[Epoch 30/200] [Batch 884/938] [D loss: 0.293302] [G loss: 0.448658] [info loss: 1.476436]\n",
            "[Epoch 30/200] [Batch 885/938] [D loss: 0.133902] [G loss: 0.217251] [info loss: 1.469824]\n",
            "[Epoch 30/200] [Batch 886/938] [D loss: 0.178404] [G loss: 0.258946] [info loss: 1.481026]\n",
            "[Epoch 30/200] [Batch 887/938] [D loss: 0.204460] [G loss: 0.505415] [info loss: 1.505123]\n",
            "[Epoch 30/200] [Batch 888/938] [D loss: 0.200214] [G loss: 0.377265] [info loss: 1.474745]\n",
            "[Epoch 30/200] [Batch 889/938] [D loss: 0.147674] [G loss: 0.456719] [info loss: 1.486898]\n",
            "[Epoch 30/200] [Batch 890/938] [D loss: 0.305277] [G loss: 0.499450] [info loss: 1.469445]\n",
            "[Epoch 30/200] [Batch 891/938] [D loss: 0.202335] [G loss: 0.329689] [info loss: 1.487666]\n",
            "[Epoch 30/200] [Batch 892/938] [D loss: 0.188489] [G loss: 0.543121] [info loss: 1.484569]\n",
            "[Epoch 30/200] [Batch 893/938] [D loss: 0.171850] [G loss: 0.448801] [info loss: 1.476928]\n",
            "[Epoch 30/200] [Batch 894/938] [D loss: 0.111291] [G loss: 0.243805] [info loss: 1.486405]\n",
            "[Epoch 30/200] [Batch 895/938] [D loss: 0.110887] [G loss: 0.149082] [info loss: 1.473159]\n",
            "[Epoch 30/200] [Batch 896/938] [D loss: 0.190652] [G loss: 0.259568] [info loss: 1.478941]\n",
            "[Epoch 30/200] [Batch 897/938] [D loss: 0.148443] [G loss: 0.175839] [info loss: 1.470210]\n",
            "[Epoch 30/200] [Batch 898/938] [D loss: 0.187815] [G loss: 0.263642] [info loss: 1.469850]\n",
            "[Epoch 30/200] [Batch 899/938] [D loss: 0.197765] [G loss: 0.236965] [info loss: 1.478642]\n",
            "[Epoch 30/200] [Batch 900/938] [D loss: 0.218891] [G loss: 0.343011] [info loss: 1.478416]\n",
            "[Epoch 30/200] [Batch 901/938] [D loss: 0.200954] [G loss: 0.492944] [info loss: 1.480909]\n",
            "[Epoch 30/200] [Batch 902/938] [D loss: 0.136463] [G loss: 0.190582] [info loss: 1.472948]\n",
            "[Epoch 30/200] [Batch 903/938] [D loss: 0.180799] [G loss: 0.363613] [info loss: 1.472041]\n",
            "[Epoch 30/200] [Batch 904/938] [D loss: 0.264736] [G loss: 0.253904] [info loss: 1.474491]\n",
            "[Epoch 30/200] [Batch 905/938] [D loss: 0.227838] [G loss: 0.273162] [info loss: 1.468514]\n",
            "[Epoch 30/200] [Batch 906/938] [D loss: 0.194395] [G loss: 0.363047] [info loss: 1.469847]\n",
            "[Epoch 30/200] [Batch 907/938] [D loss: 0.208865] [G loss: 0.271764] [info loss: 1.484445]\n",
            "[Epoch 30/200] [Batch 908/938] [D loss: 0.178072] [G loss: 0.364432] [info loss: 1.480513]\n",
            "[Epoch 30/200] [Batch 909/938] [D loss: 0.168449] [G loss: 0.284255] [info loss: 1.483891]\n",
            "[Epoch 30/200] [Batch 910/938] [D loss: 0.145651] [G loss: 0.575861] [info loss: 1.483976]\n",
            "[Epoch 30/200] [Batch 911/938] [D loss: 0.219689] [G loss: 0.342854] [info loss: 1.472207]\n",
            "[Epoch 30/200] [Batch 912/938] [D loss: 0.178794] [G loss: 0.378533] [info loss: 1.468760]\n",
            "[Epoch 30/200] [Batch 913/938] [D loss: 0.277255] [G loss: 0.350759] [info loss: 1.486558]\n",
            "[Epoch 30/200] [Batch 914/938] [D loss: 0.231678] [G loss: 0.327200] [info loss: 1.485452]\n",
            "[Epoch 30/200] [Batch 915/938] [D loss: 0.222431] [G loss: 0.310723] [info loss: 1.485905]\n",
            "[Epoch 30/200] [Batch 916/938] [D loss: 0.201541] [G loss: 0.483431] [info loss: 1.473981]\n",
            "[Epoch 30/200] [Batch 917/938] [D loss: 0.215348] [G loss: 0.296414] [info loss: 1.472526]\n",
            "[Epoch 30/200] [Batch 918/938] [D loss: 0.128938] [G loss: 0.251378] [info loss: 1.476522]\n",
            "[Epoch 30/200] [Batch 919/938] [D loss: 0.272161] [G loss: 0.227537] [info loss: 1.471044]\n",
            "[Epoch 30/200] [Batch 920/938] [D loss: 0.288069] [G loss: 0.256086] [info loss: 1.472405]\n",
            "[Epoch 30/200] [Batch 921/938] [D loss: 0.252218] [G loss: 0.362055] [info loss: 1.470651]\n",
            "[Epoch 30/200] [Batch 922/938] [D loss: 0.269508] [G loss: 0.641223] [info loss: 1.469406]\n",
            "[Epoch 30/200] [Batch 923/938] [D loss: 0.281421] [G loss: 0.236289] [info loss: 1.472198]\n",
            "[Epoch 30/200] [Batch 924/938] [D loss: 0.123166] [G loss: 0.224640] [info loss: 1.504924]\n",
            "[Epoch 30/200] [Batch 925/938] [D loss: 0.241546] [G loss: 0.209396] [info loss: 1.495574]\n",
            "[Epoch 30/200] [Batch 926/938] [D loss: 0.258952] [G loss: 0.130796] [info loss: 1.486909]\n",
            "[Epoch 30/200] [Batch 927/938] [D loss: 0.222766] [G loss: 0.265200] [info loss: 1.471583]\n",
            "[Epoch 30/200] [Batch 928/938] [D loss: 0.231929] [G loss: 0.323432] [info loss: 1.485836]\n",
            "[Epoch 30/200] [Batch 929/938] [D loss: 0.301760] [G loss: 0.474771] [info loss: 1.474633]\n",
            "[Epoch 30/200] [Batch 930/938] [D loss: 0.201235] [G loss: 0.540910] [info loss: 1.472763]\n",
            "[Epoch 30/200] [Batch 931/938] [D loss: 0.198171] [G loss: 0.188050] [info loss: 1.474062]\n",
            "[Epoch 30/200] [Batch 932/938] [D loss: 0.280722] [G loss: 0.339700] [info loss: 1.472254]\n",
            "[Epoch 30/200] [Batch 933/938] [D loss: 0.290574] [G loss: 0.228134] [info loss: 1.479774]\n",
            "[Epoch 30/200] [Batch 934/938] [D loss: 0.207689] [G loss: 0.233981] [info loss: 1.472629]\n",
            "[Epoch 30/200] [Batch 935/938] [D loss: 0.237230] [G loss: 0.271799] [info loss: 1.483740]\n",
            "[Epoch 30/200] [Batch 936/938] [D loss: 0.223405] [G loss: 0.487466] [info loss: 1.485863]\n",
            "[Epoch 30/200] [Batch 937/938] [D loss: 0.266761] [G loss: 0.368313] [info loss: 1.470791]\n",
            "[Epoch 31/200] [Batch 0/938] [D loss: 0.242269] [G loss: 0.508252] [info loss: 1.471020]\n",
            "[Epoch 31/200] [Batch 1/938] [D loss: 0.218704] [G loss: 0.357736] [info loss: 1.470363]\n",
            "[Epoch 31/200] [Batch 2/938] [D loss: 0.225674] [G loss: 0.398060] [info loss: 1.491173]\n",
            "[Epoch 31/200] [Batch 3/938] [D loss: 0.285546] [G loss: 0.378093] [info loss: 1.471015]\n",
            "[Epoch 31/200] [Batch 4/938] [D loss: 0.171917] [G loss: 0.267370] [info loss: 1.471933]\n",
            "[Epoch 31/200] [Batch 5/938] [D loss: 0.250062] [G loss: 0.348982] [info loss: 1.471408]\n",
            "[Epoch 31/200] [Batch 6/938] [D loss: 0.323743] [G loss: 0.696335] [info loss: 1.476827]\n",
            "[Epoch 31/200] [Batch 7/938] [D loss: 0.248559] [G loss: 0.243726] [info loss: 1.470272]\n",
            "[Epoch 31/200] [Batch 8/938] [D loss: 0.221718] [G loss: 0.208528] [info loss: 1.485796]\n",
            "[Epoch 31/200] [Batch 9/938] [D loss: 0.253816] [G loss: 0.243171] [info loss: 1.468809]\n",
            "[Epoch 31/200] [Batch 10/938] [D loss: 0.163299] [G loss: 0.167352] [info loss: 1.469397]\n",
            "[Epoch 31/200] [Batch 11/938] [D loss: 0.200084] [G loss: 0.345223] [info loss: 1.484402]\n",
            "[Epoch 31/200] [Batch 12/938] [D loss: 0.225471] [G loss: 0.455016] [info loss: 1.474889]\n",
            "[Epoch 31/200] [Batch 13/938] [D loss: 0.166867] [G loss: 0.561775] [info loss: 1.467606]\n",
            "[Epoch 31/200] [Batch 14/938] [D loss: 0.206021] [G loss: 0.333450] [info loss: 1.470454]\n",
            "[Epoch 31/200] [Batch 15/938] [D loss: 0.106100] [G loss: 0.196244] [info loss: 1.481198]\n",
            "[Epoch 31/200] [Batch 16/938] [D loss: 0.243938] [G loss: 0.438132] [info loss: 1.470292]\n",
            "[Epoch 31/200] [Batch 17/938] [D loss: 0.234239] [G loss: 0.395744] [info loss: 1.471526]\n",
            "[Epoch 31/200] [Batch 18/938] [D loss: 0.253403] [G loss: 0.348320] [info loss: 1.497298]\n",
            "[Epoch 31/200] [Batch 19/938] [D loss: 0.246631] [G loss: 0.337083] [info loss: 1.479668]\n",
            "[Epoch 31/200] [Batch 20/938] [D loss: 0.172225] [G loss: 0.264194] [info loss: 1.470929]\n",
            "[Epoch 31/200] [Batch 21/938] [D loss: 0.195130] [G loss: 0.388667] [info loss: 1.476567]\n",
            "[Epoch 31/200] [Batch 22/938] [D loss: 0.216301] [G loss: 0.441311] [info loss: 1.471409]\n",
            "[Epoch 31/200] [Batch 23/938] [D loss: 0.305551] [G loss: 0.549716] [info loss: 1.476077]\n",
            "[Epoch 31/200] [Batch 24/938] [D loss: 0.181349] [G loss: 0.219410] [info loss: 1.472550]\n",
            "[Epoch 31/200] [Batch 25/938] [D loss: 0.255902] [G loss: 0.280834] [info loss: 1.504979]\n",
            "[Epoch 31/200] [Batch 26/938] [D loss: 0.221826] [G loss: 0.241403] [info loss: 1.469122]\n",
            "[Epoch 31/200] [Batch 27/938] [D loss: 0.260985] [G loss: 0.320196] [info loss: 1.488085]\n",
            "[Epoch 31/200] [Batch 28/938] [D loss: 0.147099] [G loss: 0.475953] [info loss: 1.474119]\n",
            "[Epoch 31/200] [Batch 29/938] [D loss: 0.223226] [G loss: 0.338687] [info loss: 1.477043]\n",
            "[Epoch 31/200] [Batch 30/938] [D loss: 0.266073] [G loss: 0.341570] [info loss: 1.471420]\n",
            "[Epoch 31/200] [Batch 31/938] [D loss: 0.124794] [G loss: 0.306179] [info loss: 1.468957]\n",
            "[Epoch 31/200] [Batch 32/938] [D loss: 0.182238] [G loss: 0.360387] [info loss: 1.468966]\n",
            "[Epoch 31/200] [Batch 33/938] [D loss: 0.284194] [G loss: 0.154217] [info loss: 1.479455]\n",
            "[Epoch 31/200] [Batch 34/938] [D loss: 0.159117] [G loss: 0.295663] [info loss: 1.482967]\n",
            "[Epoch 31/200] [Batch 35/938] [D loss: 0.172633] [G loss: 0.206202] [info loss: 1.487642]\n",
            "[Epoch 31/200] [Batch 36/938] [D loss: 0.119221] [G loss: 0.602189] [info loss: 1.503193]\n",
            "[Epoch 31/200] [Batch 37/938] [D loss: 0.121919] [G loss: 0.435632] [info loss: 1.499494]\n",
            "[Epoch 31/200] [Batch 38/938] [D loss: 0.155052] [G loss: 0.383027] [info loss: 1.471169]\n",
            "[Epoch 31/200] [Batch 39/938] [D loss: 0.143861] [G loss: 0.324891] [info loss: 1.472469]\n",
            "[Epoch 31/200] [Batch 40/938] [D loss: 0.253853] [G loss: 0.450402] [info loss: 1.469717]\n",
            "[Epoch 31/200] [Batch 41/938] [D loss: 0.153798] [G loss: 0.328459] [info loss: 1.483934]\n",
            "[Epoch 31/200] [Batch 42/938] [D loss: 0.247576] [G loss: 0.204353] [info loss: 1.474072]\n",
            "[Epoch 31/200] [Batch 43/938] [D loss: 0.134279] [G loss: 0.415463] [info loss: 1.469889]\n",
            "[Epoch 31/200] [Batch 44/938] [D loss: 0.283251] [G loss: 0.378176] [info loss: 1.496056]\n",
            "[Epoch 31/200] [Batch 45/938] [D loss: 0.215879] [G loss: 0.399273] [info loss: 1.471143]\n",
            "[Epoch 31/200] [Batch 46/938] [D loss: 0.236588] [G loss: 0.311942] [info loss: 1.486877]\n",
            "[Epoch 31/200] [Batch 47/938] [D loss: 0.133889] [G loss: 0.501698] [info loss: 1.507451]\n",
            "[Epoch 31/200] [Batch 48/938] [D loss: 0.233819] [G loss: 0.255112] [info loss: 1.479115]\n",
            "[Epoch 31/200] [Batch 49/938] [D loss: 0.260941] [G loss: 0.278998] [info loss: 1.486897]\n",
            "[Epoch 31/200] [Batch 50/938] [D loss: 0.226759] [G loss: 0.334936] [info loss: 1.477592]\n",
            "[Epoch 31/200] [Batch 51/938] [D loss: 0.189295] [G loss: 0.229319] [info loss: 1.474869]\n",
            "[Epoch 31/200] [Batch 52/938] [D loss: 0.220723] [G loss: 0.409524] [info loss: 1.475514]\n",
            "[Epoch 31/200] [Batch 53/938] [D loss: 0.205499] [G loss: 0.282546] [info loss: 1.470034]\n",
            "[Epoch 31/200] [Batch 54/938] [D loss: 0.233630] [G loss: 0.337269] [info loss: 1.480410]\n",
            "[Epoch 31/200] [Batch 55/938] [D loss: 0.142354] [G loss: 0.726599] [info loss: 1.484284]\n",
            "[Epoch 31/200] [Batch 56/938] [D loss: 0.166740] [G loss: 0.443064] [info loss: 1.495831]\n",
            "[Epoch 31/200] [Batch 57/938] [D loss: 0.312229] [G loss: 0.243997] [info loss: 1.472234]\n",
            "[Epoch 31/200] [Batch 58/938] [D loss: 0.156616] [G loss: 0.249129] [info loss: 1.474561]\n",
            "[Epoch 31/200] [Batch 59/938] [D loss: 0.277146] [G loss: 0.083356] [info loss: 1.476941]\n",
            "[Epoch 31/200] [Batch 60/938] [D loss: 0.285655] [G loss: 0.320457] [info loss: 1.469553]\n",
            "[Epoch 31/200] [Batch 61/938] [D loss: 0.291144] [G loss: 0.250926] [info loss: 1.469916]\n",
            "[Epoch 31/200] [Batch 62/938] [D loss: 0.281980] [G loss: 0.297493] [info loss: 1.472027]\n",
            "[Epoch 31/200] [Batch 63/938] [D loss: 0.139412] [G loss: 0.328853] [info loss: 1.470086]\n",
            "[Epoch 31/200] [Batch 64/938] [D loss: 0.136260] [G loss: 0.517307] [info loss: 1.471208]\n",
            "[Epoch 31/200] [Batch 65/938] [D loss: 0.126097] [G loss: 0.300761] [info loss: 1.489424]\n",
            "[Epoch 31/200] [Batch 66/938] [D loss: 0.201691] [G loss: 0.234689] [info loss: 1.475560]\n",
            "[Epoch 31/200] [Batch 67/938] [D loss: 0.254242] [G loss: 0.330975] [info loss: 1.470827]\n",
            "[Epoch 31/200] [Batch 68/938] [D loss: 0.189828] [G loss: 0.328998] [info loss: 1.470548]\n",
            "[Epoch 31/200] [Batch 69/938] [D loss: 0.164516] [G loss: 0.350360] [info loss: 1.470561]\n",
            "[Epoch 31/200] [Batch 70/938] [D loss: 0.141394] [G loss: 0.313791] [info loss: 1.471604]\n",
            "[Epoch 31/200] [Batch 71/938] [D loss: 0.161632] [G loss: 0.185942] [info loss: 1.485188]\n",
            "[Epoch 31/200] [Batch 72/938] [D loss: 0.213273] [G loss: 0.207232] [info loss: 1.473031]\n",
            "[Epoch 31/200] [Batch 73/938] [D loss: 0.286840] [G loss: 0.317767] [info loss: 1.475359]\n",
            "[Epoch 31/200] [Batch 74/938] [D loss: 0.161902] [G loss: 0.348165] [info loss: 1.472101]\n",
            "[Epoch 31/200] [Batch 75/938] [D loss: 0.292633] [G loss: 0.179895] [info loss: 1.480301]\n",
            "[Epoch 31/200] [Batch 76/938] [D loss: 0.214759] [G loss: 0.395170] [info loss: 1.489043]\n",
            "[Epoch 31/200] [Batch 77/938] [D loss: 0.202212] [G loss: 0.440829] [info loss: 1.470939]\n",
            "[Epoch 31/200] [Batch 78/938] [D loss: 0.203097] [G loss: 0.479401] [info loss: 1.469156]\n",
            "[Epoch 31/200] [Batch 79/938] [D loss: 0.128824] [G loss: 0.419348] [info loss: 1.471280]\n",
            "[Epoch 31/200] [Batch 80/938] [D loss: 0.204001] [G loss: 0.470750] [info loss: 1.471088]\n",
            "[Epoch 31/200] [Batch 81/938] [D loss: 0.177771] [G loss: 0.432712] [info loss: 1.484539]\n",
            "[Epoch 31/200] [Batch 82/938] [D loss: 0.290961] [G loss: 0.413434] [info loss: 1.472363]\n",
            "[Epoch 31/200] [Batch 83/938] [D loss: 0.225685] [G loss: 0.314435] [info loss: 1.470574]\n",
            "[Epoch 31/200] [Batch 84/938] [D loss: 0.189489] [G loss: 0.386457] [info loss: 1.479837]\n",
            "[Epoch 31/200] [Batch 85/938] [D loss: 0.225439] [G loss: 0.524032] [info loss: 1.486596]\n",
            "[Epoch 31/200] [Batch 86/938] [D loss: 0.273066] [G loss: 0.176021] [info loss: 1.485033]\n",
            "[Epoch 31/200] [Batch 87/938] [D loss: 0.244210] [G loss: 0.338861] [info loss: 1.470338]\n",
            "[Epoch 31/200] [Batch 88/938] [D loss: 0.219743] [G loss: 0.120020] [info loss: 1.497462]\n",
            "[Epoch 31/200] [Batch 89/938] [D loss: 0.203525] [G loss: 0.477648] [info loss: 1.471296]\n",
            "[Epoch 31/200] [Batch 90/938] [D loss: 0.171418] [G loss: 0.260015] [info loss: 1.466961]\n",
            "[Epoch 31/200] [Batch 91/938] [D loss: 0.169247] [G loss: 0.359673] [info loss: 1.479635]\n",
            "[Epoch 31/200] [Batch 92/938] [D loss: 0.181407] [G loss: 0.210629] [info loss: 1.474904]\n",
            "[Epoch 31/200] [Batch 93/938] [D loss: 0.242874] [G loss: 0.459249] [info loss: 1.486065]\n",
            "[Epoch 31/200] [Batch 94/938] [D loss: 0.206750] [G loss: 0.443671] [info loss: 1.488382]\n",
            "[Epoch 31/200] [Batch 95/938] [D loss: 0.154993] [G loss: 0.398620] [info loss: 1.487883]\n",
            "[Epoch 31/200] [Batch 96/938] [D loss: 0.167502] [G loss: 0.224159] [info loss: 1.470552]\n",
            "[Epoch 31/200] [Batch 97/938] [D loss: 0.123315] [G loss: 0.202907] [info loss: 1.469214]\n",
            "[Epoch 31/200] [Batch 98/938] [D loss: 0.173266] [G loss: 0.446246] [info loss: 1.469517]\n",
            "[Epoch 31/200] [Batch 99/938] [D loss: 0.208311] [G loss: 0.505969] [info loss: 1.472513]\n",
            "[Epoch 31/200] [Batch 100/938] [D loss: 0.209056] [G loss: 0.282672] [info loss: 1.486257]\n",
            "[Epoch 31/200] [Batch 101/938] [D loss: 0.225758] [G loss: 0.115680] [info loss: 1.473078]\n",
            "[Epoch 31/200] [Batch 102/938] [D loss: 0.181452] [G loss: 0.460947] [info loss: 1.469358]\n",
            "[Epoch 31/200] [Batch 103/938] [D loss: 0.222507] [G loss: 0.451246] [info loss: 1.472282]\n",
            "[Epoch 31/200] [Batch 104/938] [D loss: 0.139082] [G loss: 0.446192] [info loss: 1.467935]\n",
            "[Epoch 31/200] [Batch 105/938] [D loss: 0.138822] [G loss: 0.403370] [info loss: 1.476804]\n",
            "[Epoch 31/200] [Batch 106/938] [D loss: 0.301458] [G loss: 0.379790] [info loss: 1.474731]\n",
            "[Epoch 31/200] [Batch 107/938] [D loss: 0.191864] [G loss: 0.329247] [info loss: 1.472952]\n",
            "[Epoch 31/200] [Batch 108/938] [D loss: 0.198539] [G loss: 0.261499] [info loss: 1.475174]\n",
            "[Epoch 31/200] [Batch 109/938] [D loss: 0.233869] [G loss: 0.559292] [info loss: 1.472733]\n",
            "[Epoch 31/200] [Batch 110/938] [D loss: 0.257109] [G loss: 0.205152] [info loss: 1.484586]\n",
            "[Epoch 31/200] [Batch 111/938] [D loss: 0.201841] [G loss: 0.351756] [info loss: 1.487026]\n",
            "[Epoch 31/200] [Batch 112/938] [D loss: 0.298930] [G loss: 0.344153] [info loss: 1.471238]\n",
            "[Epoch 31/200] [Batch 113/938] [D loss: 0.185597] [G loss: 0.191336] [info loss: 1.469561]\n",
            "[Epoch 31/200] [Batch 114/938] [D loss: 0.292447] [G loss: 0.326828] [info loss: 1.472214]\n",
            "[Epoch 31/200] [Batch 115/938] [D loss: 0.161272] [G loss: 0.325696] [info loss: 1.484495]\n",
            "[Epoch 31/200] [Batch 116/938] [D loss: 0.221923] [G loss: 0.374787] [info loss: 1.468760]\n",
            "[Epoch 31/200] [Batch 117/938] [D loss: 0.297415] [G loss: 0.226335] [info loss: 1.486908]\n",
            "[Epoch 31/200] [Batch 118/938] [D loss: 0.324424] [G loss: 0.285876] [info loss: 1.487035]\n",
            "[Epoch 31/200] [Batch 119/938] [D loss: 0.273484] [G loss: 0.313537] [info loss: 1.483570]\n",
            "[Epoch 31/200] [Batch 120/938] [D loss: 0.225095] [G loss: 0.427371] [info loss: 1.518976]\n",
            "[Epoch 31/200] [Batch 121/938] [D loss: 0.254563] [G loss: 0.354282] [info loss: 1.486318]\n",
            "[Epoch 31/200] [Batch 122/938] [D loss: 0.266241] [G loss: 0.559057] [info loss: 1.468276]\n",
            "[Epoch 31/200] [Batch 123/938] [D loss: 0.117169] [G loss: 0.226389] [info loss: 1.481583]\n",
            "[Epoch 31/200] [Batch 124/938] [D loss: 0.139291] [G loss: 0.207827] [info loss: 1.472537]\n",
            "[Epoch 31/200] [Batch 125/938] [D loss: 0.305296] [G loss: 0.386078] [info loss: 1.479013]\n",
            "[Epoch 31/200] [Batch 126/938] [D loss: 0.165478] [G loss: 0.463212] [info loss: 1.469989]\n",
            "[Epoch 31/200] [Batch 127/938] [D loss: 0.201708] [G loss: 0.169350] [info loss: 1.488972]\n",
            "[Epoch 31/200] [Batch 128/938] [D loss: 0.140693] [G loss: 0.404605] [info loss: 1.505332]\n",
            "[Epoch 31/200] [Batch 129/938] [D loss: 0.096450] [G loss: 0.513262] [info loss: 1.470529]\n",
            "[Epoch 31/200] [Batch 130/938] [D loss: 0.323928] [G loss: 0.406896] [info loss: 1.469949]\n",
            "[Epoch 31/200] [Batch 131/938] [D loss: 0.229930] [G loss: 0.463460] [info loss: 1.483080]\n",
            "[Epoch 31/200] [Batch 132/938] [D loss: 0.284158] [G loss: 0.166541] [info loss: 1.485510]\n",
            "[Epoch 31/200] [Batch 133/938] [D loss: 0.312656] [G loss: 0.199373] [info loss: 1.474328]\n",
            "[Epoch 31/200] [Batch 134/938] [D loss: 0.155760] [G loss: 0.431178] [info loss: 1.480042]\n",
            "[Epoch 31/200] [Batch 135/938] [D loss: 0.265200] [G loss: 0.263181] [info loss: 1.487653]\n",
            "[Epoch 31/200] [Batch 136/938] [D loss: 0.160878] [G loss: 0.381559] [info loss: 1.491646]\n",
            "[Epoch 31/200] [Batch 137/938] [D loss: 0.203110] [G loss: 0.115554] [info loss: 1.477659]\n",
            "[Epoch 31/200] [Batch 138/938] [D loss: 0.222772] [G loss: 0.515087] [info loss: 1.472926]\n",
            "[Epoch 31/200] [Batch 139/938] [D loss: 0.165644] [G loss: 0.441551] [info loss: 1.485501]\n",
            "[Epoch 31/200] [Batch 140/938] [D loss: 0.302413] [G loss: 0.483982] [info loss: 1.472505]\n",
            "[Epoch 31/200] [Batch 141/938] [D loss: 0.351769] [G loss: 0.295413] [info loss: 1.484617]\n",
            "[Epoch 31/200] [Batch 142/938] [D loss: 0.238130] [G loss: 0.148613] [info loss: 1.480057]\n",
            "[Epoch 31/200] [Batch 143/938] [D loss: 0.310666] [G loss: 0.447418] [info loss: 1.469177]\n",
            "[Epoch 31/200] [Batch 144/938] [D loss: 0.153032] [G loss: 0.214868] [info loss: 1.469680]\n",
            "[Epoch 31/200] [Batch 145/938] [D loss: 0.191142] [G loss: 0.533122] [info loss: 1.471121]\n",
            "[Epoch 31/200] [Batch 146/938] [D loss: 0.192714] [G loss: 0.235345] [info loss: 1.471356]\n",
            "[Epoch 31/200] [Batch 147/938] [D loss: 0.223216] [G loss: 0.293219] [info loss: 1.469746]\n",
            "[Epoch 31/200] [Batch 148/938] [D loss: 0.213325] [G loss: 0.184725] [info loss: 1.484581]\n",
            "[Epoch 31/200] [Batch 149/938] [D loss: 0.195822] [G loss: 0.305767] [info loss: 1.470293]\n",
            "[Epoch 31/200] [Batch 150/938] [D loss: 0.156803] [G loss: 0.248769] [info loss: 1.485682]\n",
            "[Epoch 31/200] [Batch 151/938] [D loss: 0.204051] [G loss: 0.356997] [info loss: 1.477897]\n",
            "[Epoch 31/200] [Batch 152/938] [D loss: 0.210379] [G loss: 0.250776] [info loss: 1.482665]\n",
            "[Epoch 31/200] [Batch 153/938] [D loss: 0.222906] [G loss: 0.202298] [info loss: 1.471799]\n",
            "[Epoch 31/200] [Batch 154/938] [D loss: 0.140152] [G loss: 0.516313] [info loss: 1.489409]\n",
            "[Epoch 31/200] [Batch 155/938] [D loss: 0.202859] [G loss: 0.464266] [info loss: 1.476674]\n",
            "[Epoch 31/200] [Batch 156/938] [D loss: 0.233232] [G loss: 0.452133] [info loss: 1.470483]\n",
            "[Epoch 31/200] [Batch 157/938] [D loss: 0.328295] [G loss: 0.186455] [info loss: 1.468602]\n",
            "[Epoch 31/200] [Batch 158/938] [D loss: 0.290974] [G loss: 0.328461] [info loss: 1.481492]\n",
            "[Epoch 31/200] [Batch 159/938] [D loss: 0.336251] [G loss: 0.414589] [info loss: 1.471004]\n",
            "[Epoch 31/200] [Batch 160/938] [D loss: 0.206686] [G loss: 0.542149] [info loss: 1.486113]\n",
            "[Epoch 31/200] [Batch 161/938] [D loss: 0.227154] [G loss: 0.402649] [info loss: 1.476339]\n",
            "[Epoch 31/200] [Batch 162/938] [D loss: 0.246469] [G loss: 0.215623] [info loss: 1.481945]\n",
            "[Epoch 31/200] [Batch 163/938] [D loss: 0.278014] [G loss: 0.138251] [info loss: 1.494598]\n",
            "[Epoch 31/200] [Batch 164/938] [D loss: 0.277196] [G loss: 0.279758] [info loss: 1.475983]\n",
            "[Epoch 31/200] [Batch 165/938] [D loss: 0.211807] [G loss: 0.541329] [info loss: 1.470488]\n",
            "[Epoch 31/200] [Batch 166/938] [D loss: 0.255910] [G loss: 0.329846] [info loss: 1.468701]\n",
            "[Epoch 31/200] [Batch 167/938] [D loss: 0.149292] [G loss: 0.271700] [info loss: 1.476742]\n",
            "[Epoch 31/200] [Batch 168/938] [D loss: 0.158397] [G loss: 0.345598] [info loss: 1.487525]\n",
            "[Epoch 31/200] [Batch 169/938] [D loss: 0.239401] [G loss: 0.237698] [info loss: 1.488479]\n",
            "[Epoch 31/200] [Batch 170/938] [D loss: 0.142635] [G loss: 0.355839] [info loss: 1.469574]\n",
            "[Epoch 31/200] [Batch 171/938] [D loss: 0.218904] [G loss: 0.344567] [info loss: 1.473945]\n",
            "[Epoch 31/200] [Batch 172/938] [D loss: 0.255780] [G loss: 0.375775] [info loss: 1.485183]\n",
            "[Epoch 31/200] [Batch 173/938] [D loss: 0.199913] [G loss: 0.402003] [info loss: 1.471511]\n",
            "[Epoch 31/200] [Batch 174/938] [D loss: 0.232817] [G loss: 0.151429] [info loss: 1.502822]\n",
            "[Epoch 31/200] [Batch 175/938] [D loss: 0.214706] [G loss: 0.210578] [info loss: 1.480795]\n",
            "[Epoch 31/200] [Batch 176/938] [D loss: 0.211450] [G loss: 0.189083] [info loss: 1.484244]\n",
            "[Epoch 31/200] [Batch 177/938] [D loss: 0.125899] [G loss: 0.207155] [info loss: 1.475321]\n",
            "[Epoch 31/200] [Batch 178/938] [D loss: 0.137816] [G loss: 0.342344] [info loss: 1.473920]\n",
            "[Epoch 31/200] [Batch 179/938] [D loss: 0.219121] [G loss: 0.223077] [info loss: 1.486193]\n",
            "[Epoch 31/200] [Batch 180/938] [D loss: 0.191535] [G loss: 0.091141] [info loss: 1.488627]\n",
            "[Epoch 31/200] [Batch 181/938] [D loss: 0.182114] [G loss: 0.195542] [info loss: 1.489219]\n",
            "[Epoch 31/200] [Batch 182/938] [D loss: 0.282981] [G loss: 0.350897] [info loss: 1.471833]\n",
            "[Epoch 31/200] [Batch 183/938] [D loss: 0.250061] [G loss: 0.233762] [info loss: 1.485846]\n",
            "[Epoch 31/200] [Batch 184/938] [D loss: 0.242103] [G loss: 0.175817] [info loss: 1.487120]\n",
            "[Epoch 31/200] [Batch 185/938] [D loss: 0.176397] [G loss: 0.379504] [info loss: 1.471160]\n",
            "[Epoch 31/200] [Batch 186/938] [D loss: 0.249376] [G loss: 0.469953] [info loss: 1.473013]\n",
            "[Epoch 31/200] [Batch 187/938] [D loss: 0.232783] [G loss: 0.193301] [info loss: 1.470406]\n",
            "[Epoch 31/200] [Batch 188/938] [D loss: 0.183159] [G loss: 0.570475] [info loss: 1.473071]\n",
            "[Epoch 31/200] [Batch 189/938] [D loss: 0.258763] [G loss: 0.229016] [info loss: 1.477122]\n",
            "[Epoch 31/200] [Batch 190/938] [D loss: 0.258302] [G loss: 0.317838] [info loss: 1.471164]\n",
            "[Epoch 31/200] [Batch 191/938] [D loss: 0.169263] [G loss: 0.502969] [info loss: 1.496014]\n",
            "[Epoch 31/200] [Batch 192/938] [D loss: 0.160390] [G loss: 0.238457] [info loss: 1.473015]\n",
            "[Epoch 31/200] [Batch 193/938] [D loss: 0.210735] [G loss: 0.284909] [info loss: 1.479729]\n",
            "[Epoch 31/200] [Batch 194/938] [D loss: 0.252338] [G loss: 0.496614] [info loss: 1.473228]\n",
            "[Epoch 31/200] [Batch 195/938] [D loss: 0.242478] [G loss: 0.480872] [info loss: 1.469660]\n",
            "[Epoch 31/200] [Batch 196/938] [D loss: 0.107217] [G loss: 0.304420] [info loss: 1.483949]\n",
            "[Epoch 31/200] [Batch 197/938] [D loss: 0.261460] [G loss: 0.244500] [info loss: 1.474924]\n",
            "[Epoch 31/200] [Batch 198/938] [D loss: 0.175669] [G loss: 0.406641] [info loss: 1.468479]\n",
            "[Epoch 31/200] [Batch 199/938] [D loss: 0.341057] [G loss: 0.404368] [info loss: 1.470856]\n",
            "[Epoch 31/200] [Batch 200/938] [D loss: 0.202325] [G loss: 0.259782] [info loss: 1.470771]\n",
            "[Epoch 31/200] [Batch 201/938] [D loss: 0.108372] [G loss: 0.198889] [info loss: 1.469122]\n",
            "[Epoch 31/200] [Batch 202/938] [D loss: 0.188504] [G loss: 0.449308] [info loss: 1.470586]\n",
            "[Epoch 31/200] [Batch 203/938] [D loss: 0.255599] [G loss: 0.428496] [info loss: 1.477342]\n",
            "[Epoch 31/200] [Batch 204/938] [D loss: 0.140025] [G loss: 0.319579] [info loss: 1.487449]\n",
            "[Epoch 31/200] [Batch 205/938] [D loss: 0.206349] [G loss: 0.356849] [info loss: 1.473570]\n",
            "[Epoch 31/200] [Batch 206/938] [D loss: 0.172819] [G loss: 0.382919] [info loss: 1.484527]\n",
            "[Epoch 31/200] [Batch 207/938] [D loss: 0.224662] [G loss: 0.306079] [info loss: 1.473790]\n",
            "[Epoch 31/200] [Batch 208/938] [D loss: 0.253490] [G loss: 0.222324] [info loss: 1.468768]\n",
            "[Epoch 31/200] [Batch 209/938] [D loss: 0.192536] [G loss: 0.326777] [info loss: 1.484651]\n",
            "[Epoch 31/200] [Batch 210/938] [D loss: 0.244078] [G loss: 0.226911] [info loss: 1.470320]\n",
            "[Epoch 31/200] [Batch 211/938] [D loss: 0.218649] [G loss: 0.258006] [info loss: 1.472828]\n",
            "[Epoch 31/200] [Batch 212/938] [D loss: 0.282815] [G loss: 0.375693] [info loss: 1.470563]\n",
            "[Epoch 31/200] [Batch 213/938] [D loss: 0.205019] [G loss: 0.408967] [info loss: 1.475732]\n",
            "[Epoch 31/200] [Batch 214/938] [D loss: 0.204505] [G loss: 0.262511] [info loss: 1.471206]\n",
            "[Epoch 31/200] [Batch 215/938] [D loss: 0.131069] [G loss: 0.334777] [info loss: 1.497650]\n",
            "[Epoch 31/200] [Batch 216/938] [D loss: 0.251282] [G loss: 0.169424] [info loss: 1.469661]\n",
            "[Epoch 31/200] [Batch 217/938] [D loss: 0.124893] [G loss: 0.526985] [info loss: 1.470165]\n",
            "[Epoch 31/200] [Batch 218/938] [D loss: 0.242691] [G loss: 0.279523] [info loss: 1.471114]\n",
            "[Epoch 31/200] [Batch 219/938] [D loss: 0.179921] [G loss: 0.332845] [info loss: 1.469203]\n",
            "[Epoch 31/200] [Batch 220/938] [D loss: 0.179712] [G loss: 0.239083] [info loss: 1.474196]\n",
            "[Epoch 31/200] [Batch 221/938] [D loss: 0.173928] [G loss: 0.239863] [info loss: 1.485688]\n",
            "[Epoch 31/200] [Batch 222/938] [D loss: 0.185201] [G loss: 0.354315] [info loss: 1.470997]\n",
            "[Epoch 31/200] [Batch 223/938] [D loss: 0.239059] [G loss: 0.322546] [info loss: 1.490022]\n",
            "[Epoch 31/200] [Batch 224/938] [D loss: 0.234021] [G loss: 0.391152] [info loss: 1.478007]\n",
            "[Epoch 31/200] [Batch 225/938] [D loss: 0.216309] [G loss: 0.359422] [info loss: 1.472949]\n",
            "[Epoch 31/200] [Batch 226/938] [D loss: 0.205221] [G loss: 0.452821] [info loss: 1.486772]\n",
            "[Epoch 31/200] [Batch 227/938] [D loss: 0.245229] [G loss: 0.186364] [info loss: 1.469050]\n",
            "[Epoch 31/200] [Batch 228/938] [D loss: 0.343960] [G loss: 0.247838] [info loss: 1.490074]\n",
            "[Epoch 31/200] [Batch 229/938] [D loss: 0.190191] [G loss: 0.203262] [info loss: 1.483345]\n",
            "[Epoch 31/200] [Batch 230/938] [D loss: 0.149500] [G loss: 0.282653] [info loss: 1.487235]\n",
            "[Epoch 31/200] [Batch 231/938] [D loss: 0.148182] [G loss: 0.437157] [info loss: 1.475103]\n",
            "[Epoch 31/200] [Batch 232/938] [D loss: 0.163592] [G loss: 0.252797] [info loss: 1.469305]\n",
            "[Epoch 31/200] [Batch 233/938] [D loss: 0.244950] [G loss: 0.470204] [info loss: 1.485944]\n",
            "[Epoch 31/200] [Batch 234/938] [D loss: 0.152615] [G loss: 0.276053] [info loss: 1.469047]\n",
            "[Epoch 31/200] [Batch 235/938] [D loss: 0.245836] [G loss: 0.366339] [info loss: 1.486724]\n",
            "[Epoch 31/200] [Batch 236/938] [D loss: 0.239097] [G loss: 0.356654] [info loss: 1.476705]\n",
            "[Epoch 31/200] [Batch 237/938] [D loss: 0.165659] [G loss: 0.384726] [info loss: 1.489039]\n",
            "[Epoch 31/200] [Batch 238/938] [D loss: 0.345209] [G loss: 0.382646] [info loss: 1.486141]\n",
            "[Epoch 31/200] [Batch 239/938] [D loss: 0.260082] [G loss: 0.369084] [info loss: 1.482502]\n",
            "[Epoch 31/200] [Batch 240/938] [D loss: 0.185677] [G loss: 0.338515] [info loss: 1.472416]\n",
            "[Epoch 31/200] [Batch 241/938] [D loss: 0.246817] [G loss: 0.566335] [info loss: 1.484882]\n",
            "[Epoch 31/200] [Batch 242/938] [D loss: 0.232365] [G loss: 0.600353] [info loss: 1.470298]\n",
            "[Epoch 31/200] [Batch 243/938] [D loss: 0.153549] [G loss: 0.211994] [info loss: 1.472014]\n",
            "[Epoch 31/200] [Batch 244/938] [D loss: 0.287812] [G loss: 0.307401] [info loss: 1.480888]\n",
            "[Epoch 31/200] [Batch 245/938] [D loss: 0.250863] [G loss: 0.362528] [info loss: 1.470407]\n",
            "[Epoch 31/200] [Batch 246/938] [D loss: 0.200494] [G loss: 0.401211] [info loss: 1.473668]\n",
            "[Epoch 31/200] [Batch 247/938] [D loss: 0.304236] [G loss: 0.311779] [info loss: 1.474126]\n",
            "[Epoch 31/200] [Batch 248/938] [D loss: 0.187758] [G loss: 0.296099] [info loss: 1.472317]\n",
            "[Epoch 31/200] [Batch 249/938] [D loss: 0.213156] [G loss: 0.414300] [info loss: 1.469531]\n",
            "[Epoch 31/200] [Batch 250/938] [D loss: 0.162528] [G loss: 0.296949] [info loss: 1.469421]\n",
            "[Epoch 31/200] [Batch 251/938] [D loss: 0.281516] [G loss: 0.377902] [info loss: 1.486232]\n",
            "[Epoch 31/200] [Batch 252/938] [D loss: 0.163230] [G loss: 0.240122] [info loss: 1.471695]\n",
            "[Epoch 31/200] [Batch 253/938] [D loss: 0.184856] [G loss: 0.419807] [info loss: 1.468431]\n",
            "[Epoch 31/200] [Batch 254/938] [D loss: 0.174354] [G loss: 0.324532] [info loss: 1.470667]\n",
            "[Epoch 31/200] [Batch 255/938] [D loss: 0.269305] [G loss: 0.394971] [info loss: 1.470158]\n",
            "[Epoch 31/200] [Batch 256/938] [D loss: 0.212440] [G loss: 0.405544] [info loss: 1.485890]\n",
            "[Epoch 31/200] [Batch 257/938] [D loss: 0.160934] [G loss: 0.633945] [info loss: 1.475826]\n",
            "[Epoch 31/200] [Batch 258/938] [D loss: 0.193903] [G loss: 0.343952] [info loss: 1.470235]\n",
            "[Epoch 31/200] [Batch 259/938] [D loss: 0.297388] [G loss: 0.257653] [info loss: 1.469305]\n",
            "[Epoch 31/200] [Batch 260/938] [D loss: 0.277618] [G loss: 0.203702] [info loss: 1.485994]\n",
            "[Epoch 31/200] [Batch 261/938] [D loss: 0.203063] [G loss: 0.322019] [info loss: 1.473379]\n",
            "[Epoch 31/200] [Batch 262/938] [D loss: 0.236679] [G loss: 0.356099] [info loss: 1.473523]\n",
            "[Epoch 31/200] [Batch 263/938] [D loss: 0.149966] [G loss: 0.249283] [info loss: 1.469087]\n",
            "[Epoch 31/200] [Batch 264/938] [D loss: 0.322113] [G loss: 0.143057] [info loss: 1.481943]\n",
            "[Epoch 31/200] [Batch 265/938] [D loss: 0.255635] [G loss: 0.279434] [info loss: 1.469659]\n",
            "[Epoch 31/200] [Batch 266/938] [D loss: 0.218341] [G loss: 0.328554] [info loss: 1.474231]\n",
            "[Epoch 31/200] [Batch 267/938] [D loss: 0.207876] [G loss: 0.175067] [info loss: 1.469893]\n",
            "[Epoch 31/200] [Batch 268/938] [D loss: 0.261995] [G loss: 0.487408] [info loss: 1.468092]\n",
            "[Epoch 31/200] [Batch 269/938] [D loss: 0.203119] [G loss: 0.152442] [info loss: 1.476087]\n",
            "[Epoch 31/200] [Batch 270/938] [D loss: 0.372922] [G loss: 0.303908] [info loss: 1.475651]\n",
            "[Epoch 31/200] [Batch 271/938] [D loss: 0.215396] [G loss: 0.423792] [info loss: 1.472298]\n",
            "[Epoch 31/200] [Batch 272/938] [D loss: 0.249415] [G loss: 0.177326] [info loss: 1.499808]\n",
            "[Epoch 31/200] [Batch 273/938] [D loss: 0.194595] [G loss: 0.331842] [info loss: 1.475038]\n",
            "[Epoch 31/200] [Batch 274/938] [D loss: 0.266176] [G loss: 0.498222] [info loss: 1.469483]\n",
            "[Epoch 31/200] [Batch 275/938] [D loss: 0.223097] [G loss: 0.567751] [info loss: 1.473870]\n",
            "[Epoch 31/200] [Batch 276/938] [D loss: 0.141310] [G loss: 0.244158] [info loss: 1.488378]\n",
            "[Epoch 31/200] [Batch 277/938] [D loss: 0.239408] [G loss: 0.136604] [info loss: 1.481449]\n",
            "[Epoch 31/200] [Batch 278/938] [D loss: 0.175143] [G loss: 0.403569] [info loss: 1.477030]\n",
            "[Epoch 31/200] [Batch 279/938] [D loss: 0.320537] [G loss: 0.249201] [info loss: 1.487118]\n",
            "[Epoch 31/200] [Batch 280/938] [D loss: 0.146854] [G loss: 0.225465] [info loss: 1.474463]\n",
            "[Epoch 31/200] [Batch 281/938] [D loss: 0.207310] [G loss: 0.189111] [info loss: 1.483900]\n",
            "[Epoch 31/200] [Batch 282/938] [D loss: 0.218180] [G loss: 0.570879] [info loss: 1.469267]\n",
            "[Epoch 31/200] [Batch 283/938] [D loss: 0.124430] [G loss: 0.206938] [info loss: 1.472299]\n",
            "[Epoch 31/200] [Batch 284/938] [D loss: 0.271838] [G loss: 0.294759] [info loss: 1.470749]\n",
            "[Epoch 31/200] [Batch 285/938] [D loss: 0.200069] [G loss: 0.183914] [info loss: 1.472219]\n",
            "[Epoch 31/200] [Batch 286/938] [D loss: 0.224899] [G loss: 0.441356] [info loss: 1.469923]\n",
            "[Epoch 31/200] [Batch 287/938] [D loss: 0.284984] [G loss: 0.261963] [info loss: 1.474118]\n",
            "[Epoch 31/200] [Batch 288/938] [D loss: 0.209322] [G loss: 0.405636] [info loss: 1.475862]\n",
            "[Epoch 31/200] [Batch 289/938] [D loss: 0.165920] [G loss: 0.211593] [info loss: 1.469699]\n",
            "[Epoch 31/200] [Batch 290/938] [D loss: 0.251893] [G loss: 0.323085] [info loss: 1.479323]\n",
            "[Epoch 31/200] [Batch 291/938] [D loss: 0.120967] [G loss: 0.307154] [info loss: 1.485676]\n",
            "[Epoch 31/200] [Batch 292/938] [D loss: 0.219991] [G loss: 0.216572] [info loss: 1.470261]\n",
            "[Epoch 31/200] [Batch 293/938] [D loss: 0.264639] [G loss: 0.389100] [info loss: 1.502377]\n",
            "[Epoch 31/200] [Batch 294/938] [D loss: 0.258990] [G loss: 0.419900] [info loss: 1.496491]\n",
            "[Epoch 31/200] [Batch 295/938] [D loss: 0.230738] [G loss: 0.318882] [info loss: 1.474091]\n",
            "[Epoch 31/200] [Batch 296/938] [D loss: 0.153009] [G loss: 0.435997] [info loss: 1.471445]\n",
            "[Epoch 31/200] [Batch 297/938] [D loss: 0.280736] [G loss: 0.348038] [info loss: 1.470658]\n",
            "[Epoch 31/200] [Batch 298/938] [D loss: 0.271017] [G loss: 0.353313] [info loss: 1.469992]\n",
            "[Epoch 31/200] [Batch 299/938] [D loss: 0.160185] [G loss: 0.324234] [info loss: 1.484202]\n",
            "[Epoch 31/200] [Batch 300/938] [D loss: 0.271522] [G loss: 0.567549] [info loss: 1.485035]\n",
            "[Epoch 31/200] [Batch 301/938] [D loss: 0.188195] [G loss: 0.386638] [info loss: 1.473380]\n",
            "[Epoch 31/200] [Batch 302/938] [D loss: 0.161397] [G loss: 0.291185] [info loss: 1.482248]\n",
            "[Epoch 31/200] [Batch 303/938] [D loss: 0.253749] [G loss: 0.285723] [info loss: 1.469331]\n",
            "[Epoch 31/200] [Batch 304/938] [D loss: 0.162113] [G loss: 0.450209] [info loss: 1.472575]\n",
            "[Epoch 31/200] [Batch 305/938] [D loss: 0.296547] [G loss: 0.608879] [info loss: 1.469331]\n",
            "[Epoch 31/200] [Batch 306/938] [D loss: 0.246226] [G loss: 0.546997] [info loss: 1.481618]\n",
            "[Epoch 31/200] [Batch 307/938] [D loss: 0.186261] [G loss: 0.335677] [info loss: 1.486424]\n",
            "[Epoch 31/200] [Batch 308/938] [D loss: 0.182486] [G loss: 0.284686] [info loss: 1.469156]\n",
            "[Epoch 31/200] [Batch 309/938] [D loss: 0.229582] [G loss: 0.307591] [info loss: 1.485028]\n",
            "[Epoch 31/200] [Batch 310/938] [D loss: 0.214120] [G loss: 0.405915] [info loss: 1.475757]\n",
            "[Epoch 31/200] [Batch 311/938] [D loss: 0.280792] [G loss: 0.479237] [info loss: 1.471497]\n",
            "[Epoch 31/200] [Batch 312/938] [D loss: 0.344896] [G loss: 0.471682] [info loss: 1.484241]\n",
            "[Epoch 31/200] [Batch 313/938] [D loss: 0.213946] [G loss: 0.284641] [info loss: 1.486268]\n",
            "[Epoch 31/200] [Batch 314/938] [D loss: 0.216150] [G loss: 0.386307] [info loss: 1.488815]\n",
            "[Epoch 31/200] [Batch 315/938] [D loss: 0.240665] [G loss: 0.227234] [info loss: 1.487740]\n",
            "[Epoch 31/200] [Batch 316/938] [D loss: 0.248079] [G loss: 0.484186] [info loss: 1.474380]\n",
            "[Epoch 31/200] [Batch 317/938] [D loss: 0.176180] [G loss: 0.225788] [info loss: 1.470261]\n",
            "[Epoch 31/200] [Batch 318/938] [D loss: 0.169976] [G loss: 0.449561] [info loss: 1.490061]\n",
            "[Epoch 31/200] [Batch 319/938] [D loss: 0.243638] [G loss: 0.227093] [info loss: 1.485677]\n",
            "[Epoch 31/200] [Batch 320/938] [D loss: 0.258296] [G loss: 0.353689] [info loss: 1.472179]\n",
            "[Epoch 31/200] [Batch 321/938] [D loss: 0.182771] [G loss: 0.344733] [info loss: 1.487980]\n",
            "[Epoch 31/200] [Batch 322/938] [D loss: 0.238285] [G loss: 0.240809] [info loss: 1.485155]\n",
            "[Epoch 31/200] [Batch 323/938] [D loss: 0.205099] [G loss: 0.417372] [info loss: 1.471174]\n",
            "[Epoch 31/200] [Batch 324/938] [D loss: 0.236133] [G loss: 0.376042] [info loss: 1.482689]\n",
            "[Epoch 31/200] [Batch 325/938] [D loss: 0.204443] [G loss: 0.539324] [info loss: 1.468993]\n",
            "[Epoch 31/200] [Batch 326/938] [D loss: 0.271055] [G loss: 0.320003] [info loss: 1.474874]\n",
            "[Epoch 31/200] [Batch 327/938] [D loss: 0.269492] [G loss: 0.137092] [info loss: 1.471604]\n",
            "[Epoch 31/200] [Batch 328/938] [D loss: 0.360429] [G loss: 0.162499] [info loss: 1.474150]\n",
            "[Epoch 31/200] [Batch 329/938] [D loss: 0.153527] [G loss: 0.258990] [info loss: 1.481832]\n",
            "[Epoch 31/200] [Batch 330/938] [D loss: 0.245026] [G loss: 0.397443] [info loss: 1.471766]\n",
            "[Epoch 31/200] [Batch 331/938] [D loss: 0.292731] [G loss: 0.616963] [info loss: 1.472552]\n",
            "[Epoch 31/200] [Batch 332/938] [D loss: 0.208432] [G loss: 0.557520] [info loss: 1.475002]\n",
            "[Epoch 31/200] [Batch 333/938] [D loss: 0.190791] [G loss: 0.184041] [info loss: 1.471148]\n",
            "[Epoch 31/200] [Batch 334/938] [D loss: 0.228737] [G loss: 0.186490] [info loss: 1.467454]\n",
            "[Epoch 31/200] [Batch 335/938] [D loss: 0.233929] [G loss: 0.331278] [info loss: 1.469112]\n",
            "[Epoch 31/200] [Batch 336/938] [D loss: 0.100215] [G loss: 0.251379] [info loss: 1.470059]\n",
            "[Epoch 31/200] [Batch 337/938] [D loss: 0.177584] [G loss: 0.383378] [info loss: 1.482911]\n",
            "[Epoch 31/200] [Batch 338/938] [D loss: 0.239010] [G loss: 0.202548] [info loss: 1.480534]\n",
            "[Epoch 31/200] [Batch 339/938] [D loss: 0.216666] [G loss: 0.392248] [info loss: 1.468603]\n",
            "[Epoch 31/200] [Batch 340/938] [D loss: 0.157173] [G loss: 0.360301] [info loss: 1.469591]\n",
            "[Epoch 31/200] [Batch 341/938] [D loss: 0.204994] [G loss: 0.632822] [info loss: 1.471221]\n",
            "[Epoch 31/200] [Batch 342/938] [D loss: 0.239493] [G loss: 0.362136] [info loss: 1.489363]\n",
            "[Epoch 31/200] [Batch 343/938] [D loss: 0.234697] [G loss: 0.454217] [info loss: 1.471439]\n",
            "[Epoch 31/200] [Batch 344/938] [D loss: 0.233047] [G loss: 0.230545] [info loss: 1.481065]\n",
            "[Epoch 31/200] [Batch 345/938] [D loss: 0.238717] [G loss: 0.308061] [info loss: 1.471420]\n",
            "[Epoch 31/200] [Batch 346/938] [D loss: 0.256726] [G loss: 0.291164] [info loss: 1.470260]\n",
            "[Epoch 31/200] [Batch 347/938] [D loss: 0.183391] [G loss: 0.390830] [info loss: 1.469953]\n",
            "[Epoch 31/200] [Batch 348/938] [D loss: 0.164355] [G loss: 0.262317] [info loss: 1.469154]\n",
            "[Epoch 31/200] [Batch 349/938] [D loss: 0.197924] [G loss: 0.322069] [info loss: 1.468965]\n",
            "[Epoch 31/200] [Batch 350/938] [D loss: 0.217537] [G loss: 0.138213] [info loss: 1.476893]\n",
            "[Epoch 31/200] [Batch 351/938] [D loss: 0.171578] [G loss: 0.395898] [info loss: 1.467827]\n",
            "[Epoch 31/200] [Batch 352/938] [D loss: 0.314024] [G loss: 0.624645] [info loss: 1.475125]\n",
            "[Epoch 31/200] [Batch 353/938] [D loss: 0.278714] [G loss: 0.346224] [info loss: 1.472874]\n",
            "[Epoch 31/200] [Batch 354/938] [D loss: 0.209725] [G loss: 0.374867] [info loss: 1.470404]\n",
            "[Epoch 31/200] [Batch 355/938] [D loss: 0.157254] [G loss: 0.217045] [info loss: 1.472442]\n",
            "[Epoch 31/200] [Batch 356/938] [D loss: 0.260826] [G loss: 0.135048] [info loss: 1.499202]\n",
            "[Epoch 31/200] [Batch 357/938] [D loss: 0.228468] [G loss: 0.238792] [info loss: 1.469993]\n",
            "[Epoch 31/200] [Batch 358/938] [D loss: 0.295656] [G loss: 0.387913] [info loss: 1.485748]\n",
            "[Epoch 31/200] [Batch 359/938] [D loss: 0.180869] [G loss: 0.181368] [info loss: 1.470360]\n",
            "[Epoch 31/200] [Batch 360/938] [D loss: 0.225736] [G loss: 0.167311] [info loss: 1.469592]\n",
            "[Epoch 31/200] [Batch 361/938] [D loss: 0.234716] [G loss: 0.267439] [info loss: 1.508959]\n",
            "[Epoch 31/200] [Batch 362/938] [D loss: 0.293540] [G loss: 0.312045] [info loss: 1.486391]\n",
            "[Epoch 31/200] [Batch 363/938] [D loss: 0.212675] [G loss: 0.223518] [info loss: 1.471632]\n",
            "[Epoch 31/200] [Batch 364/938] [D loss: 0.286929] [G loss: 0.525162] [info loss: 1.477921]\n",
            "[Epoch 31/200] [Batch 365/938] [D loss: 0.253578] [G loss: 0.253687] [info loss: 1.469683]\n",
            "[Epoch 31/200] [Batch 366/938] [D loss: 0.134028] [G loss: 0.577752] [info loss: 1.470024]\n",
            "[Epoch 31/200] [Batch 367/938] [D loss: 0.314608] [G loss: 0.589986] [info loss: 1.476220]\n",
            "[Epoch 31/200] [Batch 368/938] [D loss: 0.157376] [G loss: 0.418191] [info loss: 1.471754]\n",
            "[Epoch 31/200] [Batch 369/938] [D loss: 0.160178] [G loss: 0.261342] [info loss: 1.484887]\n",
            "[Epoch 31/200] [Batch 370/938] [D loss: 0.300456] [G loss: 0.264085] [info loss: 1.502460]\n",
            "[Epoch 31/200] [Batch 371/938] [D loss: 0.246413] [G loss: 0.347872] [info loss: 1.470719]\n",
            "[Epoch 31/200] [Batch 372/938] [D loss: 0.214182] [G loss: 0.473891] [info loss: 1.474777]\n",
            "[Epoch 31/200] [Batch 373/938] [D loss: 0.149736] [G loss: 0.242384] [info loss: 1.478053]\n",
            "[Epoch 31/200] [Batch 374/938] [D loss: 0.275024] [G loss: 0.713881] [info loss: 1.470515]\n",
            "[Epoch 31/200] [Batch 375/938] [D loss: 0.274219] [G loss: 0.709523] [info loss: 1.486238]\n",
            "[Epoch 31/200] [Batch 376/938] [D loss: 0.209645] [G loss: 0.577621] [info loss: 1.474883]\n",
            "[Epoch 31/200] [Batch 377/938] [D loss: 0.206888] [G loss: 0.338486] [info loss: 1.474401]\n",
            "[Epoch 31/200] [Batch 378/938] [D loss: 0.238688] [G loss: 0.352992] [info loss: 1.472060]\n",
            "[Epoch 31/200] [Batch 379/938] [D loss: 0.123476] [G loss: 0.277220] [info loss: 1.477704]\n",
            "[Epoch 31/200] [Batch 380/938] [D loss: 0.244697] [G loss: 0.452869] [info loss: 1.469654]\n",
            "[Epoch 31/200] [Batch 381/938] [D loss: 0.193631] [G loss: 0.296355] [info loss: 1.493636]\n",
            "[Epoch 31/200] [Batch 382/938] [D loss: 0.304409] [G loss: 0.273693] [info loss: 1.471007]\n",
            "[Epoch 31/200] [Batch 383/938] [D loss: 0.142378] [G loss: 0.300946] [info loss: 1.469127]\n",
            "[Epoch 31/200] [Batch 384/938] [D loss: 0.191373] [G loss: 0.351137] [info loss: 1.470054]\n",
            "[Epoch 31/200] [Batch 385/938] [D loss: 0.151428] [G loss: 0.492344] [info loss: 1.469983]\n",
            "[Epoch 31/200] [Batch 386/938] [D loss: 0.245241] [G loss: 0.312574] [info loss: 1.471852]\n",
            "[Epoch 31/200] [Batch 387/938] [D loss: 0.174135] [G loss: 0.365459] [info loss: 1.477432]\n",
            "[Epoch 31/200] [Batch 388/938] [D loss: 0.216454] [G loss: 0.253734] [info loss: 1.498221]\n",
            "[Epoch 31/200] [Batch 389/938] [D loss: 0.322712] [G loss: 0.262116] [info loss: 1.476169]\n",
            "[Epoch 31/200] [Batch 390/938] [D loss: 0.200003] [G loss: 0.356304] [info loss: 1.475291]\n",
            "[Epoch 31/200] [Batch 391/938] [D loss: 0.200256] [G loss: 0.511842] [info loss: 1.501704]\n",
            "[Epoch 31/200] [Batch 392/938] [D loss: 0.179316] [G loss: 0.201947] [info loss: 1.469190]\n",
            "[Epoch 31/200] [Batch 393/938] [D loss: 0.117261] [G loss: 0.289294] [info loss: 1.481081]\n",
            "[Epoch 31/200] [Batch 394/938] [D loss: 0.310476] [G loss: 0.293071] [info loss: 1.469403]\n",
            "[Epoch 31/200] [Batch 395/938] [D loss: 0.200222] [G loss: 0.501412] [info loss: 1.470237]\n",
            "[Epoch 31/200] [Batch 396/938] [D loss: 0.269302] [G loss: 0.248471] [info loss: 1.483262]\n",
            "[Epoch 31/200] [Batch 397/938] [D loss: 0.180523] [G loss: 0.401300] [info loss: 1.487888]\n",
            "[Epoch 31/200] [Batch 398/938] [D loss: 0.209538] [G loss: 0.161006] [info loss: 1.475369]\n",
            "[Epoch 31/200] [Batch 399/938] [D loss: 0.293240] [G loss: 0.211018] [info loss: 1.473314]\n",
            "[Epoch 31/200] [Batch 400/938] [D loss: 0.179183] [G loss: 0.382781] [info loss: 1.496142]\n",
            "[Epoch 31/200] [Batch 401/938] [D loss: 0.367706] [G loss: 0.413300] [info loss: 1.489830]\n",
            "[Epoch 31/200] [Batch 402/938] [D loss: 0.316524] [G loss: 0.323169] [info loss: 1.468082]\n",
            "[Epoch 31/200] [Batch 403/938] [D loss: 0.171751] [G loss: 0.337220] [info loss: 1.475624]\n",
            "[Epoch 31/200] [Batch 404/938] [D loss: 0.267534] [G loss: 0.324345] [info loss: 1.474855]\n",
            "[Epoch 31/200] [Batch 405/938] [D loss: 0.241826] [G loss: 0.231574] [info loss: 1.487930]\n",
            "[Epoch 31/200] [Batch 406/938] [D loss: 0.263287] [G loss: 0.401975] [info loss: 1.479132]\n",
            "[Epoch 31/200] [Batch 407/938] [D loss: 0.122691] [G loss: 0.517116] [info loss: 1.473858]\n",
            "[Epoch 31/200] [Batch 408/938] [D loss: 0.250322] [G loss: 0.244421] [info loss: 1.472705]\n",
            "[Epoch 31/200] [Batch 409/938] [D loss: 0.141615] [G loss: 0.453568] [info loss: 1.469388]\n",
            "[Epoch 31/200] [Batch 410/938] [D loss: 0.200155] [G loss: 0.630422] [info loss: 1.473354]\n",
            "[Epoch 31/200] [Batch 411/938] [D loss: 0.193344] [G loss: 0.333541] [info loss: 1.470798]\n",
            "[Epoch 31/200] [Batch 412/938] [D loss: 0.189381] [G loss: 0.118218] [info loss: 1.473368]\n",
            "[Epoch 31/200] [Batch 413/938] [D loss: 0.135879] [G loss: 0.175539] [info loss: 1.473698]\n",
            "[Epoch 31/200] [Batch 414/938] [D loss: 0.208706] [G loss: 0.216520] [info loss: 1.469559]\n",
            "[Epoch 31/200] [Batch 415/938] [D loss: 0.260696] [G loss: 0.151901] [info loss: 1.470313]\n",
            "[Epoch 31/200] [Batch 416/938] [D loss: 0.275965] [G loss: 0.461946] [info loss: 1.470647]\n",
            "[Epoch 31/200] [Batch 417/938] [D loss: 0.227949] [G loss: 0.488080] [info loss: 1.483969]\n",
            "[Epoch 31/200] [Batch 418/938] [D loss: 0.211787] [G loss: 0.472460] [info loss: 1.471183]\n",
            "[Epoch 31/200] [Batch 419/938] [D loss: 0.115943] [G loss: 0.357281] [info loss: 1.485241]\n",
            "[Epoch 31/200] [Batch 420/938] [D loss: 0.254887] [G loss: 0.342505] [info loss: 1.469260]\n",
            "[Epoch 31/200] [Batch 421/938] [D loss: 0.278204] [G loss: 0.350430] [info loss: 1.495879]\n",
            "[Epoch 31/200] [Batch 422/938] [D loss: 0.354315] [G loss: 0.523761] [info loss: 1.484203]\n",
            "[Epoch 31/200] [Batch 423/938] [D loss: 0.253793] [G loss: 0.335973] [info loss: 1.502608]\n",
            "[Epoch 31/200] [Batch 424/938] [D loss: 0.177061] [G loss: 0.362830] [info loss: 1.468269]\n",
            "[Epoch 31/200] [Batch 425/938] [D loss: 0.188326] [G loss: 0.334427] [info loss: 1.471123]\n",
            "[Epoch 31/200] [Batch 426/938] [D loss: 0.253836] [G loss: 0.342287] [info loss: 1.497984]\n",
            "[Epoch 31/200] [Batch 427/938] [D loss: 0.227757] [G loss: 0.206435] [info loss: 1.482055]\n",
            "[Epoch 31/200] [Batch 428/938] [D loss: 0.208264] [G loss: 0.227933] [info loss: 1.482873]\n",
            "[Epoch 31/200] [Batch 429/938] [D loss: 0.264832] [G loss: 0.467026] [info loss: 1.484854]\n",
            "[Epoch 31/200] [Batch 430/938] [D loss: 0.102882] [G loss: 0.347382] [info loss: 1.475104]\n",
            "[Epoch 31/200] [Batch 431/938] [D loss: 0.265624] [G loss: 0.217183] [info loss: 1.477368]\n",
            "[Epoch 31/200] [Batch 432/938] [D loss: 0.389009] [G loss: 0.367367] [info loss: 1.483663]\n",
            "[Epoch 31/200] [Batch 433/938] [D loss: 0.170017] [G loss: 0.287205] [info loss: 1.470029]\n",
            "[Epoch 31/200] [Batch 434/938] [D loss: 0.275353] [G loss: 0.168898] [info loss: 1.487821]\n",
            "[Epoch 31/200] [Batch 435/938] [D loss: 0.261814] [G loss: 0.324742] [info loss: 1.471729]\n",
            "[Epoch 31/200] [Batch 436/938] [D loss: 0.194465] [G loss: 0.612864] [info loss: 1.490574]\n",
            "[Epoch 31/200] [Batch 437/938] [D loss: 0.190025] [G loss: 0.415537] [info loss: 1.471222]\n",
            "[Epoch 31/200] [Batch 438/938] [D loss: 0.173595] [G loss: 0.469787] [info loss: 1.473429]\n",
            "[Epoch 31/200] [Batch 439/938] [D loss: 0.447033] [G loss: 0.423331] [info loss: 1.489353]\n",
            "[Epoch 31/200] [Batch 440/938] [D loss: 0.325453] [G loss: 0.420740] [info loss: 1.479967]\n",
            "[Epoch 31/200] [Batch 441/938] [D loss: 0.300042] [G loss: 0.396051] [info loss: 1.483250]\n",
            "[Epoch 31/200] [Batch 442/938] [D loss: 0.193708] [G loss: 0.347683] [info loss: 1.477854]\n",
            "[Epoch 31/200] [Batch 443/938] [D loss: 0.293429] [G loss: 0.201914] [info loss: 1.482564]\n",
            "[Epoch 31/200] [Batch 444/938] [D loss: 0.250385] [G loss: 0.487413] [info loss: 1.486131]\n",
            "[Epoch 31/200] [Batch 445/938] [D loss: 0.179465] [G loss: 0.186504] [info loss: 1.477730]\n",
            "[Epoch 31/200] [Batch 446/938] [D loss: 0.181136] [G loss: 0.238266] [info loss: 1.475311]\n",
            "[Epoch 31/200] [Batch 447/938] [D loss: 0.120048] [G loss: 0.324668] [info loss: 1.496974]\n",
            "[Epoch 31/200] [Batch 448/938] [D loss: 0.208364] [G loss: 0.262238] [info loss: 1.498392]\n",
            "[Epoch 31/200] [Batch 449/938] [D loss: 0.199778] [G loss: 0.635405] [info loss: 1.469387]\n",
            "[Epoch 31/200] [Batch 450/938] [D loss: 0.125115] [G loss: 0.181448] [info loss: 1.471483]\n",
            "[Epoch 31/200] [Batch 451/938] [D loss: 0.331986] [G loss: 0.274538] [info loss: 1.486856]\n",
            "[Epoch 31/200] [Batch 452/938] [D loss: 0.252942] [G loss: 0.243275] [info loss: 1.473000]\n",
            "[Epoch 31/200] [Batch 453/938] [D loss: 0.167948] [G loss: 0.476112] [info loss: 1.486500]\n",
            "[Epoch 31/200] [Batch 454/938] [D loss: 0.237499] [G loss: 0.440276] [info loss: 1.468905]\n",
            "[Epoch 31/200] [Batch 455/938] [D loss: 0.326361] [G loss: 0.278124] [info loss: 1.471032]\n",
            "[Epoch 31/200] [Batch 456/938] [D loss: 0.143438] [G loss: 0.131560] [info loss: 1.503704]\n",
            "[Epoch 31/200] [Batch 457/938] [D loss: 0.247319] [G loss: 0.326772] [info loss: 1.497306]\n",
            "[Epoch 31/200] [Batch 458/938] [D loss: 0.281977] [G loss: 0.618161] [info loss: 1.471342]\n",
            "[Epoch 31/200] [Batch 459/938] [D loss: 0.109326] [G loss: 0.419361] [info loss: 1.485290]\n",
            "[Epoch 31/200] [Batch 460/938] [D loss: 0.167360] [G loss: 0.621336] [info loss: 1.470493]\n",
            "[Epoch 31/200] [Batch 461/938] [D loss: 0.262697] [G loss: 0.383217] [info loss: 1.473567]\n",
            "[Epoch 31/200] [Batch 462/938] [D loss: 0.198625] [G loss: 0.270538] [info loss: 1.471906]\n",
            "[Epoch 31/200] [Batch 463/938] [D loss: 0.164658] [G loss: 0.328436] [info loss: 1.484452]\n",
            "[Epoch 31/200] [Batch 464/938] [D loss: 0.239412] [G loss: 0.532338] [info loss: 1.478019]\n",
            "[Epoch 31/200] [Batch 465/938] [D loss: 0.164584] [G loss: 0.225392] [info loss: 1.494815]\n",
            "[Epoch 31/200] [Batch 466/938] [D loss: 0.242863] [G loss: 0.227708] [info loss: 1.477504]\n",
            "[Epoch 31/200] [Batch 467/938] [D loss: 0.170547] [G loss: 0.514491] [info loss: 1.501649]\n",
            "[Epoch 31/200] [Batch 468/938] [D loss: 0.235982] [G loss: 0.457271] [info loss: 1.473438]\n",
            "[Epoch 31/200] [Batch 469/938] [D loss: 0.292062] [G loss: 0.613782] [info loss: 1.468924]\n",
            "[Epoch 31/200] [Batch 470/938] [D loss: 0.311159] [G loss: 0.270531] [info loss: 1.474244]\n",
            "[Epoch 31/200] [Batch 471/938] [D loss: 0.244839] [G loss: 0.432860] [info loss: 1.483980]\n",
            "[Epoch 31/200] [Batch 472/938] [D loss: 0.314006] [G loss: 0.294923] [info loss: 1.468788]\n",
            "[Epoch 31/200] [Batch 473/938] [D loss: 0.231335] [G loss: 0.329253] [info loss: 1.483521]\n",
            "[Epoch 31/200] [Batch 474/938] [D loss: 0.226510] [G loss: 0.466532] [info loss: 1.497975]\n",
            "[Epoch 31/200] [Batch 475/938] [D loss: 0.248848] [G loss: 0.566561] [info loss: 1.471815]\n",
            "[Epoch 31/200] [Batch 476/938] [D loss: 0.191845] [G loss: 0.522306] [info loss: 1.489241]\n",
            "[Epoch 31/200] [Batch 477/938] [D loss: 0.174629] [G loss: 0.778342] [info loss: 1.469048]\n",
            "[Epoch 31/200] [Batch 478/938] [D loss: 0.292661] [G loss: 0.469635] [info loss: 1.470302]\n",
            "[Epoch 31/200] [Batch 479/938] [D loss: 0.184784] [G loss: 0.445336] [info loss: 1.485212]\n",
            "[Epoch 31/200] [Batch 480/938] [D loss: 0.263532] [G loss: 0.415392] [info loss: 1.468881]\n",
            "[Epoch 31/200] [Batch 481/938] [D loss: 0.230620] [G loss: 0.162893] [info loss: 1.472017]\n",
            "[Epoch 31/200] [Batch 482/938] [D loss: 0.265580] [G loss: 0.321864] [info loss: 1.475157]\n",
            "[Epoch 31/200] [Batch 483/938] [D loss: 0.184792] [G loss: 0.218617] [info loss: 1.470775]\n",
            "[Epoch 31/200] [Batch 484/938] [D loss: 0.203975] [G loss: 0.677445] [info loss: 1.470509]\n",
            "[Epoch 31/200] [Batch 485/938] [D loss: 0.189572] [G loss: 0.474275] [info loss: 1.470528]\n",
            "[Epoch 31/200] [Batch 486/938] [D loss: 0.314141] [G loss: 0.504086] [info loss: 1.470056]\n",
            "[Epoch 31/200] [Batch 487/938] [D loss: 0.208710] [G loss: 0.555785] [info loss: 1.473872]\n",
            "[Epoch 31/200] [Batch 488/938] [D loss: 0.223109] [G loss: 0.256022] [info loss: 1.501676]\n",
            "[Epoch 31/200] [Batch 489/938] [D loss: 0.298081] [G loss: 0.234177] [info loss: 1.471569]\n",
            "[Epoch 31/200] [Batch 490/938] [D loss: 0.190365] [G loss: 0.248413] [info loss: 1.491294]\n",
            "[Epoch 31/200] [Batch 491/938] [D loss: 0.364908] [G loss: 0.295458] [info loss: 1.470265]\n",
            "[Epoch 31/200] [Batch 492/938] [D loss: 0.210895] [G loss: 0.640775] [info loss: 1.471130]\n",
            "[Epoch 31/200] [Batch 493/938] [D loss: 0.258639] [G loss: 0.246703] [info loss: 1.475278]\n",
            "[Epoch 31/200] [Batch 494/938] [D loss: 0.429737] [G loss: 0.349520] [info loss: 1.489057]\n",
            "[Epoch 31/200] [Batch 495/938] [D loss: 0.243851] [G loss: 0.481884] [info loss: 1.474007]\n",
            "[Epoch 31/200] [Batch 496/938] [D loss: 0.264673] [G loss: 0.346263] [info loss: 1.497480]\n",
            "[Epoch 31/200] [Batch 497/938] [D loss: 0.271925] [G loss: 0.138762] [info loss: 1.508057]\n",
            "[Epoch 31/200] [Batch 498/938] [D loss: 0.263299] [G loss: 0.169621] [info loss: 1.487455]\n",
            "[Epoch 31/200] [Batch 499/938] [D loss: 0.223977] [G loss: 0.319312] [info loss: 1.473955]\n",
            "[Epoch 31/200] [Batch 500/938] [D loss: 0.242286] [G loss: 0.538336] [info loss: 1.477699]\n",
            "[Epoch 31/200] [Batch 501/938] [D loss: 0.270725] [G loss: 0.703073] [info loss: 1.488486]\n",
            "[Epoch 31/200] [Batch 502/938] [D loss: 0.276444] [G loss: 0.462744] [info loss: 1.483911]\n",
            "[Epoch 31/200] [Batch 503/938] [D loss: 0.322178] [G loss: 0.270002] [info loss: 1.482735]\n",
            "[Epoch 31/200] [Batch 504/938] [D loss: 0.163484] [G loss: 0.324352] [info loss: 1.500026]\n",
            "[Epoch 31/200] [Batch 505/938] [D loss: 0.169345] [G loss: 0.174319] [info loss: 1.473237]\n",
            "[Epoch 31/200] [Batch 506/938] [D loss: 0.228616] [G loss: 0.266928] [info loss: 1.485548]\n",
            "[Epoch 31/200] [Batch 507/938] [D loss: 0.264806] [G loss: 0.362899] [info loss: 1.469718]\n",
            "[Epoch 31/200] [Batch 508/938] [D loss: 0.304251] [G loss: 0.379920] [info loss: 1.503636]\n",
            "[Epoch 31/200] [Batch 509/938] [D loss: 0.109064] [G loss: 0.432451] [info loss: 1.475555]\n",
            "[Epoch 31/200] [Batch 510/938] [D loss: 0.295774] [G loss: 0.292299] [info loss: 1.468940]\n",
            "[Epoch 31/200] [Batch 511/938] [D loss: 0.234273] [G loss: 0.495220] [info loss: 1.485374]\n",
            "[Epoch 31/200] [Batch 512/938] [D loss: 0.162486] [G loss: 0.454361] [info loss: 1.480874]\n",
            "[Epoch 31/200] [Batch 513/938] [D loss: 0.192867] [G loss: 0.376982] [info loss: 1.483197]\n",
            "[Epoch 31/200] [Batch 514/938] [D loss: 0.146493] [G loss: 0.254481] [info loss: 1.475201]\n",
            "[Epoch 31/200] [Batch 515/938] [D loss: 0.292499] [G loss: 0.113355] [info loss: 1.480424]\n",
            "[Epoch 31/200] [Batch 516/938] [D loss: 0.266832] [G loss: 0.395931] [info loss: 1.471667]\n",
            "[Epoch 31/200] [Batch 517/938] [D loss: 0.192233] [G loss: 0.332257] [info loss: 1.487525]\n",
            "[Epoch 31/200] [Batch 518/938] [D loss: 0.163385] [G loss: 0.447538] [info loss: 1.469002]\n",
            "[Epoch 31/200] [Batch 519/938] [D loss: 0.308564] [G loss: 0.413907] [info loss: 1.482517]\n",
            "[Epoch 31/200] [Batch 520/938] [D loss: 0.220661] [G loss: 0.299284] [info loss: 1.490836]\n",
            "[Epoch 31/200] [Batch 521/938] [D loss: 0.150624] [G loss: 0.600109] [info loss: 1.468706]\n",
            "[Epoch 31/200] [Batch 522/938] [D loss: 0.230460] [G loss: 0.465550] [info loss: 1.470993]\n",
            "[Epoch 31/200] [Batch 523/938] [D loss: 0.218606] [G loss: 0.235044] [info loss: 1.483402]\n",
            "[Epoch 31/200] [Batch 524/938] [D loss: 0.176696] [G loss: 0.212076] [info loss: 1.480439]\n",
            "[Epoch 31/200] [Batch 525/938] [D loss: 0.127912] [G loss: 0.193403] [info loss: 1.470852]\n",
            "[Epoch 31/200] [Batch 526/938] [D loss: 0.143397] [G loss: 0.235241] [info loss: 1.469822]\n",
            "[Epoch 31/200] [Batch 527/938] [D loss: 0.187660] [G loss: 0.146079] [info loss: 1.469580]\n",
            "[Epoch 31/200] [Batch 528/938] [D loss: 0.194372] [G loss: 0.253014] [info loss: 1.469834]\n",
            "[Epoch 31/200] [Batch 529/938] [D loss: 0.235376] [G loss: 0.267079] [info loss: 1.480539]\n",
            "[Epoch 31/200] [Batch 530/938] [D loss: 0.288774] [G loss: 0.442387] [info loss: 1.470256]\n",
            "[Epoch 31/200] [Batch 531/938] [D loss: 0.198587] [G loss: 0.443782] [info loss: 1.470888]\n",
            "[Epoch 31/200] [Batch 532/938] [D loss: 0.250356] [G loss: 0.289763] [info loss: 1.484893]\n",
            "[Epoch 31/200] [Batch 533/938] [D loss: 0.294803] [G loss: 0.212346] [info loss: 1.469549]\n",
            "[Epoch 31/200] [Batch 534/938] [D loss: 0.224023] [G loss: 0.320013] [info loss: 1.472333]\n",
            "[Epoch 31/200] [Batch 535/938] [D loss: 0.300645] [G loss: 0.651279] [info loss: 1.486508]\n",
            "[Epoch 31/200] [Batch 536/938] [D loss: 0.165748] [G loss: 0.176868] [info loss: 1.482098]\n",
            "[Epoch 31/200] [Batch 537/938] [D loss: 0.243326] [G loss: 0.391096] [info loss: 1.469441]\n",
            "[Epoch 31/200] [Batch 538/938] [D loss: 0.199393] [G loss: 0.323243] [info loss: 1.471070]\n",
            "[Epoch 31/200] [Batch 539/938] [D loss: 0.182722] [G loss: 0.437285] [info loss: 1.497833]\n",
            "[Epoch 31/200] [Batch 540/938] [D loss: 0.216179] [G loss: 0.336209] [info loss: 1.471452]\n",
            "[Epoch 31/200] [Batch 541/938] [D loss: 0.266882] [G loss: 0.605572] [info loss: 1.477990]\n",
            "[Epoch 31/200] [Batch 542/938] [D loss: 0.238062] [G loss: 0.309402] [info loss: 1.468003]\n",
            "[Epoch 31/200] [Batch 543/938] [D loss: 0.162073] [G loss: 0.211028] [info loss: 1.487710]\n",
            "[Epoch 31/200] [Batch 544/938] [D loss: 0.278998] [G loss: 0.280524] [info loss: 1.472375]\n",
            "[Epoch 31/200] [Batch 545/938] [D loss: 0.131526] [G loss: 0.491026] [info loss: 1.470471]\n",
            "[Epoch 31/200] [Batch 546/938] [D loss: 0.203481] [G loss: 0.439276] [info loss: 1.491784]\n",
            "[Epoch 31/200] [Batch 547/938] [D loss: 0.219124] [G loss: 0.399219] [info loss: 1.479701]\n",
            "[Epoch 31/200] [Batch 548/938] [D loss: 0.201179] [G loss: 0.223141] [info loss: 1.469347]\n",
            "[Epoch 31/200] [Batch 549/938] [D loss: 0.185148] [G loss: 0.384862] [info loss: 1.473299]\n",
            "[Epoch 31/200] [Batch 550/938] [D loss: 0.193087] [G loss: 0.402608] [info loss: 1.470096]\n",
            "[Epoch 31/200] [Batch 551/938] [D loss: 0.094832] [G loss: 0.287536] [info loss: 1.492154]\n",
            "[Epoch 31/200] [Batch 552/938] [D loss: 0.201059] [G loss: 0.418205] [info loss: 1.472804]\n",
            "[Epoch 31/200] [Batch 553/938] [D loss: 0.265031] [G loss: 0.728233] [info loss: 1.469653]\n",
            "[Epoch 31/200] [Batch 554/938] [D loss: 0.229941] [G loss: 0.335397] [info loss: 1.469039]\n",
            "[Epoch 31/200] [Batch 555/938] [D loss: 0.115419] [G loss: 0.245605] [info loss: 1.469392]\n",
            "[Epoch 31/200] [Batch 556/938] [D loss: 0.240864] [G loss: 0.336107] [info loss: 1.499173]\n",
            "[Epoch 31/200] [Batch 557/938] [D loss: 0.205535] [G loss: 0.384672] [info loss: 1.499367]\n",
            "[Epoch 31/200] [Batch 558/938] [D loss: 0.144796] [G loss: 0.453834] [info loss: 1.469491]\n",
            "[Epoch 31/200] [Batch 559/938] [D loss: 0.305239] [G loss: 0.333277] [info loss: 1.470995]\n",
            "[Epoch 31/200] [Batch 560/938] [D loss: 0.174767] [G loss: 0.209859] [info loss: 1.472344]\n",
            "[Epoch 31/200] [Batch 561/938] [D loss: 0.270305] [G loss: 0.476575] [info loss: 1.490951]\n",
            "[Epoch 31/200] [Batch 562/938] [D loss: 0.154177] [G loss: 0.241289] [info loss: 1.492781]\n",
            "[Epoch 31/200] [Batch 563/938] [D loss: 0.334428] [G loss: 0.291063] [info loss: 1.487929]\n",
            "[Epoch 31/200] [Batch 564/938] [D loss: 0.252395] [G loss: 0.252181] [info loss: 1.495024]\n",
            "[Epoch 31/200] [Batch 565/938] [D loss: 0.111415] [G loss: 0.525125] [info loss: 1.470020]\n",
            "[Epoch 31/200] [Batch 566/938] [D loss: 0.334071] [G loss: 0.298026] [info loss: 1.477818]\n",
            "[Epoch 31/200] [Batch 567/938] [D loss: 0.251648] [G loss: 0.328115] [info loss: 1.470119]\n",
            "[Epoch 31/200] [Batch 568/938] [D loss: 0.214122] [G loss: 0.680369] [info loss: 1.472055]\n",
            "[Epoch 31/200] [Batch 569/938] [D loss: 0.185154] [G loss: 0.317749] [info loss: 1.469213]\n",
            "[Epoch 31/200] [Batch 570/938] [D loss: 0.261984] [G loss: 0.109857] [info loss: 1.469563]\n",
            "[Epoch 31/200] [Batch 571/938] [D loss: 0.230404] [G loss: 0.144158] [info loss: 1.469457]\n",
            "[Epoch 31/200] [Batch 572/938] [D loss: 0.241949] [G loss: 0.346054] [info loss: 1.485201]\n",
            "[Epoch 31/200] [Batch 573/938] [D loss: 0.235762] [G loss: 0.391880] [info loss: 1.469330]\n",
            "[Epoch 31/200] [Batch 574/938] [D loss: 0.194852] [G loss: 0.432594] [info loss: 1.486868]\n",
            "[Epoch 31/200] [Batch 575/938] [D loss: 0.214272] [G loss: 0.299785] [info loss: 1.493191]\n",
            "[Epoch 31/200] [Batch 576/938] [D loss: 0.195984] [G loss: 0.391321] [info loss: 1.470649]\n",
            "[Epoch 31/200] [Batch 577/938] [D loss: 0.251445] [G loss: 0.181616] [info loss: 1.491407]\n",
            "[Epoch 31/200] [Batch 578/938] [D loss: 0.175119] [G loss: 0.117468] [info loss: 1.471867]\n",
            "[Epoch 31/200] [Batch 579/938] [D loss: 0.338596] [G loss: 0.322280] [info loss: 1.483103]\n",
            "[Epoch 31/200] [Batch 580/938] [D loss: 0.210892] [G loss: 0.395439] [info loss: 1.471682]\n",
            "[Epoch 31/200] [Batch 581/938] [D loss: 0.298190] [G loss: 0.601577] [info loss: 1.494089]\n",
            "[Epoch 31/200] [Batch 582/938] [D loss: 0.178087] [G loss: 0.118478] [info loss: 1.472059]\n",
            "[Epoch 31/200] [Batch 583/938] [D loss: 0.140396] [G loss: 0.227623] [info loss: 1.468892]\n",
            "[Epoch 31/200] [Batch 584/938] [D loss: 0.220866] [G loss: 0.334669] [info loss: 1.480780]\n",
            "[Epoch 31/200] [Batch 585/938] [D loss: 0.301831] [G loss: 0.433011] [info loss: 1.471674]\n",
            "[Epoch 31/200] [Batch 586/938] [D loss: 0.257296] [G loss: 0.504812] [info loss: 1.472183]\n",
            "[Epoch 31/200] [Batch 587/938] [D loss: 0.236967] [G loss: 0.334793] [info loss: 1.489461]\n",
            "[Epoch 31/200] [Batch 588/938] [D loss: 0.294695] [G loss: 0.237577] [info loss: 1.469664]\n",
            "[Epoch 31/200] [Batch 589/938] [D loss: 0.250388] [G loss: 0.480423] [info loss: 1.471385]\n",
            "[Epoch 31/200] [Batch 590/938] [D loss: 0.165082] [G loss: 0.314540] [info loss: 1.500457]\n",
            "[Epoch 31/200] [Batch 591/938] [D loss: 0.266577] [G loss: 0.254457] [info loss: 1.482976]\n",
            "[Epoch 31/200] [Batch 592/938] [D loss: 0.238669] [G loss: 0.653024] [info loss: 1.470553]\n",
            "[Epoch 31/200] [Batch 593/938] [D loss: 0.336811] [G loss: 0.412272] [info loss: 1.470858]\n",
            "[Epoch 31/200] [Batch 594/938] [D loss: 0.210609] [G loss: 0.246962] [info loss: 1.474102]\n",
            "[Epoch 31/200] [Batch 595/938] [D loss: 0.221898] [G loss: 0.392480] [info loss: 1.475645]\n",
            "[Epoch 31/200] [Batch 596/938] [D loss: 0.249809] [G loss: 0.183544] [info loss: 1.470559]\n",
            "[Epoch 31/200] [Batch 597/938] [D loss: 0.201910] [G loss: 0.266948] [info loss: 1.489416]\n",
            "[Epoch 31/200] [Batch 598/938] [D loss: 0.182275] [G loss: 0.315211] [info loss: 1.469612]\n",
            "[Epoch 31/200] [Batch 599/938] [D loss: 0.201273] [G loss: 0.393048] [info loss: 1.486192]\n",
            "[Epoch 31/200] [Batch 600/938] [D loss: 0.194616] [G loss: 0.319601] [info loss: 1.469748]\n",
            "[Epoch 31/200] [Batch 601/938] [D loss: 0.222488] [G loss: 0.404621] [info loss: 1.470589]\n",
            "[Epoch 31/200] [Batch 602/938] [D loss: 0.246116] [G loss: 0.347191] [info loss: 1.476331]\n",
            "[Epoch 31/200] [Batch 603/938] [D loss: 0.274705] [G loss: 0.256821] [info loss: 1.474271]\n",
            "[Epoch 31/200] [Batch 604/938] [D loss: 0.347483] [G loss: 0.250939] [info loss: 1.487086]\n",
            "[Epoch 31/200] [Batch 605/938] [D loss: 0.310349] [G loss: 0.202611] [info loss: 1.470872]\n",
            "[Epoch 31/200] [Batch 606/938] [D loss: 0.351561] [G loss: 0.334804] [info loss: 1.470786]\n",
            "[Epoch 31/200] [Batch 607/938] [D loss: 0.235122] [G loss: 0.471211] [info loss: 1.471538]\n",
            "[Epoch 31/200] [Batch 608/938] [D loss: 0.231835] [G loss: 0.524634] [info loss: 1.489041]\n",
            "[Epoch 31/200] [Batch 609/938] [D loss: 0.210761] [G loss: 0.257006] [info loss: 1.477015]\n",
            "[Epoch 31/200] [Batch 610/938] [D loss: 0.212483] [G loss: 0.201701] [info loss: 1.474930]\n",
            "[Epoch 31/200] [Batch 611/938] [D loss: 0.282704] [G loss: 0.209250] [info loss: 1.486287]\n",
            "[Epoch 31/200] [Batch 612/938] [D loss: 0.208360] [G loss: 0.550864] [info loss: 1.475073]\n",
            "[Epoch 31/200] [Batch 613/938] [D loss: 0.333485] [G loss: 0.301168] [info loss: 1.477391]\n",
            "[Epoch 31/200] [Batch 614/938] [D loss: 0.162335] [G loss: 0.390309] [info loss: 1.472953]\n",
            "[Epoch 31/200] [Batch 615/938] [D loss: 0.197335] [G loss: 0.442033] [info loss: 1.470493]\n",
            "[Epoch 31/200] [Batch 616/938] [D loss: 0.154423] [G loss: 0.312395] [info loss: 1.473886]\n",
            "[Epoch 31/200] [Batch 617/938] [D loss: 0.228937] [G loss: 0.349047] [info loss: 1.482552]\n",
            "[Epoch 31/200] [Batch 618/938] [D loss: 0.382793] [G loss: 0.640802] [info loss: 1.471709]\n",
            "[Epoch 31/200] [Batch 619/938] [D loss: 0.245720] [G loss: 0.538622] [info loss: 1.485898]\n",
            "[Epoch 31/200] [Batch 620/938] [D loss: 0.251291] [G loss: 0.237953] [info loss: 1.478931]\n",
            "[Epoch 31/200] [Batch 621/938] [D loss: 0.139470] [G loss: 0.345220] [info loss: 1.471503]\n",
            "[Epoch 31/200] [Batch 622/938] [D loss: 0.181684] [G loss: 0.276277] [info loss: 1.476423]\n",
            "[Epoch 31/200] [Batch 623/938] [D loss: 0.152322] [G loss: 0.249411] [info loss: 1.507162]\n",
            "[Epoch 31/200] [Batch 624/938] [D loss: 0.154258] [G loss: 0.495708] [info loss: 1.487465]\n",
            "[Epoch 31/200] [Batch 625/938] [D loss: 0.149997] [G loss: 0.493110] [info loss: 1.481509]\n",
            "[Epoch 31/200] [Batch 626/938] [D loss: 0.228494] [G loss: 0.333272] [info loss: 1.470422]\n",
            "[Epoch 31/200] [Batch 627/938] [D loss: 0.166845] [G loss: 0.533891] [info loss: 1.482353]\n",
            "[Epoch 31/200] [Batch 628/938] [D loss: 0.203963] [G loss: 0.218106] [info loss: 1.470116]\n",
            "[Epoch 31/200] [Batch 629/938] [D loss: 0.277371] [G loss: 0.566585] [info loss: 1.485835]\n",
            "[Epoch 31/200] [Batch 630/938] [D loss: 0.285503] [G loss: 0.555957] [info loss: 1.483688]\n",
            "[Epoch 31/200] [Batch 631/938] [D loss: 0.294510] [G loss: 0.384487] [info loss: 1.470515]\n",
            "[Epoch 31/200] [Batch 632/938] [D loss: 0.185882] [G loss: 0.258538] [info loss: 1.478572]\n",
            "[Epoch 31/200] [Batch 633/938] [D loss: 0.384400] [G loss: 0.188469] [info loss: 1.482495]\n",
            "[Epoch 31/200] [Batch 634/938] [D loss: 0.224321] [G loss: 0.414438] [info loss: 1.469361]\n",
            "[Epoch 31/200] [Batch 635/938] [D loss: 0.396012] [G loss: 0.384012] [info loss: 1.469936]\n",
            "[Epoch 31/200] [Batch 636/938] [D loss: 0.215259] [G loss: 0.523596] [info loss: 1.482267]\n",
            "[Epoch 31/200] [Batch 637/938] [D loss: 0.194397] [G loss: 0.256758] [info loss: 1.471313]\n",
            "[Epoch 31/200] [Batch 638/938] [D loss: 0.257534] [G loss: 0.131741] [info loss: 1.473076]\n",
            "[Epoch 31/200] [Batch 639/938] [D loss: 0.276399] [G loss: 0.348675] [info loss: 1.473207]\n",
            "[Epoch 31/200] [Batch 640/938] [D loss: 0.218315] [G loss: 0.336223] [info loss: 1.483546]\n",
            "[Epoch 31/200] [Batch 641/938] [D loss: 0.226848] [G loss: 0.344499] [info loss: 1.479744]\n",
            "[Epoch 31/200] [Batch 642/938] [D loss: 0.243513] [G loss: 0.531634] [info loss: 1.472788]\n",
            "[Epoch 31/200] [Batch 643/938] [D loss: 0.261349] [G loss: 0.432566] [info loss: 1.470386]\n",
            "[Epoch 31/200] [Batch 644/938] [D loss: 0.135304] [G loss: 0.313246] [info loss: 1.469105]\n",
            "[Epoch 31/200] [Batch 645/938] [D loss: 0.313786] [G loss: 0.411105] [info loss: 1.473024]\n",
            "[Epoch 31/200] [Batch 646/938] [D loss: 0.201307] [G loss: 0.433024] [info loss: 1.473254]\n",
            "[Epoch 31/200] [Batch 647/938] [D loss: 0.184944] [G loss: 0.285620] [info loss: 1.478135]\n",
            "[Epoch 31/200] [Batch 648/938] [D loss: 0.279892] [G loss: 0.710710] [info loss: 1.469710]\n",
            "[Epoch 31/200] [Batch 649/938] [D loss: 0.183543] [G loss: 0.285428] [info loss: 1.479681]\n",
            "[Epoch 31/200] [Batch 650/938] [D loss: 0.215961] [G loss: 0.323601] [info loss: 1.471221]\n",
            "[Epoch 31/200] [Batch 651/938] [D loss: 0.218102] [G loss: 0.201143] [info loss: 1.470628]\n",
            "[Epoch 31/200] [Batch 652/938] [D loss: 0.214802] [G loss: 0.239927] [info loss: 1.475661]\n",
            "[Epoch 31/200] [Batch 653/938] [D loss: 0.197533] [G loss: 0.164535] [info loss: 1.468620]\n",
            "[Epoch 31/200] [Batch 654/938] [D loss: 0.236482] [G loss: 0.364419] [info loss: 1.480785]\n",
            "[Epoch 31/200] [Batch 655/938] [D loss: 0.221253] [G loss: 0.366661] [info loss: 1.473564]\n",
            "[Epoch 31/200] [Batch 656/938] [D loss: 0.219793] [G loss: 0.211309] [info loss: 1.480663]\n",
            "[Epoch 31/200] [Batch 657/938] [D loss: 0.212275] [G loss: 0.350594] [info loss: 1.469474]\n",
            "[Epoch 31/200] [Batch 658/938] [D loss: 0.217345] [G loss: 0.350686] [info loss: 1.470328]\n",
            "[Epoch 31/200] [Batch 659/938] [D loss: 0.180787] [G loss: 0.358500] [info loss: 1.486777]\n",
            "[Epoch 31/200] [Batch 660/938] [D loss: 0.287031] [G loss: 0.235942] [info loss: 1.472640]\n",
            "[Epoch 31/200] [Batch 661/938] [D loss: 0.144966] [G loss: 0.251621] [info loss: 1.499756]\n",
            "[Epoch 31/200] [Batch 662/938] [D loss: 0.185993] [G loss: 0.180727] [info loss: 1.470837]\n",
            "[Epoch 31/200] [Batch 663/938] [D loss: 0.175419] [G loss: 0.232790] [info loss: 1.473893]\n",
            "[Epoch 31/200] [Batch 664/938] [D loss: 0.155535] [G loss: 0.277248] [info loss: 1.482645]\n",
            "[Epoch 31/200] [Batch 665/938] [D loss: 0.161954] [G loss: 0.224680] [info loss: 1.470307]\n",
            "[Epoch 31/200] [Batch 666/938] [D loss: 0.223578] [G loss: 0.455962] [info loss: 1.471372]\n",
            "[Epoch 31/200] [Batch 667/938] [D loss: 0.348295] [G loss: 0.614456] [info loss: 1.472138]\n",
            "[Epoch 31/200] [Batch 668/938] [D loss: 0.299538] [G loss: 0.273574] [info loss: 1.485363]\n",
            "[Epoch 31/200] [Batch 669/938] [D loss: 0.285772] [G loss: 0.177289] [info loss: 1.489127]\n",
            "[Epoch 31/200] [Batch 670/938] [D loss: 0.280868] [G loss: 0.270804] [info loss: 1.470923]\n",
            "[Epoch 31/200] [Batch 671/938] [D loss: 0.280167] [G loss: 0.384130] [info loss: 1.481823]\n",
            "[Epoch 31/200] [Batch 672/938] [D loss: 0.212884] [G loss: 0.413357] [info loss: 1.469762]\n",
            "[Epoch 31/200] [Batch 673/938] [D loss: 0.143110] [G loss: 0.278471] [info loss: 1.475986]\n",
            "[Epoch 31/200] [Batch 674/938] [D loss: 0.128906] [G loss: 0.322288] [info loss: 1.485206]\n",
            "[Epoch 31/200] [Batch 675/938] [D loss: 0.282670] [G loss: 0.368745] [info loss: 1.469265]\n",
            "[Epoch 31/200] [Batch 676/938] [D loss: 0.151346] [G loss: 0.336213] [info loss: 1.469892]\n",
            "[Epoch 31/200] [Batch 677/938] [D loss: 0.317962] [G loss: 0.260671] [info loss: 1.470105]\n",
            "[Epoch 31/200] [Batch 678/938] [D loss: 0.229515] [G loss: 0.437810] [info loss: 1.469317]\n",
            "[Epoch 31/200] [Batch 679/938] [D loss: 0.321493] [G loss: 0.452953] [info loss: 1.478009]\n",
            "[Epoch 31/200] [Batch 680/938] [D loss: 0.224515] [G loss: 0.236593] [info loss: 1.473126]\n",
            "[Epoch 31/200] [Batch 681/938] [D loss: 0.221128] [G loss: 0.315303] [info loss: 1.486699]\n",
            "[Epoch 31/200] [Batch 682/938] [D loss: 0.296345] [G loss: 0.142140] [info loss: 1.489254]\n",
            "[Epoch 31/200] [Batch 683/938] [D loss: 0.135968] [G loss: 0.313139] [info loss: 1.471921]\n",
            "[Epoch 31/200] [Batch 684/938] [D loss: 0.251119] [G loss: 0.246637] [info loss: 1.469362]\n",
            "[Epoch 31/200] [Batch 685/938] [D loss: 0.223978] [G loss: 0.284396] [info loss: 1.485849]\n",
            "[Epoch 31/200] [Batch 686/938] [D loss: 0.274727] [G loss: 0.366620] [info loss: 1.480178]\n",
            "[Epoch 31/200] [Batch 687/938] [D loss: 0.226754] [G loss: 0.500941] [info loss: 1.470805]\n",
            "[Epoch 31/200] [Batch 688/938] [D loss: 0.236251] [G loss: 0.313492] [info loss: 1.472034]\n",
            "[Epoch 31/200] [Batch 689/938] [D loss: 0.294998] [G loss: 0.364996] [info loss: 1.473824]\n",
            "[Epoch 31/200] [Batch 690/938] [D loss: 0.225227] [G loss: 0.536754] [info loss: 1.475244]\n",
            "[Epoch 31/200] [Batch 691/938] [D loss: 0.236137] [G loss: 0.302169] [info loss: 1.476528]\n",
            "[Epoch 31/200] [Batch 692/938] [D loss: 0.223738] [G loss: 0.470474] [info loss: 1.472140]\n",
            "[Epoch 31/200] [Batch 693/938] [D loss: 0.236163] [G loss: 0.171525] [info loss: 1.473151]\n",
            "[Epoch 31/200] [Batch 694/938] [D loss: 0.188583] [G loss: 0.320432] [info loss: 1.497804]\n",
            "[Epoch 31/200] [Batch 695/938] [D loss: 0.148007] [G loss: 0.448165] [info loss: 1.473554]\n",
            "[Epoch 31/200] [Batch 696/938] [D loss: 0.227882] [G loss: 0.464733] [info loss: 1.469746]\n",
            "[Epoch 31/200] [Batch 697/938] [D loss: 0.257944] [G loss: 0.270063] [info loss: 1.471662]\n",
            "[Epoch 31/200] [Batch 698/938] [D loss: 0.166298] [G loss: 0.547527] [info loss: 1.469501]\n",
            "[Epoch 31/200] [Batch 699/938] [D loss: 0.178897] [G loss: 0.323586] [info loss: 1.492615]\n",
            "[Epoch 31/200] [Batch 700/938] [D loss: 0.185935] [G loss: 0.295104] [info loss: 1.468940]\n",
            "[Epoch 31/200] [Batch 701/938] [D loss: 0.345117] [G loss: 0.351075] [info loss: 1.481550]\n",
            "[Epoch 31/200] [Batch 702/938] [D loss: 0.193625] [G loss: 0.405254] [info loss: 1.469871]\n",
            "[Epoch 31/200] [Batch 703/938] [D loss: 0.290877] [G loss: 0.146981] [info loss: 1.469580]\n",
            "[Epoch 31/200] [Batch 704/938] [D loss: 0.239684] [G loss: 0.229764] [info loss: 1.468447]\n",
            "[Epoch 31/200] [Batch 705/938] [D loss: 0.366002] [G loss: 0.289864] [info loss: 1.473927]\n",
            "[Epoch 31/200] [Batch 706/938] [D loss: 0.231789] [G loss: 0.411187] [info loss: 1.495976]\n",
            "[Epoch 31/200] [Batch 707/938] [D loss: 0.249399] [G loss: 0.127139] [info loss: 1.483853]\n",
            "[Epoch 31/200] [Batch 708/938] [D loss: 0.247960] [G loss: 0.477389] [info loss: 1.469536]\n",
            "[Epoch 31/200] [Batch 709/938] [D loss: 0.202815] [G loss: 0.359098] [info loss: 1.471000]\n",
            "[Epoch 31/200] [Batch 710/938] [D loss: 0.212292] [G loss: 0.532272] [info loss: 1.480100]\n",
            "[Epoch 31/200] [Batch 711/938] [D loss: 0.301651] [G loss: 0.465276] [info loss: 1.491711]\n",
            "[Epoch 31/200] [Batch 712/938] [D loss: 0.295438] [G loss: 0.360161] [info loss: 1.473166]\n",
            "[Epoch 31/200] [Batch 713/938] [D loss: 0.169772] [G loss: 0.479132] [info loss: 1.490529]\n",
            "[Epoch 31/200] [Batch 714/938] [D loss: 0.260144] [G loss: 0.125256] [info loss: 1.473038]\n",
            "[Epoch 31/200] [Batch 715/938] [D loss: 0.214503] [G loss: 0.302159] [info loss: 1.470596]\n",
            "[Epoch 31/200] [Batch 716/938] [D loss: 0.176950] [G loss: 0.233161] [info loss: 1.480310]\n",
            "[Epoch 31/200] [Batch 717/938] [D loss: 0.211532] [G loss: 0.436406] [info loss: 1.507076]\n",
            "[Epoch 31/200] [Batch 718/938] [D loss: 0.132739] [G loss: 0.255454] [info loss: 1.468047]\n",
            "[Epoch 31/200] [Batch 719/938] [D loss: 0.133209] [G loss: 0.282533] [info loss: 1.470349]\n",
            "[Epoch 31/200] [Batch 720/938] [D loss: 0.120976] [G loss: 0.296463] [info loss: 1.472970]\n",
            "[Epoch 31/200] [Batch 721/938] [D loss: 0.173690] [G loss: 0.237530] [info loss: 1.477522]\n",
            "[Epoch 31/200] [Batch 722/938] [D loss: 0.195928] [G loss: 0.345854] [info loss: 1.472320]\n",
            "[Epoch 31/200] [Batch 723/938] [D loss: 0.141794] [G loss: 0.440206] [info loss: 1.469510]\n",
            "[Epoch 31/200] [Batch 724/938] [D loss: 0.199289] [G loss: 0.448546] [info loss: 1.473675]\n",
            "[Epoch 31/200] [Batch 725/938] [D loss: 0.253566] [G loss: 0.364981] [info loss: 1.470384]\n",
            "[Epoch 31/200] [Batch 726/938] [D loss: 0.194952] [G loss: 0.219633] [info loss: 1.473611]\n",
            "[Epoch 31/200] [Batch 727/938] [D loss: 0.275918] [G loss: 0.161165] [info loss: 1.486385]\n",
            "[Epoch 31/200] [Batch 728/938] [D loss: 0.239367] [G loss: 0.314431] [info loss: 1.483158]\n",
            "[Epoch 31/200] [Batch 729/938] [D loss: 0.220208] [G loss: 0.465382] [info loss: 1.478416]\n",
            "[Epoch 31/200] [Batch 730/938] [D loss: 0.187453] [G loss: 0.361852] [info loss: 1.471200]\n",
            "[Epoch 31/200] [Batch 731/938] [D loss: 0.175413] [G loss: 0.342758] [info loss: 1.475218]\n",
            "[Epoch 31/200] [Batch 732/938] [D loss: 0.187266] [G loss: 0.447442] [info loss: 1.482862]\n",
            "[Epoch 31/200] [Batch 733/938] [D loss: 0.255440] [G loss: 0.230111] [info loss: 1.469973]\n",
            "[Epoch 31/200] [Batch 734/938] [D loss: 0.169578] [G loss: 0.385092] [info loss: 1.483250]\n",
            "[Epoch 31/200] [Batch 735/938] [D loss: 0.240548] [G loss: 0.456227] [info loss: 1.469890]\n",
            "[Epoch 31/200] [Batch 736/938] [D loss: 0.169190] [G loss: 0.446942] [info loss: 1.471719]\n",
            "[Epoch 31/200] [Batch 737/938] [D loss: 0.206044] [G loss: 0.409421] [info loss: 1.483416]\n",
            "[Epoch 31/200] [Batch 738/938] [D loss: 0.193262] [G loss: 0.122629] [info loss: 1.470220]\n",
            "[Epoch 31/200] [Batch 739/938] [D loss: 0.185115] [G loss: 0.392373] [info loss: 1.471430]\n",
            "[Epoch 31/200] [Batch 740/938] [D loss: 0.235784] [G loss: 0.470404] [info loss: 1.470805]\n",
            "[Epoch 31/200] [Batch 741/938] [D loss: 0.278919] [G loss: 0.734974] [info loss: 1.473642]\n",
            "[Epoch 31/200] [Batch 742/938] [D loss: 0.168033] [G loss: 0.416396] [info loss: 1.471089]\n",
            "[Epoch 31/200] [Batch 743/938] [D loss: 0.216807] [G loss: 0.330005] [info loss: 1.473853]\n",
            "[Epoch 31/200] [Batch 744/938] [D loss: 0.323912] [G loss: 0.188453] [info loss: 1.473666]\n",
            "[Epoch 31/200] [Batch 745/938] [D loss: 0.245686] [G loss: 0.193178] [info loss: 1.470088]\n",
            "[Epoch 31/200] [Batch 746/938] [D loss: 0.115018] [G loss: 0.213150] [info loss: 1.475428]\n",
            "[Epoch 31/200] [Batch 747/938] [D loss: 0.145592] [G loss: 0.271574] [info loss: 1.487740]\n",
            "[Epoch 31/200] [Batch 748/938] [D loss: 0.177020] [G loss: 0.692195] [info loss: 1.496601]\n",
            "[Epoch 31/200] [Batch 749/938] [D loss: 0.203491] [G loss: 0.363695] [info loss: 1.473787]\n",
            "[Epoch 31/200] [Batch 750/938] [D loss: 0.215888] [G loss: 0.546245] [info loss: 1.487393]\n",
            "[Epoch 31/200] [Batch 751/938] [D loss: 0.234631] [G loss: 0.350566] [info loss: 1.472567]\n",
            "[Epoch 31/200] [Batch 752/938] [D loss: 0.147763] [G loss: 0.146241] [info loss: 1.489527]\n",
            "[Epoch 31/200] [Batch 753/938] [D loss: 0.282021] [G loss: 0.161841] [info loss: 1.494093]\n",
            "[Epoch 31/200] [Batch 754/938] [D loss: 0.179777] [G loss: 0.338629] [info loss: 1.469299]\n",
            "[Epoch 31/200] [Batch 755/938] [D loss: 0.174411] [G loss: 0.227084] [info loss: 1.469838]\n",
            "[Epoch 31/200] [Batch 756/938] [D loss: 0.105143] [G loss: 0.327047] [info loss: 1.469857]\n",
            "[Epoch 31/200] [Batch 757/938] [D loss: 0.198568] [G loss: 0.263194] [info loss: 1.477393]\n",
            "[Epoch 31/200] [Batch 758/938] [D loss: 0.241255] [G loss: 0.258620] [info loss: 1.471251]\n",
            "[Epoch 31/200] [Batch 759/938] [D loss: 0.319431] [G loss: 0.297591] [info loss: 1.472558]\n",
            "[Epoch 31/200] [Batch 760/938] [D loss: 0.174802] [G loss: 0.532026] [info loss: 1.469481]\n",
            "[Epoch 31/200] [Batch 761/938] [D loss: 0.195773] [G loss: 0.371769] [info loss: 1.472695]\n",
            "[Epoch 31/200] [Batch 762/938] [D loss: 0.214074] [G loss: 0.425668] [info loss: 1.484951]\n",
            "[Epoch 31/200] [Batch 763/938] [D loss: 0.259217] [G loss: 0.321394] [info loss: 1.471173]\n",
            "[Epoch 31/200] [Batch 764/938] [D loss: 0.150340] [G loss: 0.274663] [info loss: 1.498833]\n",
            "[Epoch 31/200] [Batch 765/938] [D loss: 0.107903] [G loss: 0.439004] [info loss: 1.477254]\n",
            "[Epoch 31/200] [Batch 766/938] [D loss: 0.200583] [G loss: 0.365647] [info loss: 1.472442]\n",
            "[Epoch 31/200] [Batch 767/938] [D loss: 0.171481] [G loss: 0.290891] [info loss: 1.469627]\n",
            "[Epoch 31/200] [Batch 768/938] [D loss: 0.170568] [G loss: 0.348759] [info loss: 1.468991]\n",
            "[Epoch 31/200] [Batch 769/938] [D loss: 0.247903] [G loss: 0.246871] [info loss: 1.469605]\n",
            "[Epoch 31/200] [Batch 770/938] [D loss: 0.264687] [G loss: 0.504568] [info loss: 1.473626]\n",
            "[Epoch 31/200] [Batch 771/938] [D loss: 0.292383] [G loss: 0.326213] [info loss: 1.476655]\n",
            "[Epoch 31/200] [Batch 772/938] [D loss: 0.153578] [G loss: 0.442251] [info loss: 1.484075]\n",
            "[Epoch 31/200] [Batch 773/938] [D loss: 0.242880] [G loss: 0.511512] [info loss: 1.474537]\n",
            "[Epoch 31/200] [Batch 774/938] [D loss: 0.226393] [G loss: 0.190768] [info loss: 1.469548]\n",
            "[Epoch 31/200] [Batch 775/938] [D loss: 0.216529] [G loss: 0.486242] [info loss: 1.478346]\n",
            "[Epoch 31/200] [Batch 776/938] [D loss: 0.327380] [G loss: 0.247947] [info loss: 1.499441]\n",
            "[Epoch 31/200] [Batch 777/938] [D loss: 0.211764] [G loss: 0.458778] [info loss: 1.483111]\n",
            "[Epoch 31/200] [Batch 778/938] [D loss: 0.126670] [G loss: 0.287766] [info loss: 1.468349]\n",
            "[Epoch 31/200] [Batch 779/938] [D loss: 0.321055] [G loss: 0.273608] [info loss: 1.475178]\n",
            "[Epoch 31/200] [Batch 780/938] [D loss: 0.250190] [G loss: 0.607637] [info loss: 1.469693]\n",
            "[Epoch 31/200] [Batch 781/938] [D loss: 0.269596] [G loss: 0.253325] [info loss: 1.470377]\n",
            "[Epoch 31/200] [Batch 782/938] [D loss: 0.101227] [G loss: 0.382590] [info loss: 1.469466]\n",
            "[Epoch 31/200] [Batch 783/938] [D loss: 0.179136] [G loss: 0.419155] [info loss: 1.470464]\n",
            "[Epoch 31/200] [Batch 784/938] [D loss: 0.162188] [G loss: 0.303958] [info loss: 1.474000]\n",
            "[Epoch 31/200] [Batch 785/938] [D loss: 0.130822] [G loss: 0.563243] [info loss: 1.468500]\n",
            "[Epoch 31/200] [Batch 786/938] [D loss: 0.100584] [G loss: 0.385695] [info loss: 1.476779]\n",
            "[Epoch 31/200] [Batch 787/938] [D loss: 0.199692] [G loss: 0.245678] [info loss: 1.471731]\n",
            "[Epoch 31/200] [Batch 788/938] [D loss: 0.289868] [G loss: 0.222377] [info loss: 1.524021]\n",
            "[Epoch 31/200] [Batch 789/938] [D loss: 0.253792] [G loss: 0.197906] [info loss: 1.483667]\n",
            "[Epoch 31/200] [Batch 790/938] [D loss: 0.283082] [G loss: 0.654814] [info loss: 1.476127]\n",
            "[Epoch 31/200] [Batch 791/938] [D loss: 0.261848] [G loss: 0.256008] [info loss: 1.474482]\n",
            "[Epoch 31/200] [Batch 792/938] [D loss: 0.265086] [G loss: 0.400264] [info loss: 1.483397]\n",
            "[Epoch 31/200] [Batch 793/938] [D loss: 0.204429] [G loss: 0.184799] [info loss: 1.468638]\n",
            "[Epoch 31/200] [Batch 794/938] [D loss: 0.183144] [G loss: 0.241582] [info loss: 1.497077]\n",
            "[Epoch 31/200] [Batch 795/938] [D loss: 0.223258] [G loss: 0.256259] [info loss: 1.470322]\n",
            "[Epoch 31/200] [Batch 796/938] [D loss: 0.268663] [G loss: 0.204681] [info loss: 1.470071]\n",
            "[Epoch 31/200] [Batch 797/938] [D loss: 0.152790] [G loss: 0.339616] [info loss: 1.470663]\n",
            "[Epoch 31/200] [Batch 798/938] [D loss: 0.235714] [G loss: 0.498864] [info loss: 1.470298]\n",
            "[Epoch 31/200] [Batch 799/938] [D loss: 0.182824] [G loss: 0.350773] [info loss: 1.473816]\n",
            "[Epoch 31/200] [Batch 800/938] [D loss: 0.150337] [G loss: 0.271950] [info loss: 1.471996]\n",
            "[Epoch 31/200] [Batch 801/938] [D loss: 0.183879] [G loss: 0.303423] [info loss: 1.482505]\n",
            "[Epoch 31/200] [Batch 802/938] [D loss: 0.210426] [G loss: 0.306370] [info loss: 1.477412]\n",
            "[Epoch 31/200] [Batch 803/938] [D loss: 0.220011] [G loss: 0.610869] [info loss: 1.472759]\n",
            "[Epoch 31/200] [Batch 804/938] [D loss: 0.223724] [G loss: 0.199639] [info loss: 1.472422]\n",
            "[Epoch 31/200] [Batch 805/938] [D loss: 0.176390] [G loss: 0.249561] [info loss: 1.489676]\n",
            "[Epoch 31/200] [Batch 806/938] [D loss: 0.266002] [G loss: 0.417897] [info loss: 1.474960]\n",
            "[Epoch 31/200] [Batch 807/938] [D loss: 0.208855] [G loss: 0.500722] [info loss: 1.468292]\n",
            "[Epoch 31/200] [Batch 808/938] [D loss: 0.252625] [G loss: 0.537314] [info loss: 1.471297]\n",
            "[Epoch 31/200] [Batch 809/938] [D loss: 0.172861] [G loss: 0.291576] [info loss: 1.468512]\n",
            "[Epoch 31/200] [Batch 810/938] [D loss: 0.248477] [G loss: 0.140579] [info loss: 1.475323]\n",
            "[Epoch 31/200] [Batch 811/938] [D loss: 0.238408] [G loss: 0.208043] [info loss: 1.472057]\n",
            "[Epoch 31/200] [Batch 812/938] [D loss: 0.185543] [G loss: 0.382054] [info loss: 1.486137]\n",
            "[Epoch 31/200] [Batch 813/938] [D loss: 0.252615] [G loss: 0.389895] [info loss: 1.470616]\n",
            "[Epoch 31/200] [Batch 814/938] [D loss: 0.204207] [G loss: 0.475614] [info loss: 1.499180]\n",
            "[Epoch 31/200] [Batch 815/938] [D loss: 0.324142] [G loss: 0.291690] [info loss: 1.472059]\n",
            "[Epoch 31/200] [Batch 816/938] [D loss: 0.138138] [G loss: 0.332536] [info loss: 1.512679]\n",
            "[Epoch 31/200] [Batch 817/938] [D loss: 0.190803] [G loss: 0.342893] [info loss: 1.489268]\n",
            "[Epoch 31/200] [Batch 818/938] [D loss: 0.287357] [G loss: 0.350356] [info loss: 1.484600]\n",
            "[Epoch 31/200] [Batch 819/938] [D loss: 0.299893] [G loss: 0.426557] [info loss: 1.471039]\n",
            "[Epoch 31/200] [Batch 820/938] [D loss: 0.174381] [G loss: 0.401004] [info loss: 1.470319]\n",
            "[Epoch 31/200] [Batch 821/938] [D loss: 0.230921] [G loss: 0.191122] [info loss: 1.478048]\n",
            "[Epoch 31/200] [Batch 822/938] [D loss: 0.266480] [G loss: 0.285290] [info loss: 1.469979]\n",
            "[Epoch 31/200] [Batch 823/938] [D loss: 0.289001] [G loss: 0.406315] [info loss: 1.476163]\n",
            "[Epoch 31/200] [Batch 824/938] [D loss: 0.247294] [G loss: 0.227558] [info loss: 1.480883]\n",
            "[Epoch 31/200] [Batch 825/938] [D loss: 0.282767] [G loss: 0.223052] [info loss: 1.470176]\n",
            "[Epoch 31/200] [Batch 826/938] [D loss: 0.197630] [G loss: 0.425139] [info loss: 1.487224]\n",
            "[Epoch 31/200] [Batch 827/938] [D loss: 0.219889] [G loss: 0.714266] [info loss: 1.472663]\n",
            "[Epoch 31/200] [Batch 828/938] [D loss: 0.215720] [G loss: 0.354565] [info loss: 1.491560]\n",
            "[Epoch 31/200] [Batch 829/938] [D loss: 0.215489] [G loss: 0.231886] [info loss: 1.486480]\n",
            "[Epoch 31/200] [Batch 830/938] [D loss: 0.384108] [G loss: 0.236750] [info loss: 1.470912]\n",
            "[Epoch 31/200] [Batch 831/938] [D loss: 0.227555] [G loss: 0.321399] [info loss: 1.472287]\n",
            "[Epoch 31/200] [Batch 832/938] [D loss: 0.228308] [G loss: 0.309127] [info loss: 1.471475]\n",
            "[Epoch 31/200] [Batch 833/938] [D loss: 0.203740] [G loss: 0.523293] [info loss: 1.489071]\n",
            "[Epoch 31/200] [Batch 834/938] [D loss: 0.121314] [G loss: 0.552120] [info loss: 1.480371]\n",
            "[Epoch 31/200] [Batch 835/938] [D loss: 0.234928] [G loss: 0.239303] [info loss: 1.468881]\n",
            "[Epoch 31/200] [Batch 836/938] [D loss: 0.219924] [G loss: 0.388619] [info loss: 1.476029]\n",
            "[Epoch 31/200] [Batch 837/938] [D loss: 0.111245] [G loss: 0.289155] [info loss: 1.474280]\n",
            "[Epoch 31/200] [Batch 838/938] [D loss: 0.202017] [G loss: 0.395865] [info loss: 1.495275]\n",
            "[Epoch 31/200] [Batch 839/938] [D loss: 0.196159] [G loss: 0.191654] [info loss: 1.476653]\n",
            "[Epoch 31/200] [Batch 840/938] [D loss: 0.239721] [G loss: 0.359045] [info loss: 1.485203]\n",
            "[Epoch 31/200] [Batch 841/938] [D loss: 0.225403] [G loss: 0.244084] [info loss: 1.469159]\n",
            "[Epoch 31/200] [Batch 842/938] [D loss: 0.196112] [G loss: 0.416997] [info loss: 1.475851]\n",
            "[Epoch 31/200] [Batch 843/938] [D loss: 0.153524] [G loss: 0.146379] [info loss: 1.473440]\n",
            "[Epoch 31/200] [Batch 844/938] [D loss: 0.277525] [G loss: 0.190151] [info loss: 1.468809]\n",
            "[Epoch 31/200] [Batch 845/938] [D loss: 0.204484] [G loss: 0.293627] [info loss: 1.473716]\n",
            "[Epoch 31/200] [Batch 846/938] [D loss: 0.200292] [G loss: 0.595095] [info loss: 1.471466]\n",
            "[Epoch 31/200] [Batch 847/938] [D loss: 0.184140] [G loss: 0.470759] [info loss: 1.469383]\n",
            "[Epoch 31/200] [Batch 848/938] [D loss: 0.215461] [G loss: 0.227620] [info loss: 1.469683]\n",
            "[Epoch 31/200] [Batch 849/938] [D loss: 0.138390] [G loss: 0.534261] [info loss: 1.470782]\n",
            "[Epoch 31/200] [Batch 850/938] [D loss: 0.113265] [G loss: 0.555434] [info loss: 1.482182]\n",
            "[Epoch 31/200] [Batch 851/938] [D loss: 0.243521] [G loss: 0.503055] [info loss: 1.471975]\n",
            "[Epoch 31/200] [Batch 852/938] [D loss: 0.163365] [G loss: 0.299525] [info loss: 1.483711]\n",
            "[Epoch 31/200] [Batch 853/938] [D loss: 0.286253] [G loss: 0.319797] [info loss: 1.471299]\n",
            "[Epoch 31/200] [Batch 854/938] [D loss: 0.265525] [G loss: 0.382227] [info loss: 1.468592]\n",
            "[Epoch 31/200] [Batch 855/938] [D loss: 0.202741] [G loss: 0.820363] [info loss: 1.473638]\n",
            "[Epoch 31/200] [Batch 856/938] [D loss: 0.179760] [G loss: 0.493397] [info loss: 1.471336]\n",
            "[Epoch 31/200] [Batch 857/938] [D loss: 0.176617] [G loss: 0.409366] [info loss: 1.473136]\n",
            "[Epoch 31/200] [Batch 858/938] [D loss: 0.189569] [G loss: 0.148168] [info loss: 1.489711]\n",
            "[Epoch 31/200] [Batch 859/938] [D loss: 0.228165] [G loss: 0.465769] [info loss: 1.474005]\n",
            "[Epoch 31/200] [Batch 860/938] [D loss: 0.178052] [G loss: 0.406653] [info loss: 1.502851]\n",
            "[Epoch 31/200] [Batch 861/938] [D loss: 0.179966] [G loss: 0.366699] [info loss: 1.487479]\n",
            "[Epoch 31/200] [Batch 862/938] [D loss: 0.233578] [G loss: 0.329144] [info loss: 1.472575]\n",
            "[Epoch 31/200] [Batch 863/938] [D loss: 0.191862] [G loss: 0.109826] [info loss: 1.493670]\n",
            "[Epoch 31/200] [Batch 864/938] [D loss: 0.257512] [G loss: 0.260095] [info loss: 1.469980]\n",
            "[Epoch 31/200] [Batch 865/938] [D loss: 0.207875] [G loss: 0.343866] [info loss: 1.469719]\n",
            "[Epoch 31/200] [Batch 866/938] [D loss: 0.210288] [G loss: 0.220071] [info loss: 1.474224]\n",
            "[Epoch 31/200] [Batch 867/938] [D loss: 0.280394] [G loss: 0.276334] [info loss: 1.470121]\n",
            "[Epoch 31/200] [Batch 868/938] [D loss: 0.225414] [G loss: 0.176540] [info loss: 1.495026]\n",
            "[Epoch 31/200] [Batch 869/938] [D loss: 0.160163] [G loss: 0.332776] [info loss: 1.471399]\n",
            "[Epoch 31/200] [Batch 870/938] [D loss: 0.236626] [G loss: 0.566011] [info loss: 1.466797]\n",
            "[Epoch 31/200] [Batch 871/938] [D loss: 0.188448] [G loss: 0.530621] [info loss: 1.469185]\n",
            "[Epoch 31/200] [Batch 872/938] [D loss: 0.286051] [G loss: 0.114851] [info loss: 1.470495]\n",
            "[Epoch 31/200] [Batch 873/938] [D loss: 0.284364] [G loss: 0.186865] [info loss: 1.507961]\n",
            "[Epoch 31/200] [Batch 874/938] [D loss: 0.099906] [G loss: 0.503326] [info loss: 1.469789]\n",
            "[Epoch 31/200] [Batch 875/938] [D loss: 0.148619] [G loss: 0.430286] [info loss: 1.470481]\n",
            "[Epoch 31/200] [Batch 876/938] [D loss: 0.159440] [G loss: 0.365724] [info loss: 1.483300]\n",
            "[Epoch 31/200] [Batch 877/938] [D loss: 0.315989] [G loss: 0.179128] [info loss: 1.469878]\n",
            "[Epoch 31/200] [Batch 878/938] [D loss: 0.119743] [G loss: 0.124349] [info loss: 1.468786]\n",
            "[Epoch 31/200] [Batch 879/938] [D loss: 0.230168] [G loss: 0.275141] [info loss: 1.485427]\n",
            "[Epoch 31/200] [Batch 880/938] [D loss: 0.187891] [G loss: 0.143757] [info loss: 1.514352]\n",
            "[Epoch 31/200] [Batch 881/938] [D loss: 0.146078] [G loss: 0.250057] [info loss: 1.480866]\n",
            "[Epoch 31/200] [Batch 882/938] [D loss: 0.255839] [G loss: 0.301989] [info loss: 1.476696]\n",
            "[Epoch 31/200] [Batch 883/938] [D loss: 0.178524] [G loss: 0.496595] [info loss: 1.480756]\n",
            "[Epoch 31/200] [Batch 884/938] [D loss: 0.308459] [G loss: 0.546379] [info loss: 1.499570]\n",
            "[Epoch 31/200] [Batch 885/938] [D loss: 0.200721] [G loss: 0.209385] [info loss: 1.469966]\n",
            "[Epoch 31/200] [Batch 886/938] [D loss: 0.238438] [G loss: 0.290631] [info loss: 1.488281]\n",
            "[Epoch 31/200] [Batch 887/938] [D loss: 0.217495] [G loss: 0.297811] [info loss: 1.470868]\n",
            "[Epoch 31/200] [Batch 888/938] [D loss: 0.152432] [G loss: 0.365921] [info loss: 1.485171]\n",
            "[Epoch 31/200] [Batch 889/938] [D loss: 0.277129] [G loss: 0.417359] [info loss: 1.471858]\n",
            "[Epoch 31/200] [Batch 890/938] [D loss: 0.195884] [G loss: 0.393957] [info loss: 1.470889]\n",
            "[Epoch 31/200] [Batch 891/938] [D loss: 0.176621] [G loss: 0.451882] [info loss: 1.469764]\n",
            "[Epoch 31/200] [Batch 892/938] [D loss: 0.262875] [G loss: 0.316716] [info loss: 1.469576]\n",
            "[Epoch 31/200] [Batch 893/938] [D loss: 0.279212] [G loss: 0.103790] [info loss: 1.470112]\n",
            "[Epoch 31/200] [Batch 894/938] [D loss: 0.099934] [G loss: 0.300922] [info loss: 1.485049]\n",
            "[Epoch 31/200] [Batch 895/938] [D loss: 0.179966] [G loss: 0.326886] [info loss: 1.471533]\n",
            "[Epoch 31/200] [Batch 896/938] [D loss: 0.243392] [G loss: 0.255712] [info loss: 1.484712]\n",
            "[Epoch 31/200] [Batch 897/938] [D loss: 0.343968] [G loss: 0.594463] [info loss: 1.482830]\n",
            "[Epoch 31/200] [Batch 898/938] [D loss: 0.270322] [G loss: 0.267562] [info loss: 1.485550]\n",
            "[Epoch 31/200] [Batch 899/938] [D loss: 0.193331] [G loss: 0.250034] [info loss: 1.479793]\n",
            "[Epoch 31/200] [Batch 900/938] [D loss: 0.146048] [G loss: 0.276169] [info loss: 1.486518]\n",
            "[Epoch 31/200] [Batch 901/938] [D loss: 0.283455] [G loss: 0.190602] [info loss: 1.469141]\n",
            "[Epoch 31/200] [Batch 902/938] [D loss: 0.348779] [G loss: 0.265469] [info loss: 1.478167]\n",
            "[Epoch 31/200] [Batch 903/938] [D loss: 0.146686] [G loss: 0.490063] [info loss: 1.477217]\n",
            "[Epoch 31/200] [Batch 904/938] [D loss: 0.288739] [G loss: 0.313188] [info loss: 1.470100]\n",
            "[Epoch 31/200] [Batch 905/938] [D loss: 0.283957] [G loss: 0.259901] [info loss: 1.485649]\n",
            "[Epoch 31/200] [Batch 906/938] [D loss: 0.295358] [G loss: 0.238896] [info loss: 1.483954]\n",
            "[Epoch 31/200] [Batch 907/938] [D loss: 0.219392] [G loss: 0.272018] [info loss: 1.485573]\n",
            "[Epoch 31/200] [Batch 908/938] [D loss: 0.227933] [G loss: 0.339057] [info loss: 1.473169]\n",
            "[Epoch 31/200] [Batch 909/938] [D loss: 0.249456] [G loss: 0.308931] [info loss: 1.476854]\n",
            "[Epoch 31/200] [Batch 910/938] [D loss: 0.273248] [G loss: 0.401490] [info loss: 1.479537]\n",
            "[Epoch 31/200] [Batch 911/938] [D loss: 0.215143] [G loss: 0.583645] [info loss: 1.473728]\n",
            "[Epoch 31/200] [Batch 912/938] [D loss: 0.231089] [G loss: 0.381307] [info loss: 1.479885]\n",
            "[Epoch 31/200] [Batch 913/938] [D loss: 0.162152] [G loss: 0.501314] [info loss: 1.486003]\n",
            "[Epoch 31/200] [Batch 914/938] [D loss: 0.202685] [G loss: 0.357636] [info loss: 1.475860]\n",
            "[Epoch 31/200] [Batch 915/938] [D loss: 0.192322] [G loss: 0.250183] [info loss: 1.482117]\n",
            "[Epoch 31/200] [Batch 916/938] [D loss: 0.178604] [G loss: 0.261153] [info loss: 1.470633]\n",
            "[Epoch 31/200] [Batch 917/938] [D loss: 0.274325] [G loss: 0.258952] [info loss: 1.502676]\n",
            "[Epoch 31/200] [Batch 918/938] [D loss: 0.219409] [G loss: 0.459339] [info loss: 1.468117]\n",
            "[Epoch 31/200] [Batch 919/938] [D loss: 0.168583] [G loss: 0.605246] [info loss: 1.468090]\n",
            "[Epoch 31/200] [Batch 920/938] [D loss: 0.152076] [G loss: 0.242484] [info loss: 1.470962]\n",
            "[Epoch 31/200] [Batch 921/938] [D loss: 0.175721] [G loss: 0.276620] [info loss: 1.497923]\n",
            "[Epoch 31/200] [Batch 922/938] [D loss: 0.191767] [G loss: 0.303453] [info loss: 1.470871]\n",
            "[Epoch 31/200] [Batch 923/938] [D loss: 0.340564] [G loss: 0.501081] [info loss: 1.471530]\n",
            "[Epoch 31/200] [Batch 924/938] [D loss: 0.158631] [G loss: 0.328691] [info loss: 1.499843]\n",
            "[Epoch 31/200] [Batch 925/938] [D loss: 0.155062] [G loss: 0.233156] [info loss: 1.469958]\n",
            "[Epoch 31/200] [Batch 926/938] [D loss: 0.241089] [G loss: 0.239197] [info loss: 1.484348]\n",
            "[Epoch 31/200] [Batch 927/938] [D loss: 0.150784] [G loss: 0.125977] [info loss: 1.489668]\n",
            "[Epoch 31/200] [Batch 928/938] [D loss: 0.165036] [G loss: 0.171727] [info loss: 1.478062]\n",
            "[Epoch 31/200] [Batch 929/938] [D loss: 0.220187] [G loss: 0.363460] [info loss: 1.483819]\n",
            "[Epoch 31/200] [Batch 930/938] [D loss: 0.310768] [G loss: 0.389865] [info loss: 1.483422]\n",
            "[Epoch 31/200] [Batch 931/938] [D loss: 0.202463] [G loss: 0.322465] [info loss: 1.485511]\n",
            "[Epoch 31/200] [Batch 932/938] [D loss: 0.156960] [G loss: 0.376164] [info loss: 1.471094]\n",
            "[Epoch 31/200] [Batch 933/938] [D loss: 0.189173] [G loss: 0.435111] [info loss: 1.541561]\n",
            "[Epoch 31/200] [Batch 934/938] [D loss: 0.299882] [G loss: 0.435106] [info loss: 1.475266]\n",
            "[Epoch 31/200] [Batch 935/938] [D loss: 0.189572] [G loss: 0.144149] [info loss: 1.486322]\n",
            "[Epoch 31/200] [Batch 936/938] [D loss: 0.204207] [G loss: 0.227584] [info loss: 1.471674]\n",
            "[Epoch 31/200] [Batch 937/938] [D loss: 0.203240] [G loss: 0.564909] [info loss: 1.468701]\n",
            "[Epoch 32/200] [Batch 0/938] [D loss: 0.209161] [G loss: 0.342218] [info loss: 1.468323]\n",
            "[Epoch 32/200] [Batch 1/938] [D loss: 0.226347] [G loss: 0.386133] [info loss: 1.469421]\n",
            "[Epoch 32/200] [Batch 2/938] [D loss: 0.365632] [G loss: 0.770524] [info loss: 1.483787]\n",
            "[Epoch 32/200] [Batch 3/938] [D loss: 0.217801] [G loss: 0.323388] [info loss: 1.495957]\n",
            "[Epoch 32/200] [Batch 4/938] [D loss: 0.187303] [G loss: 0.415945] [info loss: 1.486665]\n",
            "[Epoch 32/200] [Batch 5/938] [D loss: 0.184098] [G loss: 0.356598] [info loss: 1.485923]\n",
            "[Epoch 32/200] [Batch 6/938] [D loss: 0.306565] [G loss: 0.363366] [info loss: 1.470710]\n",
            "[Epoch 32/200] [Batch 7/938] [D loss: 0.156673] [G loss: 0.592574] [info loss: 1.485628]\n",
            "[Epoch 32/200] [Batch 8/938] [D loss: 0.191970] [G loss: 0.277612] [info loss: 1.476436]\n",
            "[Epoch 32/200] [Batch 9/938] [D loss: 0.212736] [G loss: 0.111979] [info loss: 1.479360]\n",
            "[Epoch 32/200] [Batch 10/938] [D loss: 0.238449] [G loss: 0.331478] [info loss: 1.484798]\n",
            "[Epoch 32/200] [Batch 11/938] [D loss: 0.160547] [G loss: 0.606052] [info loss: 1.470987]\n",
            "[Epoch 32/200] [Batch 12/938] [D loss: 0.320360] [G loss: 0.538433] [info loss: 1.472493]\n",
            "[Epoch 32/200] [Batch 13/938] [D loss: 0.233913] [G loss: 0.111332] [info loss: 1.482440]\n",
            "[Epoch 32/200] [Batch 14/938] [D loss: 0.192856] [G loss: 0.292685] [info loss: 1.469407]\n",
            "[Epoch 32/200] [Batch 15/938] [D loss: 0.273462] [G loss: 0.594468] [info loss: 1.472275]\n",
            "[Epoch 32/200] [Batch 16/938] [D loss: 0.246225] [G loss: 0.626791] [info loss: 1.481587]\n",
            "[Epoch 32/200] [Batch 17/938] [D loss: 0.225665] [G loss: 0.479382] [info loss: 1.496983]\n",
            "[Epoch 32/200] [Batch 18/938] [D loss: 0.274240] [G loss: 0.182496] [info loss: 1.478372]\n",
            "[Epoch 32/200] [Batch 19/938] [D loss: 0.137229] [G loss: 0.495036] [info loss: 1.470277]\n",
            "[Epoch 32/200] [Batch 20/938] [D loss: 0.191385] [G loss: 0.242539] [info loss: 1.469880]\n",
            "[Epoch 32/200] [Batch 21/938] [D loss: 0.285634] [G loss: 0.292550] [info loss: 1.487005]\n",
            "[Epoch 32/200] [Batch 22/938] [D loss: 0.237023] [G loss: 0.222418] [info loss: 1.476064]\n",
            "[Epoch 32/200] [Batch 23/938] [D loss: 0.239254] [G loss: 0.154851] [info loss: 1.469461]\n",
            "[Epoch 32/200] [Batch 24/938] [D loss: 0.325746] [G loss: 0.391734] [info loss: 1.470627]\n",
            "[Epoch 32/200] [Batch 25/938] [D loss: 0.362180] [G loss: 0.253822] [info loss: 1.469967]\n",
            "[Epoch 32/200] [Batch 26/938] [D loss: 0.254055] [G loss: 0.331609] [info loss: 1.476214]\n",
            "[Epoch 32/200] [Batch 27/938] [D loss: 0.179435] [G loss: 0.399980] [info loss: 1.482201]\n",
            "[Epoch 32/200] [Batch 28/938] [D loss: 0.211832] [G loss: 0.430843] [info loss: 1.468122]\n",
            "[Epoch 32/200] [Batch 29/938] [D loss: 0.168491] [G loss: 0.265908] [info loss: 1.469626]\n",
            "[Epoch 32/200] [Batch 30/938] [D loss: 0.279403] [G loss: 0.421388] [info loss: 1.486878]\n",
            "[Epoch 32/200] [Batch 31/938] [D loss: 0.153929] [G loss: 0.671056] [info loss: 1.478854]\n",
            "[Epoch 32/200] [Batch 32/938] [D loss: 0.231281] [G loss: 0.360769] [info loss: 1.480893]\n",
            "[Epoch 32/200] [Batch 33/938] [D loss: 0.159680] [G loss: 0.193395] [info loss: 1.471323]\n",
            "[Epoch 32/200] [Batch 34/938] [D loss: 0.139166] [G loss: 0.433351] [info loss: 1.473639]\n",
            "[Epoch 32/200] [Batch 35/938] [D loss: 0.181980] [G loss: 0.538039] [info loss: 1.470300]\n",
            "[Epoch 32/200] [Batch 36/938] [D loss: 0.168401] [G loss: 0.275148] [info loss: 1.483665]\n",
            "[Epoch 32/200] [Batch 37/938] [D loss: 0.126674] [G loss: 0.419514] [info loss: 1.472138]\n",
            "[Epoch 32/200] [Batch 38/938] [D loss: 0.358102] [G loss: 0.342051] [info loss: 1.471765]\n",
            "[Epoch 32/200] [Batch 39/938] [D loss: 0.295178] [G loss: 0.400917] [info loss: 1.471936]\n",
            "[Epoch 32/200] [Batch 40/938] [D loss: 0.299526] [G loss: 0.232463] [info loss: 1.468174]\n",
            "[Epoch 32/200] [Batch 41/938] [D loss: 0.255671] [G loss: 0.388500] [info loss: 1.469276]\n",
            "[Epoch 32/200] [Batch 42/938] [D loss: 0.128401] [G loss: 0.460011] [info loss: 1.469543]\n",
            "[Epoch 32/200] [Batch 43/938] [D loss: 0.241128] [G loss: 0.277099] [info loss: 1.476168]\n",
            "[Epoch 32/200] [Batch 44/938] [D loss: 0.171421] [G loss: 0.171286] [info loss: 1.486054]\n",
            "[Epoch 32/200] [Batch 45/938] [D loss: 0.180294] [G loss: 0.286574] [info loss: 1.470053]\n",
            "[Epoch 32/200] [Batch 46/938] [D loss: 0.192017] [G loss: 0.316502] [info loss: 1.472201]\n",
            "[Epoch 32/200] [Batch 47/938] [D loss: 0.219434] [G loss: 0.597290] [info loss: 1.468148]\n",
            "[Epoch 32/200] [Batch 48/938] [D loss: 0.211017] [G loss: 0.518932] [info loss: 1.481361]\n",
            "[Epoch 32/200] [Batch 49/938] [D loss: 0.327418] [G loss: 0.230200] [info loss: 1.481068]\n",
            "[Epoch 32/200] [Batch 50/938] [D loss: 0.165673] [G loss: 0.324274] [info loss: 1.471661]\n",
            "[Epoch 32/200] [Batch 51/938] [D loss: 0.357236] [G loss: 0.450151] [info loss: 1.474377]\n",
            "[Epoch 32/200] [Batch 52/938] [D loss: 0.135813] [G loss: 0.534307] [info loss: 1.469787]\n",
            "[Epoch 32/200] [Batch 53/938] [D loss: 0.111808] [G loss: 0.369740] [info loss: 1.476367]\n",
            "[Epoch 32/200] [Batch 54/938] [D loss: 0.230395] [G loss: 0.637514] [info loss: 1.475915]\n",
            "[Epoch 32/200] [Batch 55/938] [D loss: 0.184968] [G loss: 0.376792] [info loss: 1.473787]\n",
            "[Epoch 32/200] [Batch 56/938] [D loss: 0.256542] [G loss: 0.372519] [info loss: 1.485304]\n",
            "[Epoch 32/200] [Batch 57/938] [D loss: 0.240710] [G loss: 0.273950] [info loss: 1.493849]\n",
            "[Epoch 32/200] [Batch 58/938] [D loss: 0.254705] [G loss: 0.398826] [info loss: 1.470776]\n",
            "[Epoch 32/200] [Batch 59/938] [D loss: 0.185478] [G loss: 0.271321] [info loss: 1.472292]\n",
            "[Epoch 32/200] [Batch 60/938] [D loss: 0.127752] [G loss: 0.433067] [info loss: 1.481708]\n",
            "[Epoch 32/200] [Batch 61/938] [D loss: 0.248178] [G loss: 0.264015] [info loss: 1.483224]\n",
            "[Epoch 32/200] [Batch 62/938] [D loss: 0.156663] [G loss: 0.341111] [info loss: 1.470132]\n",
            "[Epoch 32/200] [Batch 63/938] [D loss: 0.247991] [G loss: 0.351887] [info loss: 1.472868]\n",
            "[Epoch 32/200] [Batch 64/938] [D loss: 0.226633] [G loss: 0.298404] [info loss: 1.487829]\n",
            "[Epoch 32/200] [Batch 65/938] [D loss: 0.303565] [G loss: 0.144796] [info loss: 1.476881]\n",
            "[Epoch 32/200] [Batch 66/938] [D loss: 0.257821] [G loss: 0.372099] [info loss: 1.481851]\n",
            "[Epoch 32/200] [Batch 67/938] [D loss: 0.239189] [G loss: 0.332935] [info loss: 1.470237]\n",
            "[Epoch 32/200] [Batch 68/938] [D loss: 0.202167] [G loss: 0.516468] [info loss: 1.470360]\n",
            "[Epoch 32/200] [Batch 69/938] [D loss: 0.209762] [G loss: 0.404373] [info loss: 1.484524]\n",
            "[Epoch 32/200] [Batch 70/938] [D loss: 0.120631] [G loss: 0.335972] [info loss: 1.471523]\n",
            "[Epoch 32/200] [Batch 71/938] [D loss: 0.195748] [G loss: 0.153350] [info loss: 1.471700]\n",
            "[Epoch 32/200] [Batch 72/938] [D loss: 0.212166] [G loss: 0.550231] [info loss: 1.468538]\n",
            "[Epoch 32/200] [Batch 73/938] [D loss: 0.202734] [G loss: 0.242916] [info loss: 1.471156]\n",
            "[Epoch 32/200] [Batch 74/938] [D loss: 0.285468] [G loss: 0.169907] [info loss: 1.476127]\n",
            "[Epoch 32/200] [Batch 75/938] [D loss: 0.098950] [G loss: 0.369824] [info loss: 1.471073]\n",
            "[Epoch 32/200] [Batch 76/938] [D loss: 0.233179] [G loss: 0.384093] [info loss: 1.468321]\n",
            "[Epoch 32/200] [Batch 77/938] [D loss: 0.157804] [G loss: 0.392201] [info loss: 1.472959]\n",
            "[Epoch 32/200] [Batch 78/938] [D loss: 0.250443] [G loss: 0.097010] [info loss: 1.483490]\n",
            "[Epoch 32/200] [Batch 79/938] [D loss: 0.184470] [G loss: 0.424697] [info loss: 1.471346]\n",
            "[Epoch 32/200] [Batch 80/938] [D loss: 0.218423] [G loss: 0.259142] [info loss: 1.470084]\n",
            "[Epoch 32/200] [Batch 81/938] [D loss: 0.138262] [G loss: 0.648616] [info loss: 1.478933]\n",
            "[Epoch 32/200] [Batch 82/938] [D loss: 0.178403] [G loss: 0.525479] [info loss: 1.479605]\n",
            "[Epoch 32/200] [Batch 83/938] [D loss: 0.203749] [G loss: 0.275596] [info loss: 1.473885]\n",
            "[Epoch 32/200] [Batch 84/938] [D loss: 0.222649] [G loss: 0.371782] [info loss: 1.481014]\n",
            "[Epoch 32/200] [Batch 85/938] [D loss: 0.234698] [G loss: 0.144335] [info loss: 1.481918]\n",
            "[Epoch 32/200] [Batch 86/938] [D loss: 0.138091] [G loss: 0.198250] [info loss: 1.470287]\n",
            "[Epoch 32/200] [Batch 87/938] [D loss: 0.260110] [G loss: 0.401915] [info loss: 1.484818]\n",
            "[Epoch 32/200] [Batch 88/938] [D loss: 0.149881] [G loss: 0.283364] [info loss: 1.470514]\n",
            "[Epoch 32/200] [Batch 89/938] [D loss: 0.252448] [G loss: 0.176116] [info loss: 1.473897]\n",
            "[Epoch 32/200] [Batch 90/938] [D loss: 0.311487] [G loss: 0.469140] [info loss: 1.472956]\n",
            "[Epoch 32/200] [Batch 91/938] [D loss: 0.157581] [G loss: 0.459765] [info loss: 1.484839]\n",
            "[Epoch 32/200] [Batch 92/938] [D loss: 0.218494] [G loss: 0.567564] [info loss: 1.470339]\n",
            "[Epoch 32/200] [Batch 93/938] [D loss: 0.203784] [G loss: 0.244482] [info loss: 1.476318]\n",
            "[Epoch 32/200] [Batch 94/938] [D loss: 0.275862] [G loss: 0.320203] [info loss: 1.485633]\n",
            "[Epoch 32/200] [Batch 95/938] [D loss: 0.240057] [G loss: 0.252446] [info loss: 1.475347]\n",
            "[Epoch 32/200] [Batch 96/938] [D loss: 0.153391] [G loss: 0.291493] [info loss: 1.499374]\n",
            "[Epoch 32/200] [Batch 97/938] [D loss: 0.144375] [G loss: 0.264497] [info loss: 1.498412]\n",
            "[Epoch 32/200] [Batch 98/938] [D loss: 0.246833] [G loss: 0.222634] [info loss: 1.471049]\n",
            "[Epoch 32/200] [Batch 99/938] [D loss: 0.151413] [G loss: 0.451141] [info loss: 1.488019]\n",
            "[Epoch 32/200] [Batch 100/938] [D loss: 0.271772] [G loss: 0.551246] [info loss: 1.474021]\n",
            "[Epoch 32/200] [Batch 101/938] [D loss: 0.291003] [G loss: 0.252776] [info loss: 1.474239]\n",
            "[Epoch 32/200] [Batch 102/938] [D loss: 0.158697] [G loss: 0.360640] [info loss: 1.470347]\n",
            "[Epoch 32/200] [Batch 103/938] [D loss: 0.184647] [G loss: 0.183792] [info loss: 1.470106]\n",
            "[Epoch 32/200] [Batch 104/938] [D loss: 0.171724] [G loss: 0.273418] [info loss: 1.485048]\n",
            "[Epoch 32/200] [Batch 105/938] [D loss: 0.267710] [G loss: 0.497754] [info loss: 1.480691]\n",
            "[Epoch 32/200] [Batch 106/938] [D loss: 0.283888] [G loss: 0.616486] [info loss: 1.487326]\n",
            "[Epoch 32/200] [Batch 107/938] [D loss: 0.440694] [G loss: 0.269836] [info loss: 1.470981]\n",
            "[Epoch 32/200] [Batch 108/938] [D loss: 0.131311] [G loss: 0.620303] [info loss: 1.470024]\n",
            "[Epoch 32/200] [Batch 109/938] [D loss: 0.201155] [G loss: 0.242766] [info loss: 1.469811]\n",
            "[Epoch 32/200] [Batch 110/938] [D loss: 0.200498] [G loss: 0.224225] [info loss: 1.487214]\n",
            "[Epoch 32/200] [Batch 111/938] [D loss: 0.226320] [G loss: 0.443853] [info loss: 1.473708]\n",
            "[Epoch 32/200] [Batch 112/938] [D loss: 0.217534] [G loss: 0.341718] [info loss: 1.468689]\n",
            "[Epoch 32/200] [Batch 113/938] [D loss: 0.160929] [G loss: 0.278258] [info loss: 1.470296]\n",
            "[Epoch 32/200] [Batch 114/938] [D loss: 0.180130] [G loss: 0.326008] [info loss: 1.471438]\n",
            "[Epoch 32/200] [Batch 115/938] [D loss: 0.215472] [G loss: 0.308696] [info loss: 1.469036]\n",
            "[Epoch 32/200] [Batch 116/938] [D loss: 0.283684] [G loss: 0.182317] [info loss: 1.474924]\n",
            "[Epoch 32/200] [Batch 117/938] [D loss: 0.329581] [G loss: 0.165282] [info loss: 1.480705]\n",
            "[Epoch 32/200] [Batch 118/938] [D loss: 0.161228] [G loss: 0.240836] [info loss: 1.480049]\n",
            "[Epoch 32/200] [Batch 119/938] [D loss: 0.170620] [G loss: 0.408566] [info loss: 1.478289]\n",
            "[Epoch 32/200] [Batch 120/938] [D loss: 0.243367] [G loss: 0.223011] [info loss: 1.487443]\n",
            "[Epoch 32/200] [Batch 121/938] [D loss: 0.229122] [G loss: 0.243616] [info loss: 1.484007]\n",
            "[Epoch 32/200] [Batch 122/938] [D loss: 0.158929] [G loss: 0.229367] [info loss: 1.496023]\n",
            "[Epoch 32/200] [Batch 123/938] [D loss: 0.201637] [G loss: 0.196275] [info loss: 1.470605]\n",
            "[Epoch 32/200] [Batch 124/938] [D loss: 0.200313] [G loss: 0.387860] [info loss: 1.486114]\n",
            "[Epoch 32/200] [Batch 125/938] [D loss: 0.147720] [G loss: 0.437395] [info loss: 1.492911]\n",
            "[Epoch 32/200] [Batch 126/938] [D loss: 0.293426] [G loss: 0.364550] [info loss: 1.490132]\n",
            "[Epoch 32/200] [Batch 127/938] [D loss: 0.226036] [G loss: 0.400905] [info loss: 1.471437]\n",
            "[Epoch 32/200] [Batch 128/938] [D loss: 0.123656] [G loss: 0.337881] [info loss: 1.490970]\n",
            "[Epoch 32/200] [Batch 129/938] [D loss: 0.136355] [G loss: 0.353091] [info loss: 1.470125]\n",
            "[Epoch 32/200] [Batch 130/938] [D loss: 0.257979] [G loss: 0.256025] [info loss: 1.481434]\n",
            "[Epoch 32/200] [Batch 131/938] [D loss: 0.212853] [G loss: 0.653341] [info loss: 1.484723]\n",
            "[Epoch 32/200] [Batch 132/938] [D loss: 0.291235] [G loss: 0.445126] [info loss: 1.484386]\n",
            "[Epoch 32/200] [Batch 133/938] [D loss: 0.260523] [G loss: 0.316419] [info loss: 1.473418]\n",
            "[Epoch 32/200] [Batch 134/938] [D loss: 0.263232] [G loss: 0.347817] [info loss: 1.503671]\n",
            "[Epoch 32/200] [Batch 135/938] [D loss: 0.158776] [G loss: 0.829551] [info loss: 1.474800]\n",
            "[Epoch 32/200] [Batch 136/938] [D loss: 0.185817] [G loss: 0.553627] [info loss: 1.471488]\n",
            "[Epoch 32/200] [Batch 137/938] [D loss: 0.218657] [G loss: 0.308436] [info loss: 1.483590]\n",
            "[Epoch 32/200] [Batch 138/938] [D loss: 0.190525] [G loss: 0.443022] [info loss: 1.469252]\n",
            "[Epoch 32/200] [Batch 139/938] [D loss: 0.225654] [G loss: 0.247428] [info loss: 1.490885]\n",
            "[Epoch 32/200] [Batch 140/938] [D loss: 0.164846] [G loss: 0.195529] [info loss: 1.469984]\n",
            "[Epoch 32/200] [Batch 141/938] [D loss: 0.202628] [G loss: 0.347444] [info loss: 1.485698]\n",
            "[Epoch 32/200] [Batch 142/938] [D loss: 0.249249] [G loss: 0.419673] [info loss: 1.471972]\n",
            "[Epoch 32/200] [Batch 143/938] [D loss: 0.180252] [G loss: 0.323208] [info loss: 1.473221]\n",
            "[Epoch 32/200] [Batch 144/938] [D loss: 0.189520] [G loss: 0.583822] [info loss: 1.486550]\n",
            "[Epoch 32/200] [Batch 145/938] [D loss: 0.193735] [G loss: 0.332620] [info loss: 1.478829]\n",
            "[Epoch 32/200] [Batch 146/938] [D loss: 0.248262] [G loss: 0.216443] [info loss: 1.474884]\n",
            "[Epoch 32/200] [Batch 147/938] [D loss: 0.260097] [G loss: 0.078614] [info loss: 1.484067]\n",
            "[Epoch 32/200] [Batch 148/938] [D loss: 0.174864] [G loss: 0.289203] [info loss: 1.482972]\n",
            "[Epoch 32/200] [Batch 149/938] [D loss: 0.145551] [G loss: 0.436737] [info loss: 1.470031]\n",
            "[Epoch 32/200] [Batch 150/938] [D loss: 0.278377] [G loss: 0.529906] [info loss: 1.469135]\n",
            "[Epoch 32/200] [Batch 151/938] [D loss: 0.273950] [G loss: 0.178176] [info loss: 1.497854]\n",
            "[Epoch 32/200] [Batch 152/938] [D loss: 0.198176] [G loss: 0.257796] [info loss: 1.469915]\n",
            "[Epoch 32/200] [Batch 153/938] [D loss: 0.104248] [G loss: 0.263514] [info loss: 1.481154]\n",
            "[Epoch 32/200] [Batch 154/938] [D loss: 0.216521] [G loss: 0.227358] [info loss: 1.472167]\n",
            "[Epoch 32/200] [Batch 155/938] [D loss: 0.195086] [G loss: 0.163851] [info loss: 1.470681]\n",
            "[Epoch 32/200] [Batch 156/938] [D loss: 0.270275] [G loss: 0.284778] [info loss: 1.476708]\n",
            "[Epoch 32/200] [Batch 157/938] [D loss: 0.187273] [G loss: 0.284409] [info loss: 1.481271]\n",
            "[Epoch 32/200] [Batch 158/938] [D loss: 0.227340] [G loss: 0.122207] [info loss: 1.471176]\n",
            "[Epoch 32/200] [Batch 159/938] [D loss: 0.193547] [G loss: 0.316356] [info loss: 1.469721]\n",
            "[Epoch 32/200] [Batch 160/938] [D loss: 0.184904] [G loss: 0.269838] [info loss: 1.468433]\n",
            "[Epoch 32/200] [Batch 161/938] [D loss: 0.198406] [G loss: 0.489727] [info loss: 1.468807]\n",
            "[Epoch 32/200] [Batch 162/938] [D loss: 0.131843] [G loss: 0.266392] [info loss: 1.471095]\n",
            "[Epoch 32/200] [Batch 163/938] [D loss: 0.183435] [G loss: 0.343920] [info loss: 1.470214]\n",
            "[Epoch 32/200] [Batch 164/938] [D loss: 0.276506] [G loss: 0.444983] [info loss: 1.468422]\n",
            "[Epoch 32/200] [Batch 165/938] [D loss: 0.254321] [G loss: 0.243189] [info loss: 1.469126]\n",
            "[Epoch 32/200] [Batch 166/938] [D loss: 0.273790] [G loss: 0.371432] [info loss: 1.469054]\n",
            "[Epoch 32/200] [Batch 167/938] [D loss: 0.204727] [G loss: 0.209931] [info loss: 1.468664]\n",
            "[Epoch 32/200] [Batch 168/938] [D loss: 0.201830] [G loss: 0.342474] [info loss: 1.467498]\n",
            "[Epoch 32/200] [Batch 169/938] [D loss: 0.228822] [G loss: 0.541380] [info loss: 1.480798]\n",
            "[Epoch 32/200] [Batch 170/938] [D loss: 0.176016] [G loss: 0.269607] [info loss: 1.500359]\n",
            "[Epoch 32/200] [Batch 171/938] [D loss: 0.151078] [G loss: 0.223826] [info loss: 1.479156]\n",
            "[Epoch 32/200] [Batch 172/938] [D loss: 0.203915] [G loss: 0.291309] [info loss: 1.469800]\n",
            "[Epoch 32/200] [Batch 173/938] [D loss: 0.099646] [G loss: 0.315180] [info loss: 1.485073]\n",
            "[Epoch 32/200] [Batch 174/938] [D loss: 0.157467] [G loss: 0.205782] [info loss: 1.469982]\n",
            "[Epoch 32/200] [Batch 175/938] [D loss: 0.113026] [G loss: 0.329613] [info loss: 1.498484]\n",
            "[Epoch 32/200] [Batch 176/938] [D loss: 0.349646] [G loss: 0.157142] [info loss: 1.500912]\n",
            "[Epoch 32/200] [Batch 177/938] [D loss: 0.149280] [G loss: 0.155801] [info loss: 1.471215]\n",
            "[Epoch 32/200] [Batch 178/938] [D loss: 0.167697] [G loss: 0.231762] [info loss: 1.489879]\n",
            "[Epoch 32/200] [Batch 179/938] [D loss: 0.185948] [G loss: 0.182439] [info loss: 1.472304]\n",
            "[Epoch 32/200] [Batch 180/938] [D loss: 0.282433] [G loss: 0.253208] [info loss: 1.471547]\n",
            "[Epoch 32/200] [Batch 181/938] [D loss: 0.260051] [G loss: 0.291849] [info loss: 1.470989]\n",
            "[Epoch 32/200] [Batch 182/938] [D loss: 0.255704] [G loss: 0.276493] [info loss: 1.473709]\n",
            "[Epoch 32/200] [Batch 183/938] [D loss: 0.202043] [G loss: 0.271345] [info loss: 1.500595]\n",
            "[Epoch 32/200] [Batch 184/938] [D loss: 0.166858] [G loss: 0.195665] [info loss: 1.469574]\n",
            "[Epoch 32/200] [Batch 185/938] [D loss: 0.222087] [G loss: 0.347614] [info loss: 1.469509]\n",
            "[Epoch 32/200] [Batch 186/938] [D loss: 0.182705] [G loss: 0.216492] [info loss: 1.471451]\n",
            "[Epoch 32/200] [Batch 187/938] [D loss: 0.167816] [G loss: 0.200789] [info loss: 1.485162]\n",
            "[Epoch 32/200] [Batch 188/938] [D loss: 0.177244] [G loss: 0.278578] [info loss: 1.470396]\n",
            "[Epoch 32/200] [Batch 189/938] [D loss: 0.139603] [G loss: 0.448200] [info loss: 1.488189]\n",
            "[Epoch 32/200] [Batch 190/938] [D loss: 0.299445] [G loss: 0.357697] [info loss: 1.486540]\n",
            "[Epoch 32/200] [Batch 191/938] [D loss: 0.142644] [G loss: 0.316641] [info loss: 1.472007]\n",
            "[Epoch 32/200] [Batch 192/938] [D loss: 0.284565] [G loss: 0.364096] [info loss: 1.471929]\n",
            "[Epoch 32/200] [Batch 193/938] [D loss: 0.200493] [G loss: 0.175631] [info loss: 1.491370]\n",
            "[Epoch 32/200] [Batch 194/938] [D loss: 0.269584] [G loss: 0.278907] [info loss: 1.467585]\n",
            "[Epoch 32/200] [Batch 195/938] [D loss: 0.150483] [G loss: 0.372744] [info loss: 1.468357]\n",
            "[Epoch 32/200] [Batch 196/938] [D loss: 0.162532] [G loss: 0.294499] [info loss: 1.469123]\n",
            "[Epoch 32/200] [Batch 197/938] [D loss: 0.196929] [G loss: 0.295115] [info loss: 1.470815]\n",
            "[Epoch 32/200] [Batch 198/938] [D loss: 0.238339] [G loss: 0.276160] [info loss: 1.482239]\n",
            "[Epoch 32/200] [Batch 199/938] [D loss: 0.302297] [G loss: 0.234283] [info loss: 1.469926]\n",
            "[Epoch 32/200] [Batch 200/938] [D loss: 0.211401] [G loss: 0.571000] [info loss: 1.474872]\n",
            "[Epoch 32/200] [Batch 201/938] [D loss: 0.276141] [G loss: 0.388756] [info loss: 1.478936]\n",
            "[Epoch 32/200] [Batch 202/938] [D loss: 0.201686] [G loss: 0.344961] [info loss: 1.470169]\n",
            "[Epoch 32/200] [Batch 203/938] [D loss: 0.266230] [G loss: 0.242465] [info loss: 1.472989]\n",
            "[Epoch 32/200] [Batch 204/938] [D loss: 0.235753] [G loss: 0.387169] [info loss: 1.478713]\n",
            "[Epoch 32/200] [Batch 205/938] [D loss: 0.244571] [G loss: 0.540174] [info loss: 1.469388]\n",
            "[Epoch 32/200] [Batch 206/938] [D loss: 0.167534] [G loss: 0.305532] [info loss: 1.498684]\n",
            "[Epoch 32/200] [Batch 207/938] [D loss: 0.137451] [G loss: 0.335642] [info loss: 1.476562]\n",
            "[Epoch 32/200] [Batch 208/938] [D loss: 0.354776] [G loss: 0.371562] [info loss: 1.494728]\n",
            "[Epoch 32/200] [Batch 209/938] [D loss: 0.326011] [G loss: 0.201139] [info loss: 1.478821]\n",
            "[Epoch 32/200] [Batch 210/938] [D loss: 0.169539] [G loss: 0.179028] [info loss: 1.468714]\n",
            "[Epoch 32/200] [Batch 211/938] [D loss: 0.295123] [G loss: 0.433331] [info loss: 1.489424]\n",
            "[Epoch 32/200] [Batch 212/938] [D loss: 0.247063] [G loss: 0.147120] [info loss: 1.512172]\n",
            "[Epoch 32/200] [Batch 213/938] [D loss: 0.260272] [G loss: 0.288704] [info loss: 1.472965]\n",
            "[Epoch 32/200] [Batch 214/938] [D loss: 0.298011] [G loss: 0.433394] [info loss: 1.491261]\n",
            "[Epoch 32/200] [Batch 215/938] [D loss: 0.211515] [G loss: 0.291555] [info loss: 1.492281]\n",
            "[Epoch 32/200] [Batch 216/938] [D loss: 0.467045] [G loss: 0.167356] [info loss: 1.469575]\n",
            "[Epoch 32/200] [Batch 217/938] [D loss: 0.235463] [G loss: 0.206160] [info loss: 1.484144]\n",
            "[Epoch 32/200] [Batch 218/938] [D loss: 0.224156] [G loss: 0.158831] [info loss: 1.496066]\n",
            "[Epoch 32/200] [Batch 219/938] [D loss: 0.191570] [G loss: 0.230817] [info loss: 1.473244]\n",
            "[Epoch 32/200] [Batch 220/938] [D loss: 0.230709] [G loss: 0.589017] [info loss: 1.470891]\n",
            "[Epoch 32/200] [Batch 221/938] [D loss: 0.151583] [G loss: 0.455197] [info loss: 1.472647]\n",
            "[Epoch 32/200] [Batch 222/938] [D loss: 0.120977] [G loss: 0.391372] [info loss: 1.474098]\n",
            "[Epoch 32/200] [Batch 223/938] [D loss: 0.336788] [G loss: 0.358742] [info loss: 1.476954]\n",
            "[Epoch 32/200] [Batch 224/938] [D loss: 0.228308] [G loss: 0.074017] [info loss: 1.470766]\n",
            "[Epoch 32/200] [Batch 225/938] [D loss: 0.178269] [G loss: 0.129406] [info loss: 1.473813]\n",
            "[Epoch 32/200] [Batch 226/938] [D loss: 0.306712] [G loss: 0.249236] [info loss: 1.472144]\n",
            "[Epoch 32/200] [Batch 227/938] [D loss: 0.259000] [G loss: 0.450276] [info loss: 1.473631]\n",
            "[Epoch 32/200] [Batch 228/938] [D loss: 0.200580] [G loss: 0.447804] [info loss: 1.487174]\n",
            "[Epoch 32/200] [Batch 229/938] [D loss: 0.340823] [G loss: 0.341741] [info loss: 1.472566]\n",
            "[Epoch 32/200] [Batch 230/938] [D loss: 0.255684] [G loss: 0.491568] [info loss: 1.509686]\n",
            "[Epoch 32/200] [Batch 231/938] [D loss: 0.261121] [G loss: 0.320214] [info loss: 1.468790]\n",
            "[Epoch 32/200] [Batch 232/938] [D loss: 0.236740] [G loss: 0.480247] [info loss: 1.471140]\n",
            "[Epoch 32/200] [Batch 233/938] [D loss: 0.296278] [G loss: 0.171115] [info loss: 1.476159]\n",
            "[Epoch 32/200] [Batch 234/938] [D loss: 0.204174] [G loss: 0.214536] [info loss: 1.478214]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4ad9340bd3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Generate a batch of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Loss measures generator's ability to fool the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-890fb09523d7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, noise, labels, code)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}